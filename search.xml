<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>图像分割（深度学习）</title>
      <link href="/2019/05/24/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%EF%BC%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%89/"/>
      <url>/2019/05/24/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%EF%BC%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="按分割目的划分"><a href="#按分割目的划分" class="headerlink" title="按分割目的划分"></a>按分割目的划分</h2><ul><li><p><strong>普通分割</strong></p><p>将不同分属不同物体的像素区域分开。<br>如前景与后景分割开，狗的区域与猫的区域与背景分割开。</p></li><li><p><strong>语义分割</strong></p><p>在普通分割的基础上，分类出每一块区域的语义（即这块区域是什么物体）。<br>如把画面中的所有物体都指出它们各自的类别。</p></li><li><p><strong>实例分割</strong></p><p>在语义分割的基础上，给每个物体编号。<br>如这个是该画面中的狗A，那个是画面中的狗B。</p></li></ul><h2 id="CNN图像语义分割一般流程："><a href="#CNN图像语义分割一般流程：" class="headerlink" title="CNN图像语义分割一般流程："></a>CNN图像语义分割一般流程：</h2><ol><li><strong>下采样+上采样：Convlution + Deconvlution／Resize</strong></li><li><strong>多尺度特征融合：特征逐点相加／特征channel维度拼接</strong></li><li><strong>获得像素级别的segement map：对每一个像素点进行判断类别</strong></li></ol><h2 id="图像分割网络结构比较"><a href="#图像分割网络结构比较" class="headerlink" title="图像分割网络结构比较"></a>图像分割网络结构比较</h2><p><img src="net.png" alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>FCN更像一种技巧。随着基本网络（如VGG， ResNet）性能的提升而不断进步。</li><li>深度学习+概率图模型（PGM）是一种趋势。其实DL说白了就是进行特征提取，而PGM能够从数学理论很好的解释事物本质间的联系。</li><li>概率图模型的网络化。因为PGM通常不太方便加入DL的模型中，将PGM网络化后能够是PGM参数自学习，同时构成end-to-end的系统。</li></ul><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><h3 id="入门学习"><a href="#入门学习" class="headerlink" title="入门学习"></a>入门学习</h3><ol><li>A 2017 Guide to Semantic Segmentation with Deep Learning 概述——用深度学习做语义分割<ul><li>[<a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review" target="_blank" rel="noopener">http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review</a>]</li><li>中文翻译：[<a href="http://simonduan.site/2017/07/23/notes-semantic-segmentation-deep-learning-review/" target="_blank" rel="noopener">http://simonduan.site/2017/07/23/notes-semantic-segmentation-deep-learning-review/</a>]</li></ul></li><li>从全卷积网络到大型卷积核：深度学习的语义分割全指南<ul><li>[<a href="https://www.jiqizhixin.com/articles/2017-07-14-10" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-07-14-10</a>]</li></ul></li><li>Fully Convolutional Networks<ul><li>[<a href="http://simtalk.cn/2016/11/01/Fully-Convolutional-Networks/" target="_blank" rel="noopener">http://simtalk.cn/2016/11/01/Fully-Convolutional-Networks/</a>]</li></ul></li><li>语义分割中的深度学习方法全解：从FCN、SegNet到各代DeepLab<ul><li>[<a href="https://zhuanlan.zhihu.com/p/27794982" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27794982</a>]</li></ul></li><li>图像语义分割之FCN和CRF<ul><li>[<a href="https://zhuanlan.zhihu.com/p/22308032" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22308032</a>]</li></ul></li><li>从特斯拉到计算机视觉之「图像语义分割」<ul><li>[<a href="http://www.52cs.org/?p=1089" target="_blank" rel="noopener">http://www.52cs.org/?p=1089</a>]</li></ul></li><li>计算机视觉之语义分割<ul><li>[<a href="http://blog.geohey.com/ji-suan-ji-shi-jue-zhi-yu-yi-fen-ge/" target="_blank" rel="noopener">http://blog.geohey.com/ji-suan-ji-shi-jue-zhi-yu-yi-fen-ge/</a>]</li></ul></li><li>Segmentation Results: VOC2012 PASCAL语义分割比赛排名<ul><li>[<a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6" target="_blank" rel="noopener">http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6</a>]</li></ul></li></ol><h3 id="进阶论文"><a href="#进阶论文" class="headerlink" title="进阶论文"></a>进阶论文</h3><ol><li>U-Net [<a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1505.04597.pdf</a>]</li><li>SegNet [<a href="https://arxiv.org/pdf/1511.00561.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.00561.pdf</a>]</li><li>DeepLab [<a href="https://arxiv.org/pdf/1606.00915.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.00915.pdf</a>]</li><li>FCN [<a href="https://arxiv.org/pdf/1605.06211.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1605.06211.pdf</a>]</li><li>ENet [<a href="https://arxiv.org/pdf/1606.02147.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.02147.pdf</a>]</li><li>LinkNet [<a href="https://arxiv.org/pdf/1707.03718.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1707.03718.pdf</a>]</li><li>DenseNet [<a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1608.06993.pdf</a>]</li><li>Tiramisu [<a href="https://arxiv.org/pdf/1611.09326.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.09326.pdf</a>]</li><li>DilatedNet [<a href="https://arxiv.org/pdf/1511.07122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.07122.pdf</a>]</li><li>PixelNet [<a href="https://arxiv.org/pdf/1609.06694.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1609.06694.pdf</a>]</li><li>ICNet [<a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.08545.pdf</a>]</li><li>ERFNet [<a href="http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera17iv.pdf" target="_blank" rel="noopener">http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera17iv.pdf</a>]</li><li>RefineNet [<a href="https://arxiv.org/pdf/1611.06612.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.06612.pdf</a>]</li><li>PSPNet [<a href="https://arxiv.org/pdf/1612.01105.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1612.01105.pdf</a>]</li><li>CRFasRNN [<a href="http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/%7Eszheng/papers/CRFasRNN.pdf</a>]</li><li>Dilated convolution [<a href="https://arxiv.org/pdf/1511.07122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.07122.pdf</a>]</li><li>DeconvNet [<a href="https://arxiv.org/pdf/1505.04366.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1505.04366.pdf</a>]</li><li>FRRN [<a href="https://arxiv.org/pdf/1611.08323.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.08323.pdf</a>]</li><li>GCN [<a href="https://arxiv.org/pdf/1703.02719.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.02719.pdf</a>]</li><li>DUC, HDC [<a href="https://arxiv.org/pdf/1702.08502.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1702.08502.pdf</a>]</li><li>Segaware [<a href="https://arxiv.org/pdf/1708.04607.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1708.04607.pdf</a>]</li><li>Semantic Segmentation using Adversarial Networks [<a href="https://arxiv.org/pdf/1611.08408.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.08408.pdf</a>]</li></ol><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><ol><li>A Review on Deep Learning Techniques Applied to Semantic Segmentation Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez 2017<ul><li>[<a href="https://arxiv.org/abs/1704.06857" target="_blank" rel="noopener">https://arxiv.org/abs/1704.06857</a>]</li></ul></li><li>Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art<ul><li>[<a href="https://arxiv.org/abs/1704.05519" target="_blank" rel="noopener">https://arxiv.org/abs/1704.05519</a>]</li></ul></li><li>基于内容的图像分割方法综述 姜 枫 顾 庆 郝慧珍 李 娜 郭延文 陈道蓄 2017<ul><li>[<a href="http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=5136&amp;journal_id=jos" target="_blank" rel="noopener">http://www.jos.org.cn/ch/reader/create_pdf.aspx?file_no=5136&amp;journal_id=jos</a>]</li></ul></li></ol><h3 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h3><ol><li>Semantic Image Segmentation with Deep Learning<ul><li>[<a href="http://www.robots.ox.ac.uk/~sadeep/files/crfasrnn_presentation.pdf" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/~sadeep/files/crfasrnn_presentation.pdf</a>]</li></ul></li><li>A 2017 Guide to Semantic Segmentation with Deep Learning<ul><li>[<a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review" target="_blank" rel="noopener">http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review</a>]</li></ul></li><li>Image Segmentation with Tensorflow using CNNs and Conditional Random Fields<ul><li>[<a href="http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/" target="_blank" rel="noopener">http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/</a>]</li></ul></li></ol><h3 id="视频教程"><a href="#视频教程" class="headerlink" title="视频教程"></a>视频教程</h3><ol><li>CS231n: Convolutional Neural Networks for Visual Recognition Lecture 11 Detection and Segmentation <ul><li>[<a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">http://cs231n.stanford.edu/syllabus.html</a>]</li></ul></li><li>Machine Learning for Semantic Segmentation - Basics of Modern Image Analysis<ul><li>[<a href="https://www.youtube.com/watch?v=psLChcm8aiU" target="_blank" rel="noopener">https://www.youtube.com/watch?v=psLChcm8aiU</a>]</li></ul></li></ol><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="Semantic-segmentation"><a href="#Semantic-segmentation" class="headerlink" title="Semantic segmentation"></a>Semantic segmentation</h4><ol><li>U-Net (<a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1505.04597.pdf</a>)<ul><li><a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/" target="_blank" rel="noopener">https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/</a> (Caffe - Matlab)</li><li><a href="https://github.com/jocicmarko/ultrasound-nerve-segmentation" target="_blank" rel="noopener">https://github.com/jocicmarko/ultrasound-nerve-segmentation</a> (Keras)</li><li><a href="https://github.com/EdwardTyantov/ultrasound-nerve-segmentation(Keras" target="_blank" rel="noopener">https://github.com/EdwardTyantov/ultrasound-nerve-segmentation(Keras</a>)</li><li><a href="https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model" target="_blank" rel="noopener">https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model</a> (Keras)</li><li><a href="https://github.com/yihui-he/u-net" target="_blank" rel="noopener">https://github.com/yihui-he/u-net</a> (Keras)</li><li><a href="https://github.com/jakeret/tf_unet" target="_blank" rel="noopener">https://github.com/jakeret/tf_unet</a> (Tensorflow)</li><li><a href="https://github.com/DLTK/DLTK/blob/master/examples/Toy_segmentation/simple_dltk_unet.ipynb" target="_blank" rel="noopener">https://github.com/DLTK/DLTK/blob/master/examples/Toy_segmentation/simple_dltk_unet.ipynb</a> (Tensorflow)</li><li><a href="https://github.com/divamgupta/image-segmentation-keras" target="_blank" rel="noopener">https://github.com/divamgupta/image-segmentation-keras</a> (Keras)</li><li><a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation" target="_blank" rel="noopener">https://github.com/ZijunDeng/pytorch-semantic-segmentation</a> (PyTorch)</li><li><a href="https://github.com/akirasosa/mobile-semantic-segmentation" target="_blank" rel="noopener">https://github.com/akirasosa/mobile-semantic-segmentation</a> (Keras)</li><li><a href="https://github.com/orobix/retina-unet" target="_blank" rel="noopener">https://github.com/orobix/retina-unet</a> (Keras)</li></ul></li><li>SegNet (<a href="https://arxiv.org/pdf/1511.00561.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.00561.pdf</a>)<ul><li><a href="https://github.com/alexgkendall/caffe-segnet" target="_blank" rel="noopener">https://github.com/alexgkendall/caffe-segnet</a> (Caffe)</li><li><a href="https://github.com/developmentseed/caffe/tree/segnet-multi-gpu" target="_blank" rel="noopener">https://github.com/developmentseed/caffe/tree/segnet-multi-gpu</a> (Caffe)</li><li><a href="https://github.com/preddy5/segnet" target="_blank" rel="noopener">https://github.com/preddy5/segnet</a> (Keras)</li><li><a href="https://github.com/imlab-uiip/keras-segnet" target="_blank" rel="noopener">https://github.com/imlab-uiip/keras-segnet</a> (Keras)</li><li><a href="https://github.com/andreaazzini/segnet" target="_blank" rel="noopener">https://github.com/andreaazzini/segnet</a> (Tensorflow)</li><li><a href="https://github.com/fedor-chervinskii/segnet-torch" target="_blank" rel="noopener">https://github.com/fedor-chervinskii/segnet-torch</a> (Torch)</li><li><a href="https://github.com/0bserver07/Keras-SegNet-Basic" target="_blank" rel="noopener">https://github.com/0bserver07/Keras-SegNet-Basic</a> (Keras)</li><li><a href="https://github.com/tkuanlun350/Tensorflow-SegNet" target="_blank" rel="noopener">https://github.com/tkuanlun350/Tensorflow-SegNet</a> (Tensorflow)</li><li><a href="https://github.com/divamgupta/image-segmentation-keras" target="_blank" rel="noopener">https://github.com/divamgupta/image-segmentation-keras</a> (Keras)</li><li><a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation" target="_blank" rel="noopener">https://github.com/ZijunDeng/pytorch-semantic-segmentation</a> (PyTorch)</li><li><a href="https://github.com/chainer/chainercv/tree/master/examples/segnet(Chainer" target="_blank" rel="noopener">https://github.com/chainer/chainercv/tree/master/examples/segnet(Chainer</a>)</li><li><a href="https://github.com/ykamikawa/keras-SegNet" target="_blank" rel="noopener">https://github.com/ykamikawa/keras-SegNet</a> (Keras)</li></ul></li><li>DeepLab (<a href="https://arxiv.org/pdf/1606.00915.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.00915.pdf</a>)<ul><li><a href="https://bitbucket.org/deeplab/deeplab-public/" target="_blank" rel="noopener">https://bitbucket.org/deeplab/deeplab-public/</a> (Caffe)</li><li><a href="https://github.com/cdmh/deeplab-public" target="_blank" rel="noopener">https://github.com/cdmh/deeplab-public</a> (Caffe)</li><li><a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2" target="_blank" rel="noopener">https://bitbucket.org/aquariusjay/deeplab-public-ver2</a> (Caffe)</li><li><a href="https://github.com/TheLegendAli/DeepLab-Context" target="_blank" rel="noopener">https://github.com/TheLegendAli/DeepLab-Context</a> (Caffe)</li><li><a href="https://github.com/msracver/Deformable-ConvNets/tree/master/deeplab(MXNet" target="_blank" rel="noopener">https://github.com/msracver/Deformable-ConvNets/tree/master/deeplab(MXNet</a>)</li><li><a href="https://github.com/DrSleep/tensorflow-deeplab-resnet" target="_blank" rel="noopener">https://github.com/DrSleep/tensorflow-deeplab-resnet</a> (Tensorflow)</li><li><a href="https://github.com/muyang0320/tensorflow-deeplab-resnet-crf(TensorFlow" target="_blank" rel="noopener">https://github.com/muyang0320/tensorflow-deeplab-resnet-crf(TensorFlow</a>)</li><li><a href="https://github.com/isht7/pytorch-deeplab-resnet" target="_blank" rel="noopener">https://github.com/isht7/pytorch-deeplab-resnet</a> (PyTorch)</li><li><a href="https://github.com/bermanmaxim/jaccardSegment" target="_blank" rel="noopener">https://github.com/bermanmaxim/jaccardSegment</a> (PyTorch)</li><li><a href="https://github.com/martinkersner/train-DeepLab" target="_blank" rel="noopener">https://github.com/martinkersner/train-DeepLab</a> (Caffe)</li><li><a href="https://github.com/chenxi116/TF-deeplab" target="_blank" rel="noopener">https://github.com/chenxi116/TF-deeplab</a> (Tensorflow)</li></ul></li><li>FCN (<a href="https://arxiv.org/pdf/1605.06211.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1605.06211.pdf</a>)<ul><li><a href="https://github.com/vlfeat/matconvnet-fcn" target="_blank" rel="noopener">https://github.com/vlfeat/matconvnet-fcn</a> (MatConvNet)</li><li><a href="https://github.com/shelhamer/fcn.berkeleyvision.org" target="_blank" rel="noopener">https://github.com/shelhamer/fcn.berkeleyvision.org</a> (Caffe)</li><li><a href="https://github.com/MarvinTeichmann/tensorflow-fcn" target="_blank" rel="noopener">https://github.com/MarvinTeichmann/tensorflow-fcn</a> (Tensorflow)</li><li><a href="https://github.com/aurora95/Keras-FCN" target="_blank" rel="noopener">https://github.com/aurora95/Keras-FCN</a> (Keras)</li><li><a href="https://github.com/mzaradzki/neuralnets/tree/master/vgg_segmentation_keras" target="_blank" rel="noopener">https://github.com/mzaradzki/neuralnets/tree/master/vgg_segmentation_keras</a> (Keras)</li><li><a href="https://github.com/k3nt0w/FCN_via_keras" target="_blank" rel="noopener">https://github.com/k3nt0w/FCN_via_keras</a> (Keras)</li><li><a href="https://github.com/shekkizh/FCN.tensorflow" target="_blank" rel="noopener">https://github.com/shekkizh/FCN.tensorflow</a> (Tensorflow)</li><li><a href="https://github.com/seewalker/tf-pixelwise" target="_blank" rel="noopener">https://github.com/seewalker/tf-pixelwise</a> (Tensorflow)</li><li><a href="https://github.com/divamgupta/image-segmentation-keras" target="_blank" rel="noopener">https://github.com/divamgupta/image-segmentation-keras</a> (Keras)</li><li><a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation" target="_blank" rel="noopener">https://github.com/ZijunDeng/pytorch-semantic-segmentation</a> (PyTorch)</li><li><a href="https://github.com/wkentaro/pytorch-fcn" target="_blank" rel="noopener">https://github.com/wkentaro/pytorch-fcn</a> (PyTorch)</li><li><a href="https://github.com/wkentaro/fcn" target="_blank" rel="noopener">https://github.com/wkentaro/fcn</a> (Chainer)</li><li><a href="https://github.com/apache/incubator-mxnet/tree/master/example/fcn-xs(MxNet" target="_blank" rel="noopener">https://github.com/apache/incubator-mxnet/tree/master/example/fcn-xs(MxNet</a>)</li><li><a href="https://github.com/muyang0320/tf-fcn" target="_blank" rel="noopener">https://github.com/muyang0320/tf-fcn</a> (Tensorflow)</li><li><a href="https://github.com/ycszen/pytorch-seg" target="_blank" rel="noopener">https://github.com/ycszen/pytorch-seg</a> (PyTorch)</li><li><a href="https://github.com/Kaixhin/FCN-semantic-segmentation" target="_blank" rel="noopener">https://github.com/Kaixhin/FCN-semantic-segmentation</a> (PyTorch)</li></ul></li><li>ENet (<a href="https://arxiv.org/pdf/1606.02147.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.02147.pdf</a>)<ul><li><a href="https://github.com/TimoSaemann/ENet" target="_blank" rel="noopener">https://github.com/TimoSaemann/ENet</a> (Caffe)</li><li><a href="https://github.com/e-lab/ENet-training" target="_blank" rel="noopener">https://github.com/e-lab/ENet-training</a> (Torch)</li><li><a href="https://github.com/PavlosMelissinos/enet-keras" target="_blank" rel="noopener">https://github.com/PavlosMelissinos/enet-keras</a> (Keras)</li></ul></li><li>LinkNet (<a href="https://arxiv.org/pdf/1707.03718.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1707.03718.pdf</a>)<ul><li><a href="https://github.com/e-lab/LinkNet" target="_blank" rel="noopener">https://github.com/e-lab/LinkNet</a> (Torch)</li></ul></li><li>DenseNet (<a href="https://arxiv.org/pdf/1608.06993.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1608.06993.pdf</a>)<ul><li><a href="https://github.com/flyyufelix/DenseNet-Keras" target="_blank" rel="noopener">https://github.com/flyyufelix/DenseNet-Keras</a> (Keras)</li></ul></li><li>Tiramisu (<a href="https://arxiv.org/pdf/1611.09326.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.09326.pdf</a>)<ul><li><a href="https://github.com/0bserver07/One-Hundred-Layers-Tiramisu" target="_blank" rel="noopener">https://github.com/0bserver07/One-Hundred-Layers-Tiramisu</a> (Keras)</li><li><a href="https://github.com/SimJeg/FC-DenseNet" target="_blank" rel="noopener">https://github.com/SimJeg/FC-DenseNet</a> (Lasagne)</li></ul></li><li>DilatedNet (<a href="https://arxiv.org/pdf/1511.07122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.07122.pdf</a>)<ul><li><a href="https://github.com/nicolov/segmentation_keras" target="_blank" rel="noopener">https://github.com/nicolov/segmentation_keras</a> (Keras)</li></ul></li><li>PixelNet (<a href="https://arxiv.org/pdf/1609.06694.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1609.06694.pdf</a>)<ul><li><a href="https://github.com/aayushbansal/PixelNet" target="_blank" rel="noopener">https://github.com/aayushbansal/PixelNet</a> (Caffe)</li></ul></li><li>ICNet (<a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1704.08545.pdf</a>)<ul><li><a href="https://github.com/hszhao/ICNet" target="_blank" rel="noopener">https://github.com/hszhao/ICNet</a> (Caffe)</li></ul></li><li>ERFNet (<a href="http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera17iv.pdf" target="_blank" rel="noopener">http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera17iv.pdf</a>)<ul><li><a href="https://github.com/Eromera/erfnet" target="_blank" rel="noopener">https://github.com/Eromera/erfnet</a> (Torch)</li></ul></li><li>RefineNet (<a href="https://arxiv.org/pdf/1611.06612.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.06612.pdf</a>)<ul><li><a href="https://github.com/guosheng/refinenet" target="_blank" rel="noopener">https://github.com/guosheng/refinenet</a> (MatConvNet)</li></ul></li><li>PSPNet (<a href="https://arxiv.org/pdf/1612.01105.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1612.01105.pdf</a>)<ul><li><a href="https://github.com/hszhao/PSPNet" target="_blank" rel="noopener">https://github.com/hszhao/PSPNet</a> (Caffe)</li><li><a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation" target="_blank" rel="noopener">https://github.com/ZijunDeng/pytorch-semantic-segmentation</a> (PyTorch)</li><li><a href="https://github.com/mitmul/chainer-pspnet" target="_blank" rel="noopener">https://github.com/mitmul/chainer-pspnet</a> (Chainer)</li><li><a href="https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow(Keras/Tensorflow" target="_blank" rel="noopener">https://github.com/Vladkryvoruchko/PSPNet-Keras-tensorflow(Keras/Tensorflow</a>)</li><li><a href="https://github.com/pudae/tensorflow-pspnet" target="_blank" rel="noopener">https://github.com/pudae/tensorflow-pspnet</a> (Tensorflow)</li></ul></li><li>CRFasRNN (<a href="http://www.robots.ox.ac.uk/%7Eszheng/papers/CRFasRNN.pdf" target="_blank" rel="noopener">http://www.robots.ox.ac.uk/%7Eszheng/papers/CRFasRNN.pdf</a>)<ul><li><a href="https://github.com/torrvision/crfasrnn" target="_blank" rel="noopener">https://github.com/torrvision/crfasrnn</a> (Caffe)</li><li><a href="https://github.com/sadeepj/crfasrnn_keras" target="_blank" rel="noopener">https://github.com/sadeepj/crfasrnn_keras</a> (Keras)</li></ul></li><li>Dilated convolution (<a href="https://arxiv.org/pdf/1511.07122.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.07122.pdf</a>)<ul><li><a href="https://github.com/fyu/dilation" target="_blank" rel="noopener">https://github.com/fyu/dilation</a> (Caffe)</li><li><a href="https://github.com/fyu/drn#semantic-image-segmentataion" target="_blank" rel="noopener">https://github.com/fyu/drn#semantic-image-segmentataion</a> (PyTorch)</li><li><a href="https://github.com/hangzhaomit/semantic-segmentation-pytorch" target="_blank" rel="noopener">https://github.com/hangzhaomit/semantic-segmentation-pytorch</a> (PyTorch)</li></ul></li><li>DeconvNet (<a href="https://arxiv.org/pdf/1505.04366.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1505.04366.pdf</a>)<ul><li><a href="http://cvlab.postech.ac.kr/research/deconvnet/" target="_blank" rel="noopener">http://cvlab.postech.ac.kr/research/deconvnet/</a> (Caffe)</li><li><a href="https://github.com/HyeonwooNoh/DeconvNet" target="_blank" rel="noopener">https://github.com/HyeonwooNoh/DeconvNet</a> (Caffe)</li><li><a href="https://github.com/fabianbormann/Tensorflow-DeconvNet-Segmentation(Tensorflow" target="_blank" rel="noopener">https://github.com/fabianbormann/Tensorflow-DeconvNet-Segmentation(Tensorflow</a>)</li></ul></li><li>FRRN (<a href="https://arxiv.org/pdf/1611.08323.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.08323.pdf</a>)<ul><li><a href="https://github.com/TobyPDE/FRRN" target="_blank" rel="noopener">https://github.com/TobyPDE/FRRN</a> (Lasagne)</li></ul></li><li>GCN (<a href="https://arxiv.org/pdf/1703.02719.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.02719.pdf</a>)<ul><li><a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation" target="_blank" rel="noopener">https://github.com/ZijunDeng/pytorch-semantic-segmentation</a> (PyTorch)</li><li><a href="https://github.com/ycszen/pytorch-seg" target="_blank" rel="noopener">https://github.com/ycszen/pytorch-seg</a> (PyTorch)</li></ul></li><li>DUC, HDC (<a href="https://arxiv.org/pdf/1702.08502.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1702.08502.pdf</a>)<ul><li><a href="https://github.com/ZijunDeng/pytorch-semantic-segmentation" target="_blank" rel="noopener">https://github.com/ZijunDeng/pytorch-semantic-segmentation</a> (PyTorch)</li><li><a href="https://github.com/ycszen/pytorch-seg" target="_blank" rel="noopener">https://github.com/ycszen/pytorch-seg</a> (PyTorch)</li></ul></li><li>Segaware (<a href="https://arxiv.org/pdf/1708.04607.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1708.04607.pdf</a>)<ul><li><a href="https://github.com/aharley/segaware" target="_blank" rel="noopener">https://github.com/aharley/segaware</a> (Caffe)</li></ul></li><li>Semantic Segmentation using Adversarial Networks (<a href="https://arxiv.org/pdf/1611.08408.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.08408.pdf</a>)<ul><li><a href="https://github.com/oyam/Semantic-Segmentation-using-Adversarial-Networks" target="_blank" rel="noopener">https://github.com/oyam/Semantic-Segmentation-using-Adversarial-Networks</a> (Chainer)</li></ul></li></ol><h4 id="Instance-aware-segmentation"><a href="#Instance-aware-segmentation" class="headerlink" title="Instance aware segmentation"></a>Instance aware segmentation</h4><ol><li>FCIS [<a href="https://arxiv.org/pdf/1611.07709.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.07709.pdf</a>]<ul><li><a href="https://github.com/msracver/FCIS" target="_blank" rel="noopener">https://github.com/msracver/FCIS</a> [MxNet]</li></ul></li><li>MNC [<a href="https://arxiv.org/pdf/1512.04412.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1512.04412.pdf</a>]<ul><li><a href="https://github.com/daijifeng001/MNC" target="_blank" rel="noopener">https://github.com/daijifeng001/MNC</a> [Caffe]</li></ul></li><li>DeepMask [<a href="https://arxiv.org/pdf/1506.06204.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.06204.pdf</a>]<ul><li><a href="https://github.com/facebookresearch/deepmask" target="_blank" rel="noopener">https://github.com/facebookresearch/deepmask</a> [Torch]</li></ul></li><li>SharpMask [<a href="https://arxiv.org/pdf/1603.08695.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1603.08695.pdf</a>]<ul><li><a href="https://github.com/facebookresearch/deepmask" target="_blank" rel="noopener">https://github.com/facebookresearch/deepmask</a> [Torch]</li></ul></li><li>Mask-RCNN [<a href="https://arxiv.org/pdf/1703.06870.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.06870.pdf</a>]<ul><li><a href="https://github.com/CharlesShang/FastMaskRCNN" target="_blank" rel="noopener">https://github.com/CharlesShang/FastMaskRCNN</a> [Tensorflow]</li><li><a href="https://github.com/jasjeetIM/Mask-RCNN" target="_blank" rel="noopener">https://github.com/jasjeetIM/Mask-RCNN</a> [Caffe]</li><li><a href="https://github.com/TuSimple/mx-maskrcnn" target="_blank" rel="noopener">https://github.com/TuSimple/mx-maskrcnn</a> [MxNet]</li><li><a href="https://github.com/matterport/Mask_RCNN" target="_blank" rel="noopener">https://github.com/matterport/Mask_RCNN</a> [Keras]</li></ul></li><li>RIS [<a href="https://arxiv.org/pdf/1511.08250.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1511.08250.pdf</a>]<ul><li><a href="https://github.com/bernard24/RIS" target="_blank" rel="noopener">https://github.com/bernard24/RIS</a> [Torch]</li></ul></li><li>FastMask [<a href="https://arxiv.org/pdf/1612.08843.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1612.08843.pdf</a>]<ul><li><a href="https://github.com/voidrank/FastMask" target="_blank" rel="noopener">https://github.com/voidrank/FastMask</a> [Caffe]</li></ul></li></ol><h4 id="Satellite-images-segmentation"><a href="#Satellite-images-segmentation" class="headerlink" title="Satellite images segmentation"></a>Satellite images segmentation</h4><ul><li><a href="https://github.com/mshivaprakash/sat-seg-thesis" target="_blank" rel="noopener">https://github.com/mshivaprakash/sat-seg-thesis</a></li><li><a href="https://github.com/KGPML/Hyperspectral" target="_blank" rel="noopener">https://github.com/KGPML/Hyperspectral</a></li><li><a href="https://github.com/lopuhin/kaggle-dstl" target="_blank" rel="noopener">https://github.com/lopuhin/kaggle-dstl</a></li><li><a href="https://github.com/mitmul/ssai" target="_blank" rel="noopener">https://github.com/mitmul/ssai</a></li><li><a href="https://github.com/mitmul/ssai-cnn" target="_blank" rel="noopener">https://github.com/mitmul/ssai-cnn</a></li><li><a href="https://github.com/azavea/raster-vision" target="_blank" rel="noopener">https://github.com/azavea/raster-vision</a></li><li><a href="https://github.com/nshaud/DeepNetsForEO" target="_blank" rel="noopener">https://github.com/nshaud/DeepNetsForEO</a></li><li><a href="https://github.com/trailbehind/DeepOSM" target="_blank" rel="noopener">https://github.com/trailbehind/DeepOSM</a></li></ul><h4 id="Video-segmentation"><a href="#Video-segmentation" class="headerlink" title="Video segmentation"></a>Video segmentation</h4><ul><li><a href="https://github.com/shelhamer/clockwork-fcn" target="_blank" rel="noopener">https://github.com/shelhamer/clockwork-fcn</a></li><li><a href="https://github.com/JingchunCheng/Seg-with-SPN" target="_blank" rel="noopener">https://github.com/JingchunCheng/Seg-with-SPN</a></li></ul><h4 id="Autonomous-driving"><a href="#Autonomous-driving" class="headerlink" title="Autonomous driving"></a>Autonomous driving</h4><ul><li><a href="https://github.com/MarvinTeichmann/MultiNet" target="_blank" rel="noopener">https://github.com/MarvinTeichmann/MultiNet</a></li><li><a href="https://github.com/MarvinTeichmann/KittiSeg" target="_blank" rel="noopener">https://github.com/MarvinTeichmann/KittiSeg</a></li><li><a href="https://github.com/vxy10/p5_VehicleDetection_Unet" target="_blank" rel="noopener">https://github.com/vxy10/p5_VehicleDetection_Unet</a> [Keras]</li><li><a href="https://github.com/ndrplz/self-driving-car" target="_blank" rel="noopener">https://github.com/ndrplz/self-driving-car</a></li><li><a href="https://github.com/mvirgo/MLND-Capstone" target="_blank" rel="noopener">https://github.com/mvirgo/MLND-Capstone</a></li></ul><h4 id="Annotation-Tools"><a href="#Annotation-Tools" class="headerlink" title="Annotation Tools:"></a>Annotation Tools:</h4><ul><li><a href="https://github.com/AKSHAYUBHAT/ImageSegmentation" target="_blank" rel="noopener">https://github.com/AKSHAYUBHAT/ImageSegmentation</a></li><li><a href="https://github.com/kyamagu/js-segment-annotator" target="_blank" rel="noopener">https://github.com/kyamagu/js-segment-annotator</a></li><li><a href="https://github.com/CSAILVision/LabelMeAnnotationTool" target="_blank" rel="noopener">https://github.com/CSAILVision/LabelMeAnnotationTool</a></li><li><a href="https://github.com/seanbell/opensurfaces-segmentation-ui" target="_blank" rel="noopener">https://github.com/seanbell/opensurfaces-segmentation-ui</a></li><li><a href="https://github.com/lzx1413/labelImgPlus" target="_blank" rel="noopener">https://github.com/lzx1413/labelImgPlus</a></li><li><a href="https://github.com/wkentaro/labelme" target="_blank" rel="noopener">https://github.com/wkentaro/labelme</a></li></ul><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><ol><li>Stanford Background Dataset[<a href="http://dags.stanford.edu/projects/scenedataset.html" target="_blank" rel="noopener">http://dags.stanford.edu/projects/scenedataset.html</a>]</li><li>Sift Flow Dataset[<a href="http://people.csail.mit.edu/celiu/SIFTflow/" target="_blank" rel="noopener">http://people.csail.mit.edu/celiu/SIFTflow/</a>]</li><li>Barcelona Dataset[<a href="http://www.cs.unc.edu/~jtighe/Papers/ECCV10/" target="_blank" rel="noopener">http://www.cs.unc.edu/~jtighe/Papers/ECCV10/</a>]</li><li>Microsoft COCO dataset[<a href="http://mscoco.org/" target="_blank" rel="noopener">http://mscoco.org/</a>]</li><li>MSRC Dataset[<a href="http://research.microsoft.com/en-us/projects/objectclassrecognition/" target="_blank" rel="noopener">http://research.microsoft.com/en-us/projects/objectclassrecognition/</a>]</li><li>LITS Liver Tumor Segmentation Dataset[<a href="https://competitions.codalab.org/competitions/15595" target="_blank" rel="noopener">https://competitions.codalab.org/competitions/15595</a>]</li><li>KITTI[<a href="http://www.cvlibs.net/datasets/kitti/eval_road.php" target="_blank" rel="noopener">http://www.cvlibs.net/datasets/kitti/eval_road.php</a>]</li><li>Stanford background dataset[<a href="http://dags.stanford.edu/projects/scenedataset.html" target="_blank" rel="noopener">http://dags.stanford.edu/projects/scenedataset.html</a>]</li><li>Data from Games dataset[<a href="https://download.visinf.tu-darmstadt.de/data/from_games/" target="_blank" rel="noopener">https://download.visinf.tu-darmstadt.de/data/from_games/</a>]</li><li>Human parsing dataset[<a href="https://github.com/lemondan/HumanParsing-Dataset" target="_blank" rel="noopener">https://github.com/lemondan/HumanParsing-Dataset</a>]</li><li>Silenko person database[<a href="https://github.com/Maxfashko/CamVid" target="_blank" rel="noopener">https://github.com/Maxfashko/CamVid</a>]</li><li>Mapillary Vistas Dataset[<a href="https://www.mapillary.com/dataset/vistas" target="_blank" rel="noopener">https://www.mapillary.com/dataset/vistas</a>]</li><li>Microsoft AirSim[<a href="https://github.com/Microsoft/AirSim" target="_blank" rel="noopener">https://github.com/Microsoft/AirSim</a>]</li><li>MIT Scene Parsing Benchmark[<a href="http://sceneparsing.csail.mit.edu/" target="_blank" rel="noopener">http://sceneparsing.csail.mit.edu/</a>]</li><li>COCO 2017 Stuff Segmentation Challenge[<a href="http://cocodataset.org/#stuff-challenge2017" target="_blank" rel="noopener">http://cocodataset.org/#stuff-challenge2017</a>]</li><li>ADE20K Dataset[<a href="http://groups.csail.mit.edu/vision/datasets/ADE20K/" target="_blank" rel="noopener">http://groups.csail.mit.edu/vision/datasets/ADE20K/</a>]</li><li>INRIA Annotations for Graz-02[<a href="http://lear.inrialpes.fr/people/marszalek/data/ig02/" target="_blank" rel="noopener">http://lear.inrialpes.fr/people/marszalek/data/ig02/</a>]</li></ol><h3 id="比赛"><a href="#比赛" class="headerlink" title="比赛"></a>比赛</h3><ol><li>MSRC-21 [<a href="http://rodrigob.github.io/are_we_there_yet/build/semantic_labeling_datasets_results.html" target="_blank" rel="noopener">http://rodrigob.github.io/are_we_there_yet/build/semantic_labeling_datasets_results.html</a>]</li><li>Cityscapes [<a href="https://www.cityscapes-dataset.com/benchmarks/" target="_blank" rel="noopener">https://www.cityscapes-dataset.com/benchmarks/</a>]</li><li>VOC2012 [<a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6" target="_blank" rel="noopener">http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6</a>]</li></ol><h3 id="领域专家"><a href="#领域专家" class="headerlink" title="领域专家"></a>领域专家</h3><ol><li>Jonathan Long<ul><li>[<a href="http://people.eecs.berkeley.edu/~jonlong/" target="_blank" rel="noopener">http://people.eecs.berkeley.edu/~jonlong/</a>]</li></ul></li><li>Liang-Chieh Chen<ul><li>[<a href="http://liangchiehchen.com/" target="_blank" rel="noopener">http://liangchiehchen.com/</a>]</li></ul></li><li>Hyeonwoo Noh<ul><li>[<a href="http://cvlab.postech.ac.kr/~hyeonwoonoh/" target="_blank" rel="noopener">http://cvlab.postech.ac.kr/~hyeonwoonoh/</a>]</li></ul></li><li>Bharath Hariharan<ul><li>[<a href="http://home.bharathh.info/" target="_blank" rel="noopener">http://home.bharathh.info/</a>]</li></ul></li><li>Fisher Yu<ul><li>[<a href="http://www.yf.io/" target="_blank" rel="noopener">http://www.yf.io/</a>]</li></ul></li><li>Vijay Badrinarayanan<ul><li>[<a href="https://sites.google.com/site/vijaybacademichomepage/home/papers" target="_blank" rel="noopener">https://sites.google.com/site/vijaybacademichomepage/home/papers</a>]</li></ul></li><li>Guosheng Lin<ul><li>[<a href="https://sites.google.com/site/guoshenglin/" target="_blank" rel="noopener">https://sites.google.com/site/guoshenglin/</a>]</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow总结</title>
      <link href="/2019/05/22/TensorFlow%E6%80%BB%E7%BB%93/"/>
      <url>/2019/05/22/TensorFlow%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="1-综述"><a href="#1-综述" class="headerlink" title="1 综述"></a>1 综述</h2><p>• 使用图 (graph) 来表示计算任务.<br>• 在被称之为会话（Session）的上下文 (context) 中执行图.<br>• 使用 tensor 表示数据.<br>• 通过变量（Variable）维护状态.<br>• 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</p><p>一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在Session里被启动. 将图的 op 分发到诸如 CPU 或 GPU 之类的设备上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray对象; 在 C 和 C++ 语言中, 返回的 tensor 是tensorflow::Tensor 实例. </p><h2 id="2-基本概念"><a href="#2-基本概念" class="headerlink" title="2 基本概念"></a>2 基本概念</h2><h3 id="2-1-计算图"><a href="#2-1-计算图" class="headerlink" title="2.1 计算图"></a>2.1 计算图</h3><p>TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op.</p><h4 id="2-1-1-构建图"><a href="#2-1-1-构建图" class="headerlink" title="2.1.1 构建图"></a>2.1.1 构建图</h4><p>构建图的第一步, 是创建源 op (source op). 源 op 不需要任何输入, 例如 常量 (Constant) . 源 op 的输出被传递给其它 op 做运算.</p><p>为了真正进行运算, 并得到运算的结果, 你必须在会话里启动这个图.</p><h4 id="2-1-2-在一个会话中启动图"><a href="#2-1-2-在一个会话中启动图" class="headerlink" title="2.1.2 在一个会话中启动图"></a>2.1.2 在一个会话中启动图</h4><p>构造阶段完成后, 才能启动图. 启动图的第一步是创建一个 Session 对象, 如果无任何创建参数, 会话构造器将启动默认图.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line"># 整个执行过程是自动化的, 会话负责传递 op 所需的全部输入. op 通常是并发执行的.</span><br><span class="line">result = sess.run(op)</span><br><span class="line">print result</span><br><span class="line"># ==&gt; [[ 12.]]</span><br><span class="line"># 任务完成, 关闭会话.</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure><p>Session 对象在使用完后需要关闭以释放资源. 除了显式调用 close 外, 也可以使用 “with” 代码块 来自动完成关闭动作.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">  result = sess.run([product])</span><br><span class="line">  print result</span><br></pre></td></tr></table></figure><p>在实现上, TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU). 一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测. 如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作.</p><p>如果机器上有超过一个可用的 GPU, 除第一个外的其它 GPU 默认是不参与计算的. 为了让 TensorFlow 使用这些GPU, 你必须将 op 明确指派给它们执行.<code>with…Device</code> 语句用来指派特定的 CPU 或 GPU 执行操作:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">  with tf.device(&quot;/gpu:1&quot;):</span><br><span class="line">    matrix1 = tf.constant([[3., 3.]])</span><br><span class="line">    matrix2 = tf.constant([[2.],[2.]])</span><br><span class="line">    product = tf.matmul(matrix1, matrix2)</span><br><span class="line">    ..</span><br></pre></td></tr></table></figure><p>设备用字符串进行标识. 目前支持的设备包括: </p><ul><li>“/cpu:0” : 机器的 CPU. </li><li>“/gpu:0” : 机器的第一个 GPU, 如果有的话. </li><li>“/gpu:1” : 机器的第二个 GPU, 以此类推. </li></ul><h3 id="2-2-Tensor"><a href="#2-2-Tensor" class="headerlink" title="2.2 Tensor"></a>2.2 Tensor</h3><p>TensorFlow 程序使用 tensor 数据结构来代表所有的数据, 计算图中, 操作间传递的数据都是 tensor. 你可以把 TensorFlow tensor 看作是一个 n 维的数组或列表. 一个 tensor 包含一个静态类型 rank, 和 一个 shape.</p><h3 id="2-3-变量"><a href="#2-3-变量" class="headerlink" title="2.3 变量"></a>2.3 变量</h3><p>变量维护图执行过程中的状态信息.通常会将一个统计模型中的参数表示为一组变量. 例如, 你可以将一个神经网络的权重作为某个变量存储在一个tensor 中. 在训练过程中, 通过重复运行训练图, 更新这个 tensor.</p><h3 id="2-4-Fetch"><a href="#2-4-Fetch" class="headerlink" title="2.4 Fetch"></a>2.4 Fetch</h3><p>为了取回操作的输出内容, 可以在使用 Session 对象的 <code>run()</code>调用 执行图时, 传入一些 tensor, 这些 tensor 会帮助你取回结果. 在之前的例子里, 我们只取回了单个节点 state , 但是你也可以取回多个 tensor。需要获取的多个 tensor 值，在 op 的一次运行中一起获得(而不是逐个去获取 tensor)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = sess.run([mul, intermed])</span><br></pre></td></tr></table></figure><h3 id="2-5-Feed"><a href="#2-5-Feed" class="headerlink" title="2.5 Feed"></a>2.5 Feed</h3><p>上述示例在计算图中引入了 tensor, 以常量或变量的形式存储. TensorFlow 还提供了 feed 机制, 该机制 可以 临时替代图中的任意操作中的 tensor 可以对图中任何操作提交补丁, 直接插入一个 tensor. </p><p>feed 使用一个 tensor 值临时替换一个操作的输出结果. 你可以提供 feed 数据作为 <code>run()</code>调用的参数. feed 只在调用它的方法内有效, 方法结束, feed 就会消失. 最常见的用例是将某些特殊的操作指定为 “feed” 操作, 标记的方法是使用 <code>tf.placeholder()</code>为这些操作创建占位符. </p><h2 id="3-运作方式"><a href="#3-运作方式" class="headerlink" title="3 运作方式"></a>3 运作方式</h2><h3 id="3-1-变量：创建、初始化、保存和加载"><a href="#3-1-变量：创建、初始化、保存和加载" class="headerlink" title="3.1 变量：创建、初始化、保存和加载"></a>3.1 变量：创建、初始化、保存和加载</h3><p>当训练模型时，用变量来存储和更新参数。变量包含张量 (Tensor)存放于内存的缓存区。建模时它们需要被明确地初始化，模型训练后它们必须被存储到磁盘。这些变量的值可在之后模型训练和分析是被加载。</p><h4 id="3-1-1-创建"><a href="#3-1-1-创建" class="headerlink" title="3.1.1 创建"></a>3.1.1 创建</h4><p>当创建一个变量时，你将一个 张量 作为初始值传入构造函数 <code>Variable()</code>。TensorFlow提供了一系列操作符来初始化张量，初始值是常量或是随机值。</p><p>注意，所有这些操作符都需要你指定张量的shape。那个形状自动成为变量的shape。变量的shape通常是固定的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> # Create two variables.</span><br><span class="line">weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),</span><br><span class="line">                      name=&quot;weights&quot;)</span><br><span class="line">biases = tf.Variable(tf.zeros([200]), name=&quot;biases&quot;)</span><br></pre></td></tr></table></figure><p>调用<code>tf.Variable()</code>添加一些操作<code>(Op, operation)</code>到graph: </p><p>• 一个 操作存放变量的值。<br>• 一个初始化op将变量设置为初始值。这事实上是一个 操作.<br>• 初始值的操作，例如示例中对 变量的 操作也被加入了graph。 </p><p><code>tf.Variable()</code>的返回值是Python的 类的一个实例。 </p><h4 id="3-1-2-初始化"><a href="#3-1-2-初始化" class="headerlink" title="3.1.2 初始化"></a>3.1.2 初始化</h4><p>变量的初始化必须在模型的其它操作运行之前先明确地完成。最简单的方法就是添加一个给所有变量初始化的操作，并在使用模型之前首先运行那个操作。</p><p>使用 <code>tf.initialize_all_variables()</code>添加一个操作对变量做初始化。记得在完全构建好模型并加载之后再运行那个操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> # Create two variables.</span><br><span class="line">weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),</span><br><span class="line">                      name=&quot;weights&quot;)</span><br><span class="line">biases = tf.Variable(tf.zeros([200]), name=&quot;biases&quot;)</span><br><span class="line">...</span><br><span class="line"> # Add an op to initialize the variables.</span><br><span class="line">init_op = tf.initialize_all_variables()</span><br><span class="line"> # Later, when launching the model</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  # Run the init operation.</span><br><span class="line">  sess.run(init_op)</span><br><span class="line">  ...</span><br><span class="line">  # Use the model</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p><strong>由另一个变量初始化</strong></p><p>你有时候会需要用另一个变量的初始化值给当前变量初始化。由于<code>tf.initialize_all_variables()</code>是并行地初始 化所有变量，所以在有这种需求的情况下需要小心。 </p><p>用其它变量的值初始化一个新的变量时，使用其它变量的<code>initialized_value()</code>属性。你可以直接把已初始化的值作为新变量的初始值，或者把它当做tensor计算得到一个值赋予新变量。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> # Create a variable with a random value.</span><br><span class="line">weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),</span><br><span class="line">                      name=&quot;weights&quot;)</span><br><span class="line"> # Create another variable with the same value as &apos;weights&apos;.</span><br><span class="line">w2 = tf.Variable(weights.initialized_value(), name=&quot;w2&quot;)</span><br><span class="line"> # Create another variable with twice the value of &apos;weights&apos;</span><br><span class="line">w_twice = tf.Variable(weights.initialized_value() * 0.2, name=&quot;w_twice&quot;)</span><br></pre></td></tr></table></figure><p><strong>自定义初始化</strong></p><p><code>tf.initialize_all_variables()</code> 函数便捷地添加一个op来初始化模型的所有变量。你也可以给它传入一组变量进行初始化。</p><h4 id="3-1-3-保存和加载"><a href="#3-1-3-保存和加载" class="headerlink" title="3.1.3 保存和加载"></a>3.1.3 保存和加载</h4><p>最简单的保存和恢复模型的方法是使用 tf.train.Saver 对象。构造器给graph的所有变量，或是定义在列表里的变量，添加 save 和 restore ops。saver对象提供了方法来运行这些ops，定义检查点文件的读写路径。 </p><p><strong>检查点文件ckpt</strong></p><p>变量存储在二进制文件里，主要包含从变量名到tensor值的映射关系。</p><p>当你创建一个 Saver 对象时，你可以选择性地为检查点文件中的变量挑选变量名。</p><p><strong>保存变量</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> # Create some variables.</span><br><span class="line">v1 = tf.Variable(..., name=&quot;v1&quot;)</span><br><span class="line">v2 = tf.Variable(..., name=&quot;v2&quot;)</span><br><span class="line">...</span><br><span class="line"> # Add an op to initialize the variables.</span><br><span class="line">init_op = tf.initialize_all_variables()</span><br><span class="line"> # Add ops to save and restore all the variables.</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"> # Later, launch the model, initialize the variables, do some work, save the</span><br><span class="line"> # variables to disk.</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  sess.run(init_op)</span><br><span class="line">  # Do some work with the model.</span><br><span class="line">  ..</span><br><span class="line">  # Save the variables to disk.</span><br><span class="line">  save_path = saver.save(sess, &quot;/tmp/model.ckpt&quot;)</span><br><span class="line">  print &quot;Model saved in file: &quot;, save_path</span><br></pre></td></tr></table></figure><p><strong>恢复变量</strong></p><p>用同一个 Saver 对象来恢复变量。<strong>注意，当你从文件中恢复变量时，不需要事先对它们做初始化。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> # Create some variables.</span><br><span class="line">v1 = tf.Variable(..., name=&quot;v1&quot;)</span><br><span class="line">v2 = tf.Variable(..., name=&quot;v2&quot;)</span><br><span class="line">...</span><br><span class="line"> # Add ops to save and restore all the variables.</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"> # Later, launch the model, use the saver to restore variables from disk, and</span><br><span class="line"> # do some work with the model.</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  # Restore variables from disk.</span><br><span class="line">  saver.restore(sess, &quot;/tmp/model.ckpt&quot;)</span><br><span class="line">  print &quot;Model restored.&quot;</span><br><span class="line">  # Do some work with the model</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p><strong>选择存储和恢复哪些变量</strong></p><p>如果你不给 tf.train.Saver() 传入任何参数，那么saver将处理graph中的所有变量。其中每一个变量都以变量创 建时传入的名称被保存。 </p><p>有时候在检查点文件中明确定义变量的名称很有用。举个例子，你也许已经训练得到了一个模型，其中有个变量 命名为 “weights” ，你想把它的值恢复到一个新的变量 “params” 中。 </p><p>有时候仅保存和恢复模型的一部分变量很有用。再举个例子，你也许训练得到了一个5层神经网络，现在想训练一 个6层的新模型，可以将之前5层模型的参数导入到新模型的前5层中。 </p><p>你可以通过给 tf.train.Saver() 构造函数传入Python字典，很容易地定义需要保持的变量及对应名称:键对应使 用的名称，值对应被管理的变量。 </p><h3 id="3-2-TensorBoard：可视化学习"><a href="#3-2-TensorBoard：可视化学习" class="headerlink" title="3.2 TensorBoard：可视化学习"></a>3.2 TensorBoard：可视化学习</h3><h4 id="3-2-1-数据序列化"><a href="#3-2-1-数据序列化" class="headerlink" title="3.2.1 数据序列化"></a>3.2.1 数据序列化</h4><p>TensorBoard 通过读取 TensorFlow 的事件文件来运行。TensorFlow 的事件文件包括了你会在 TensorFlow 运行中涉及到的主要数据。下面是 TensorBoard 中汇总数据(Summary data)的大体生命周期。</p><p>首先，创建你想汇总数据的 TensorFlow 图，然后再选择你想在哪个节点进行汇总(summary)操作。</p><p>比如，假设你正在训练一个卷积神经网络，用于识别 MNISt 标签。你可能希望记录学习速度(learning rate)如何变化，以及目标函数如何变化。通过向节点附加scalar_summary操作来分别输出学习速度和期望误差。然后你可以给每个 scalary_summary 分配一个有意义的 标签 ，比如 ‘learning rate’ 和 ‘loss function’ 。或者你还希望显示一个特殊层中激活的分布，或者梯度权重的分布。可以通过分别附加 histogram_summary 运算来收集权重变量和梯度输出。</p><p>在TensorFlow中，所有的操作只有当你执行，或者另一个操作依赖于它的输出时才会运行。我们刚才创建的这些 节点(summary nodes)都围绕着你的图像:没有任何操作依赖于它们的结果。因此，为了生成汇总信息，我们需 要运行所有这些节点。这样的手动工作是很乏味的，因此可以使用<code>tf.merge_all_summaries</code>来将他们合并为一个操作。 </p><p>然后你可以执行合并命令，它会依据特点步骤将所有数据生成一个序列化的Summary protobuf对象。最后，为了 将汇总数据写入磁盘，需要将汇总的protobuf对象传递给<code>tf.train.Summarywriter</code>。 </p><p>SummaryWriter 的构造函数中包含了参数 logdir。这个 logdir 非常重要，所有事件都会写到它所指的目录 下。此外， SummaryWriter 中还包含了一个可选择的参数 GraphDef 。如果输入了该参数，那么 TensorBoard 也会显示你的图像。 </p><p>现在已经修改了你的图，也有了 SummaryWriter ，现在就可以运行你的神经网络了!如果你愿意的话，你可以每 一步执行一次合并汇总，这样你会得到一大堆训练数据。这很有可能超过了你想要的数据量。你也可以每一百步 执行一次合并汇总，或者如下面代码里示范的这样。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">merged_summary_op = tf.merge_all_summaries()</span><br><span class="line">summary_writer = tf.train.SummaryWriter(&apos;/tmp/mnist_logs&apos;, sess.graph)</span><br><span class="line">total_step = 0</span><br><span class="line">while training:</span><br><span class="line">  total_step += 1</span><br><span class="line">  session.run(training_op)</span><br><span class="line">  if total_step % 100 == 0:</span><br><span class="line">    summary_str = session.run(merged_summary_op)</span><br><span class="line">    summary_writer.add_summary(summary_str, total_step)</span><br></pre></td></tr></table></figure><p>现在已经准备好用 TensorBoard 来可视化这些数据了。</p><h4 id="3-2-2-启动TensorBoard"><a href="#3-2-2-启动TensorBoard" class="headerlink" title="3.2.2 启动TensorBoard"></a>3.2.2 启动TensorBoard</h4><p>在terminal中输入下面命令（log文件地址需填写准确）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=/path/to/log-directory</span><br></pre></td></tr></table></figure><h4 id="3-2-3-名称域（Name-Scoping）和节点（Node）"><a href="#3-2-3-名称域（Name-Scoping）和节点（Node）" class="headerlink" title="3.2.3 名称域（Name Scoping）和节点（Node）"></a>3.2.3 名称域（Name Scoping）和节点（Node）</h4><p>典型的 TensorFlow 可以有数以千计的节点，如此多而难以一下全部看到，甚至无法使用标准图表工具来展示。为简单起见，我们为变量名划定范围，并且可视化把该信息用于在图表中的节点上定义一个层级。默认情况下， 只有顶层节点会显示。下面这个例子使用 <code>tf.name_scope</code>在 <code>hidden</code> 命名域下定义了三个操作:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">with tf.name_scope(&apos;hidden&apos;) as scope:</span><br><span class="line">  a = tf.constant(5, name=&apos;alpha&apos;)</span><br><span class="line">  W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0), name=&apos;weights&apos;)</span><br><span class="line">  b = tf.Variable(tf.zeros([1]), name=&apos;biases&apos;)</span><br></pre></td></tr></table></figure><p>结果是得到了下面三个操作名: </p><p>• hidden/alpha<br>• hidden/weights<br>• hidden/biases </p><p>默认地，三个操作名会折叠为一个节点并标注为 hidden 。其额外细节并没有丢失，你可以双击，或点击右上方橙 色的 + 来展开节点，然后就会看到三个子节点 alpha ， weights 和 biases 了。 </p><p><img src="graph.png" alt></p><p>通过名称域把节点分组来得到可读性高的图表很关键的。如果你在构建一个模型，名称域就可以用来控制可视化结果。你的名称域越好，可视性就越好。 </p><p>TensorFlow 图表有两种连接关系:数据依赖和控制依赖。数据依赖显示两个操作之间tensor流程，用实心箭头指示，而控制依赖用点线表示。</p><h3 id="3-3-使用GPUs"><a href="#3-3-使用GPUs" class="headerlink" title="3.3 使用GPUs"></a>3.3 使用GPUs</h3><h4 id="3-3-1-支持的设备"><a href="#3-3-1-支持的设备" class="headerlink" title="3.3.1 支持的设备"></a>3.3.1 支持的设备</h4><p>在一套标准的系统上通常有多个计算设备. TensorFlow 支持 CPU 和 GPU 这两种设备. 我们用指定字符串来标识这些设备. 比如: </p><ul><li>“/cpu:0” : 机器中的 CPU </li><li>“/gpu:0” : 机器中的 GPU, 如果你有一个的话. </li><li>“/gpu:1” : 机器中的第二个 GPU, 以此类推… </li></ul><p>如果一个 TensorFlow 的 operation 中兼有 CPU 和 GPU 的实现, 当这个算子被指派设备时, GPU 有优先权. 比 如 matmul 中 CPU 和 GPU kernel 函数都存在. 那么在 cpu:0 和 gpu:0 中, matmul operation 会被指派给 gpu:0 . </p><h4 id="3-3-2-记录设备指派情况"><a href="#3-3-2-记录设备指派情况" class="headerlink" title="3.3.2 记录设备指派情况"></a>3.3.2 记录设备指派情况</h4><p>为了获取你的 operations 和 Tensor 被指派到哪个设备上运行, 用 log_device_placement 新建一个 session , 并设置为 True . </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 新建一个 graph. </span><br><span class="line">a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)</span><br><span class="line">b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)</span><br><span class="line">c = tf.matmul(a, b)</span><br><span class="line"># 新建session with log_device_placement并设置为True. </span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) </span><br><span class="line"># 运行这个 op. </span><br><span class="line">print sess.run(c)</span><br></pre></td></tr></table></figure><h4 id="3-3-3-手工指派设备"><a href="#3-3-3-手工指派设备" class="headerlink" title="3.3.3 手工指派设备"></a>3.3.3 手工指派设备</h4><p>如果你不想使用系统来为 operation 指派设备, 而是手工指派设备, 你可以用 <code>with tf.device</code>创建一个设备环境, 这个环境下的 operation 都统一运行在环境指定的设备上.</p><p># 新建一个graph. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(&apos;/cpu:0&apos;):</span><br><span class="line">  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)</span><br><span class="line">  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)</span><br><span class="line">c = tf.matmul(a, b)</span><br><span class="line"># 新建session with log_device_placement并设置为True. </span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) </span><br><span class="line"># 运行这个op. </span><br><span class="line">print sess.run(c)</span><br></pre></td></tr></table></figure><p>你会发现现在 a 和 b 操作都被指派给了 <code>cpu:0</code> .</p><h4 id="3-3-4-在多GPU系统里使用单一GPU"><a href="#3-3-4-在多GPU系统里使用单一GPU" class="headerlink" title="3.3.4 在多GPU系统里使用单一GPU"></a>3.3.4 在多GPU系统里使用单一GPU</h4><p>如果你的系统里有多个 GPU, 那么 ID 最小的 GPU 会默认使用. 如果你想用别的 GPU, 可以用下面的方法显式的声明你的偏好:</p><p># 新建一个 graph. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">with tf.device(&apos;/gpu:2&apos;):</span><br><span class="line">  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)</span><br><span class="line">  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)</span><br><span class="line">  c = tf.matmul(a, b)</span><br><span class="line">  # 新建 session with log_device_placement 并设置为 True. </span><br><span class="line">  sess = tf.Session(config=tf.ConfigProto(</span><br><span class="line">      allow_soft_placement=True, log_device_placement=True))</span><br><span class="line">  # 运行这个 op. </span><br><span class="line">  print sess.run(c)</span><br></pre></td></tr></table></figure><h4 id="3-3-5-使用多个GPU"><a href="#3-3-5-使用多个GPU" class="headerlink" title="3.3.5 使用多个GPU"></a>3.3.5 使用多个GPU</h4><p>如果你想让 TensorFlow 在多个 GPU 上运行, 你可以建立 multi-tower 结构, 在这个结构 里每个 tower 分别被指配给不同的 GPU 运行. 比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 新建一个 graph.</span><br><span class="line">c = []</span><br><span class="line">for d in [&apos;/gpu:2&apos;, &apos;/gpu:3&apos;]:</span><br><span class="line">  with tf.device(d):</span><br><span class="line">    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])</span><br><span class="line">    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])</span><br><span class="line">    c.append(tf.matmul(a, b))</span><br><span class="line">with tf.device(&apos;/cpu:0&apos;):</span><br><span class="line">  sum = tf.add_n(c)</span><br><span class="line"># 新建session with log_device_placement并设置为True.</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) </span><br><span class="line"># 运行这个op.</span><br><span class="line">print sess.run(sum)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分割（传统方法）</title>
      <link href="/2019/05/21/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%EF%BC%88%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%89/"/>
      <url>/2019/05/21/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%EF%BC%88%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>本文转自：<a href="https://zhuanlan.zhihu.com/p/30732385" target="_blank" rel="noopener">图像分割 传统方法 整理</a></p><p>图片分割根据灰度、颜色、纹理、和形状等特征将图像进行划分区域，让区域间显差异性，区域内呈相似性。主要分割方法有：</p><ul><li><strong>基于阈值的分割</strong></li><li><strong>基于边缘的分割</strong></li><li><strong>基于区域的分割</strong></li><li><strong>基于图论的分割</strong></li><li><strong>基于能量泛函的分割</strong></li></ul><hr><h2 id="基于阈值的分割方法"><a href="#基于阈值的分割方法" class="headerlink" title="基于阈值的分割方法"></a><strong>基于阈值的分割方法</strong></h2><ul><li>参考： <a href="https://link.zhihu.com/?target=http%3A//www.cnblogs.com/wangduo/p/5556903.html" target="_blank" rel="noopener">基于阈值的图像分割方法</a></li></ul><p>阈值法的基本思想是基于图像的灰度特征来计算一个或多个灰度阈值，并将图像中每个像素的灰度值与阈值相比较，最后将像素根据比较结果分到合适的类别中。因此，该类方法最为关键的一步就是按照某个准则函数来求解最佳灰度阈值。</p><ul><li><p><strong>固定阈值分割</strong>:</p></li><li><ul><li>固定某像素值为分割点。</li></ul></li><li><p><strong>直方图双峰法</strong>：</p></li><li><ul><li>Prewitt 等人于六十年代中期提出的直方图双峰法(也称 mode 法) 是典型的全局单阈值分割方法。该方法的基本思想是：假设图像中有明显的目标和背景，则其灰度直方图呈双峰分布，当灰度级直方图具有双峰特性时，选取两峰之间的谷对应的灰度级作为阈值。如果背景的灰度值在整个图像中可以合理地看作为恒定，而且所有物体与背景都具有几乎相同的对比度，那么，选择一个正确的、固定的全局阈值会有较好的效果.算法实现：找到第一个峰值和第二个峰值,再找到第一和第二个峰值之间的谷值，谷值就是那个阀值了。</li></ul></li><li><p><strong>迭代阈值图像分割</strong>:</p></li><li><ul><li>1．统计图像灰度直方图,求出图象的最大灰度值和最小灰度值，分别记为ZMAX和ZMIN，令初始阈值T0=(ZMAX+ZMIN)/2；</li><li>2． 根据阈值TK将图象分割为前景和背景，计算小于TO所有灰度的均值ZO，和大于TO的所有灰度的均值ZB。</li><li>3． 求出新阈值TK+1=(ZO+ZB)/2；</li><li>4． 若TK==TK+1，则所得即为阈值；否则转2，迭代计算。</li></ul></li><li><p><strong>自适应阈值图像分割</strong>: 有时候物体和背景的对比度在图像中不是处处一样的，普通阈值分割难以起作用。这时候可以根据图像的局部特征分别采用不同的阈值进行分割。只要我们将图像分为几个区域，分别选择阈值，或动态地根据一定邻域范围选择每点处的阈值，从而进行图像分割。</p></li><li><ul><li><p><strong>大津法 OTSU （最大类间方差法）</strong>：</p></li><li><ul><li>日本学者大津在1979年提出的自适应阈值确定方法。 按照图像的灰度特性，将图像分为背景和目标两部分。背景和目标之间的类间方差越大,说明构成图像的2部分的差别越大,当部分目标错分为背景或部分背景错分为目标都会导致2部分差别变小。因此,使类间方差最大的分割意味着错分概率最小。</li></ul></li><li><p><strong>均值法</strong>:</p></li><li><ul><li>把图像分成m*n块子图，求取每一块子图的灰度均值就是所有像素灰度值之和除以像素点的数量，这个均值就是阈值了。这种方法明显不比大津法好，因为均值法和大津法都是从图像整体来考虑阈值的，但是大津法找了一个类间方差最大值来求出最佳阈值的；这两种方法子图越多应该分割效果会好一点，但效率可能会变慢</li></ul></li></ul></li><li><p><strong>最佳阈值</strong>:</p></li><li><ul><li>阈值选择需要根据具体问题来确定，一般通过实验来确定。如对某类图片，可以分析其直方图等。</li></ul></li></ul><h2 id="基于边缘的分割方法"><a href="#基于边缘的分割方法" class="headerlink" title="基于边缘的分割方法"></a><strong>基于边缘的分割方法</strong></h2><ul><li><p>参考： <a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8532106" target="_blank" rel="noopener">图像分割之（一）概述</a></p></li><li><p>图像中两个不同区域的边界线上连续的像素点的集合，是图像局部特征不连续性的反映，体现了灰度、颜色、纹理等图像特性的突变。通常情况下，基于边缘的分割方法指的是基于灰度值的边缘检测，它是建立在边缘灰度值会呈现出阶跃型或屋顶型变化这一观测基础上的方法。阶跃型边缘两边像素点的灰度值存在着明显的差异，而屋顶型边缘则位于灰度值上升或下降的转折处。正是基于这一特性，可以使用微分算子进行边缘检测，即使用一阶导数的极值与二阶导数的过零点来确定边缘，具体实现时可以使用图像与模板进行卷积来完成。</p></li><li><p>边缘角点和兴趣点的检测器有：</p></li><li><ul><li><p><strong>Canny边缘检测器</strong>：</p></li><li><ul><li>将图像P模糊化，然后与一堆正交微分滤波器（如Prewitt滤波器）做卷积生成分别包括水平和垂直方向上的导数的图像H和V，对像素(i,j)计算其梯度方向和幅度。若幅度超过临界值就分配一条边缘（此处称为阈值法，但效果不佳）。canny使用非极大抑制的方法对那些不需要响应的进行删除。<a href="https://link.zhihu.com/?target=http%3A//125.216.241.100%3A51004/view/29" target="_blank" rel="noopener">《计算机视觉：模型、学习和推理》第13章</a></li></ul></li><li><p><strong>Harris角点检测器</strong>：</p></li><li><ul><li>对每个点周围的水平方向垂直方向的据ubu梯度进行考虑。目的在于找到图像中亮度在两个方向上均发生变化的点，而非一个方向（一条边缘）或者零个方向（平坦区域）。Harris角点检测器是基于对图像结构张量的决策。<a href="https://link.zhihu.com/?target=http%3A//125.216.241.100%3A51004/view/29" target="_blank" rel="noopener">《计算机视觉：模型、学习和推理》第13章</a></li></ul></li><li><p><strong>SIFT检测器</strong>:</p></li><li><ul><li>尺度不变特征转换，检测是用来识别兴趣点的第二中方法。不同与Harris角点检测器，SIFT将尺度和方向与结果中的兴趣点相关联。为了找到兴趣点，，交替使用多种算子。<a href="https://link.zhihu.com/?target=http%3A//125.216.241.100%3A51004/view/29" target="_blank" rel="noopener">《计算机视觉：模型、学习和推理》第13章</a></li></ul></li><li><p><strong>SURF检测器</strong> *</p></li><li><ul><li>SIFT的改进版。</li></ul></li></ul></li></ul><h2 id="基于区域的分割方法"><a href="#基于区域的分割方法" class="headerlink" title="基于区域的分割方法"></a><strong>基于区域的分割方法</strong></h2><ul><li>参考：<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8532106" target="_blank" rel="noopener">图像分割之（一）概述</a></li></ul><p>按照图像的相似性准则划分为不同区域块。主要有种子区域生长法、区域分裂合并法、分水岭法等。</p><ul><li><p><strong>种子区域生长法</strong></p></li><li><ul><li>根据统一物体区域的像素相似性来聚集像素点达到区域生长的方法。其中由一组表示不同区域的种子像素开始，逐步合并种子周围相似的像素从而扩大区域。直到无法合并像素点或小领域为止。其中区域内的相似性的度量可用平均灰度值、纹理、颜色等等信息。关键在于选择初始种子像素及生长准则。最早的区域生长图像分割方法是由Levine等人提出。</li></ul></li><li><p><strong>区域分裂合并法</strong></p></li><li><ul><li>区域分裂合并法（Gonzalez，2002），确定分裂合并的准则，然后将图像任意分成若干互不相交的区域，按准则对这些区域进行分裂合并。它可用于灰度图像分割及纹理图像分割。</li></ul></li><li><p><strong>分水岭法</strong></p></li><li><ul><li>分水岭法（Meyer，1990）是一种基于拓扑理论的数学形态学的分割方法，其基本思想是把图像看作是测地学上的拓扑地貌，图像中每一点像素的灰度值表示该点的海拔高度，每一个局部极小值及其影响区域称为集水盆，而集水盆的边界则形成分水岭。该算法的实现可以模拟成洪水淹没的过程，图像的最低点首先被淹没，然后水逐渐淹没整个山谷。当水位到达一定高度的时候将会溢出，这时在水溢出的地方修建堤坝，重复这个过程直到整个图像上的点全部被淹没，这时所建立的一系列堤坝就成为分开各个盆地的分水岭。分水岭算法对微弱的边缘有着良好的响应，但图像中的噪声会使分水岭算法产生过分割的现象</li></ul></li></ul><h2 id="基于图论的分割方法"><a href="#基于图论的分割方法" class="headerlink" title="基于图论的分割方法"></a><strong>基于图论的分割方法</strong></h2><ul><li>参考：<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8532106" target="_blank" rel="noopener">图像分割之（一）概述</a></li></ul><p>此类方法把图像分割问题与图的最小割（min cut）问题相关联。首先将图像映射为带权无向图G=，图中每个节点N∈V对应于图像中的每个像素，每条边∈E连接着一对相邻的像素，边的权值表示了相邻像素之间在灰度、颜色或纹理方面的非负相似度。而对图像的一个分割s就是对图的一个剪切，被分割的每个区域C∈S对应着图中的一个子图。而分割的最优原则就是使划分后的子图在内部保持相似度最大，而子图之间的相似度保持最小。基于图论的分割方法的本质就是移除特定的边，将图划分为若干子图从而实现分割。目前所了解到的基于图论的方法有GraphCut，GrabCut和Random Walk等。</p><ul><li><p>GraphCut 图割</p></li><li><ul><li><p>参考：</p></li><li><ul><li>Boykov Y Y, Jolly M P. Interactive graph cuts for optimal boundary &amp; region segmentation of objects in N-D images[C]// IEEE International Conference on Computer Vision. IEEE Computer Society, 2001:105.</li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8532111" target="_blank" rel="noopener">图像分割之（二）Graph Cut（图割）</a></li></ul></li><li><p>非常有用和流行的能量优化算法，在计算机视觉领域普遍应用于前背景分割（Image segmentation）、立体视觉（stereo vision）、抠图（Image matting）等。</p></li><li><p>将一幅图像分为目标和背景两个不相交的部分，那就相当于完成了图像分割。</p></li><li><p>此类方法把图像分割问题与图的最小割（min cut）问题相关联。最小割把图的顶点划分为两个不相交的子集S和T。这两个子集就对应于图像的前景像素集和背景像素集。可以通过最小化图割来最小化能量函数得到。能量函数由区域项（regional term）和边界项（boundary term）构成。</p></li><li><p>整个流程的限制是：</p></li><li><ul><li>算法基于灰度图；</li><li>需要人工标注至少一个前景点和一个背景点；</li><li>结果为硬分割结果，未考虑边缘介于0~1之间的透明度。</li></ul></li></ul></li><li><p>GrabCut 分割和抠图</p></li><li><ul><li><p>参考：</p></li><li><ul><li>Rother C, Kolmogorov V, Blake A. “GrabCut”: interactive foreground extraction using iterated graph cuts[J]. Acm Transactions on Graphics, 2004, 23(3):309-314.</li><li><a href="https://zhuanlan.zhihu.com/p/20255114" target="_blank" rel="noopener">读《”GrabCut” — Interactive Foreground Extraction using Iterated Graph Cuts》</a></li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8534954" target="_blank" rel="noopener">图像分割之（三）从Graph Cut到Grab Cut</a></li></ul></li><li><p>是Graphcut图隔的改进版，是迭代的GraphCut。改进包括：</p></li><li><ul><li>将基于灰度分布的模型替换为高斯混合模型（Gaussian Mixture Model，GMM）以支持彩色图片;</li><li>将能一次性得到结果的算法改成了『强大的』迭代流程；将用户的交互简化到只需要框选前景物体即可。</li></ul></li><li><p>与Graph Cut不同处：</p></li><li><ul><li>Graph Cut的目标和背景的模型是灰度直方图，Grab Cut取代为RGB三通道的混合高斯模型GMM;</li><li>Graph Cut的能量最小化（分割）是一次达到的，而Grab Cut取代为一个不断进行分割估计和模型参数学习的交互迭代过程;</li><li>Graph Cut需要用户指定目标和背景的一些种子点，但是Grab Cut只需要提供背景区域的像素集就可以了。也就是说你只需要框选目标，那么在方框外的像素全部当成背景，这时候就可以对GMM进行建模和完成良好的分割了。即Grab Cut允许不完全的标注（incomplete labelling）。</li></ul></li><li><p>彩色像素值的稀疏问题比灰度图要严重得多（256 vs 17M），所以，继续使用histogram是不现实的，需要信息压缩得更好一点的模型，作者在这里参考前人，对前景和背景各建了K=5的高斯混合模型。</p></li><li><p>GrabCut是按颜色分布和边缘对比度来分割图片的，对一些常见的与此原则相悖的图片，效果确实不好。比如前景人物的帽子、鞋、墨镜，通常颜色跟前景主体有较大区别；再如前景中的孔，有可能由于颜色区分和边缘的对比度不足，导致边缘的惩罚占上风，而没有扣出来背景。所以，GrabCut还是保留了人工修正的操作，定义了两种标记：绝对是背景和可能是前景。对分割错误人工修正后，分割还是可以比较准确的。对自然场景图片的分割，比Bayes matte等方法得到的边缘明显看起来舒服得多。</p></li></ul></li></ul><h2 id="基于能量泛函的分割方法"><a href="#基于能量泛函的分割方法" class="headerlink" title="基于能量泛函的分割方法"></a><strong>基于能量泛函的分割方法</strong></h2><ul><li><p>参考：</p></li><li><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8532106" target="_blank" rel="noopener">图像分割之（一）概述</a></li></ul></li></ul><p>该类方法主要指的是活动轮廓模型（active contour model）以及在其基础上发展出来的算法，其基本思想是使用连续曲线来表达目标边缘，并定义一个能量泛函使得其自变量包括边缘曲线，因此分割过程就转变为求解能量泛函的最小值的过程，一般可通过求解函数对应的欧拉(Euler．Lagrange)方程来实现，能量达到最小时的曲线位置就是目标的轮廓所在。</p><p>活动轮廓模型逐渐形成了不同的分类方式，较常见的是根据曲线演化方式的不同，将活动轮廓模型分为基于边界、基于区域和混合型活动轮廓模型。按照模型中曲线表达形式的不同，活动轮廓模型可以分为两大类：参数活动轮廓模型（parametric active contour model）和几何活动轮廓模型（geometric active contour model）。</p><ul><li><p><strong>参数活动轮廓模型（parametric active contour model）</strong>:</p></li><li><ul><li><p>参数活动轮廓模型基于Lagrange框架，直接以曲线的参数化形式来表达曲线，最具代表性的是由Kasset a1(1987)所提出的Snake模型。该类模型在早期的生物图像分割领域得到了成功的应用，但其存在着分割结果受初始轮廓的设置影响较大以及难以处理曲线拓扑结构变化等缺点，此外其能量泛函只依赖于曲线参数的选择，与物体的几何形状无关，这也限制了其进一步的应用。</p></li><li><p><strong>Snake模型</strong>：</p></li><li><ul><li><p>参考：</p></li><li><ul><li>Michael Kass et al. Snakes: Active contour models. International Journal of Computer Vision, pages 321-331, 1987.</li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/zouxy09/article/details/8712287" target="_blank" rel="noopener">图像分割之（五）活动轮廓模型之Snake模型简介</a></li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/VictoriaW/article/details/59110318" target="_blank" rel="noopener">计算机视觉之图像分割——Snake模型(1译文)</a></li></ul></li><li><p>在处理如边缘检测、角点识别、动态跟踪以及立体匹配等任务上非常成功。</p></li><li><p>SNAKE模型就是一条可变形的参数曲线及相应的能量函数，以最小化能量目标函数为目标，控制参数曲线变形，具有最小能量的闭合曲线就是目标轮廓。模型的形变受到同时作用在模型上的许多不同的力所控制，每一种力所产生一部分能量，这部分能量表示为活动轮廓模型的能量函数的一个独立的能量项。</p></li><li><p>基本Snakes模型的能量函数由三项组成，弹性能量和弯曲能量合称内部能量（内部力），用于控制轮廓线的弹性形变，起到保持轮廓连续性和平滑性的作用。而第三项代表外部能量，也被称为图像能量，表示变形曲线与图像局部特征吻合的情况。内部能量仅仅跟snake的形状有关，而跟图像数据无关。而外部能量仅仅跟图像数据有关。在某一点的α和β的值决定曲线可以在这一点伸展和弯曲的程度。最终对图像的分割转化为求解能量函数Etotal(v)极小化（最小化轮廓的能量）。在能量函数极小化过程中，弹性能量迅速把轮廓线压缩成一个光滑的圆，弯曲能量驱使轮廓线成为光滑曲线或直线，而图像力则使轮廓线向图像的高梯度位置靠拢。基本Snakes模型就是在这3个力的联合作用下工作的。</p></li><li><p>snake相对于经典的特征提取方法有以下优点：</p></li><li><ul><li>通过正确设置和项前系数，可交互方式控制snake;</li><li>容易操控，因为图像力是以直观的方式表现;</li><li>在寻找最小能量状态的时候它们是自主的和自适应的;</li><li>可以通过在图像能量函数中加入高斯平滑而对图像尺度敏感;</li><li>可以用于跟踪时间或者空间维度上的动态目标。</li></ul></li><li><p>snake的缺点：</p></li><li><ul><li>初始位置不同使得结果不同;</li><li>经常陷入局部最小状态，这也许可以通过使用模拟退火技术来克服，代价就是计算时间增加;</li><li>在最小化整个轮廓路径上的能量过程中经常忽略微小特征;</li><li>精度由能量最小化技术中使用的收敛标准控制；更高的精度要求更严格的收敛标准，因此需要更长的计算时间。</li></ul></li></ul></li><li><p><strong>ASM(Active Shape Model)</strong></p></li><li><ul><li><p>参考：</p></li><li><ul><li>Cootes T F, Taylor C J. Active Shape Models — ‘Smart Snakes’[M]// BMVC92. Springer London, 1992:266—275.</li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/watkinsong/article/details/8891071" target="_blank" rel="noopener">ASM(Active Shape Model) 主动形状模型总结</a></li></ul></li><li><p>ASM（主动形状模型）是建立在PDM（点分布模型）的基础上，通过训练图像样本获取训练图像样本的特征点分布的统计信息，并且获取特征点允许存在的变化方向，实现在目标图像上寻找对应的特征点的位置。训练样本需要手动的标记所有的特征点的位置，记录特征点的坐标，并且计算每一个特征点对应的局部灰度模型作为局部特征点调整用的特征向量。在将训练好的模型放在目标图像上，寻找每一个特征点的下一个位置的时候，采用局部灰度模型寻找在当前特征点指定方向上局部灰度模型马氏距离最小的特征点作为当前特征点即将移动到的位置，称为suggested point, 找到所有的suggested points就可以获得一个搜索的suggested shape, 然后将当前的模型通过调整参数使得当前的模型最可能相似的调整到suggest shape，重复迭代直到实现收敛。</p></li></ul></li><li><p><strong>AAM(Active Appearance Models)</strong></p></li><li><ul><li><p>参考：</p></li><li><ul><li>Cootes T F, Edwards G J, Taylor C J. Active Appearance Models[C]// European Conference on Computer Vision. Springer Berlin Heidelberg, 1998:484-498.</li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/carson2005/article/details/8196996" target="_blank" rel="noopener">AAM（Active Appearance Model）算法介绍</a></li></ul></li><li><p>ASM是基于统计形状模型的基础上进行的，而AAM则是在ASM的基础上，进一步对纹理（将人脸图像变形到平均形状而得到的形状无关图像）进行统计建模，并将形状和纹理两个统计模型进一步融合为表观模型。</p></li><li><p>AAM模型相对于ASM模型的改进为：</p></li><li><ul><li>使用两个统计模型融合 取代 ASM的灰度模型。</li><li>主要对特征点的特征描述子进行了改进，增加了描述子的复杂度和鲁棒性</li></ul></li></ul></li><li><p><strong>CLM(Constrained local model)有约束的局部模型</strong></p></li><li><ul><li><p>参考：</p></li><li><ul><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/marvin521/article/details/11489453" target="_blank" rel="noopener">机器学习理论与实战（十六）概率图模型04</a></li></ul></li><li><p>CLM是有约束的局部模型，ASM也属于CLM的一种。CLM通过初始化平均脸的位置，然后让每个平均脸上的特征点在其邻域位置上进行搜索匹配来完成人脸点检测。整个过程分两个阶段：模型构建阶段和点拟合阶段。模型构建阶段又可以细分两个不同模型的构建：</p></li><li><ul><li>形状模型构建: 对人脸模型形状进行建模，说白了就是一个ASM的点分布函数（PDM），它描述了形状变化遵循的准则.</li><li>Patch模型构建: 对每个特征点周围邻域进行建模，也就说建立一个特征点匹配准则，怎么判断特征点是最佳匹配.</li></ul></li></ul></li></ul></li><li><p><strong>几何活动轮廓模型（geometric active contour model）</strong>:</p></li><li><ul><li><p>参考：</p></li><li><ul><li>·S.Osher,J.A.Sethian,Fronts propagating with curvature dependent speed:algorithms basedon Hamilton-Jacobi formulations.Journal of Computational Physics,1988,79:12—49</li><li><a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/vast_sea/article/details/8196507" target="_blank" rel="noopener">图像分割___图像分割方法综述</a></li></ul></li><li><p>几何活动轮廓模型的曲线运动过程是基于曲线的几何度量参数而非曲线的表达参数，因此可以较好地处理拓扑结构的变化，并可以解决参数活动轮廓模型难以解决的问题。而水平集（Level Set）方法（Osher，1988）的引入，则极大地推动了几何活动轮廓模型的发展，因此几何活动轮廓模型一般也可被称为水平集方法。</p></li><li><p>几何活动轮廓模型(Geometric Active Contours Model)是以曲线演化理论和水平集方法为理论基础,继参数活动轮廓模型后形变模型的又一发展,是图像分割和边界提取的重要工具之一。相对于参数活动轮廓模型,几何活动轮廓模型具有很多优点,如可以处理曲线的拓扑变化、对初始位置不敏感、具有稳定的数值解等.</p></li><li><p>几何活动轮廓模型又可分为基于边界的活动轮廓模型、基于区域的活动轮廓模型。基于边界的活动轮廓模型主要依赖图像的边缘信息控制曲线的运动速度。在图像边缘强度较弱或是远离边缘的地方，轮廓曲线运动速度较大，而在图像边缘强度较强的地方，轮廓曲线运动速度较小甚至停止，使得最终的轮廓曲线运动到边缘位置.</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征检测与匹配--线条</title>
      <link href="/2019/05/20/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D-%E7%BA%BF%E6%9D%A1/"/>
      <url>/2019/05/20/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D-%E7%BA%BF%E6%9D%A1/</url>
      
        <content type="html"><![CDATA[<p>尽管边缘和一-般曲线适合用来描述自然物体的轮廓，但人类世界中直线段到处<br>都是。检测和匹配这些线条对于很多应用很有用，包括建筑学上的建模、城市环境<br>下的姿态估计以及书面文档版式分析。<br>本节将首先描述一些使用分段线性折线来近似曲线的算法，然后讲解一下Hough Transform，使得即使存在间隙和遮挡的时候，它都可以用于将边界元聚集成线片段。最后描述怎样将拥有”共同消失点（vanishing point）“的3D直线聚集在一起。</p><h2 id="1-1-逐次近似"><a href="#1-1-逐次近似" class="headerlink" title="1.1 逐次近似"></a>1.1 逐次近似</h2><p><img src="line.png" alt></p><p>用折线或者b样条曲线来近似一~个曲线(用黑色表示): (a)原始 曲线用一个红色<br>的折线来近似:(b)通过迭代地寻找与目前的近似离得最远的点做逐次近似;(c)拟合折线<br>顶点的光滑的内插样条用深蓝色显示。</p><p>“直线简化”最简单的方法就是通过递归地细分连接两个端点的直线最远的曲线点来近似曲线。如果需要一个更平滑的表示或者可视化，就可以使用近似线或者插值样条或是曲线本身。</p><h2 id="1-2-标准Hough变换"><a href="#1-2-标准Hough变换" class="headerlink" title="1.2 标准Hough变换"></a>1.2 标准Hough变换</h2><p><strong>定义</strong></p><p>霍夫变换(Hough Transform)是图像处理中的一种特征提取技术，可以识别图像中的几何形状。它将图像空间中的特征点映射到参数空间进行投票，通过检测累计结果的局部极值点得到一个符合某特定形状的点的集合。经典霍夫变换用来检测图像中的直线，后来霍夫变换扩展到任意形状物体的识别，多为圆和椭圆。它的抗噪声、抗形变能力较强。另一种直线提取的方法是对图像边缘点进行链码追踪，在得到的链码串中提取直线。</p><p>霍夫变换将在一个空间中具有相同形状的曲线或直线映射到另一个坐标空间的一个点上形成峰值，从而把检测任意形状的问题转化为统计峰值问题。</p><p><strong>原理</strong></p><p>霍夫变换最简单的是检测直线。我们知道，直线的方程表示可以由斜率和截距表示（这种表示方法，称为斜截式），如下所示：</p><script type="math/tex; mode=display">y=m x+b</script><p>如果用参数空间表示则为$(b,m)$,即用斜率和截距就能表示一条直线。</p><p>但是这样会参数问题，垂直线的斜率不存在（或无限大），这使得斜率参数$m$的值接近于无限。为此，为了更好的计算，Richard O. Duda和Peter E. Hart在1971年4月，提出了Hesse normal form(Hesse法线式)</p><script type="math/tex; mode=display">r=x \cos \theta+y \sin \theta</script><p>其中$r$是原点到直线上最近点的距离(其他人可能把这记录为$ρ$，下面也可以把rr看成参数$ρ$)，$θ$是$x$轴与连接原点和最近点直线之间的夹角。如图所示。</p><p><img src="kongjian.png" alt></p><p>因此，可以将图像的每一条直线与一对参数($(r,θ)$相关联。这个参数$(r,θ)$平面有时被称为<strong>霍夫空间</strong>，用于二维直线的集合。</p><p>经过Hough变换，将图像空间中经过一个点的所有直线映射到Hough空间，如下图示。</p><p><img src="suoyou.png" alt></p><p>Matlab代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">% 一个点的坐标为（3,4）</span><br><span class="line">x=3;</span><br><span class="line">y=4;</span><br><span class="line">%将给定的一个定点映射到霍夫变换空间</span><br><span class="line">theta=0:pi/200:2*pi;% 角度</span><br><span class="line">r=x*cos(theta)+y*sin(theta);</span><br><span class="line">plot(theta,r);%绘图</span><br><span class="line">set(gca,&apos;XTick&apos;,[0:pi/10:2*pi]);   % 修改x轴坐标间隔</span><br><span class="line"> xlabel(&apos;变量\theta&apos;)</span><br><span class="line"> ylabel(&apos;变量r&apos;)</span><br></pre></td></tr></table></figure><p>所以我们可以得到一个结论，给定平面中的单个点，那么通过该点的所有直线的集合对应于$(r,θ)$平面中的正弦曲线，这对于该点是独特的。一组两个或更多点形成一条直线将产生在该线的$(r,θ)$处交叉的正弦曲线。因此，检测共线点的问题可以转化为找到并发曲线的问题。</p><p><img src="jiaodian.png" alt></p><p>如上图所示，粉红色交点即为三个点共现的直线。</p><p>所以Hough 变换在图像直线检测的操作步骤如下：</p><p>1、读取原始图并转换为灰度图，采用边缘检测算子（如Canny）转换成二值化边缘图像；<br>2、顺序搜索边缘图像中的每一个黑点，在霍夫空间中依次画出正弦曲线，根据各个正弦曲线的交点情况，在累加器的对应位置加1。（累加器为二维数组$\left(\lambda^{}, \theta^{}\right)$，存放着对应参数的个数）；<br>3、求出累加器中局部极大值，其位置为$\left(\lambda^{\prime}, \theta^{\prime}\right)$；<br>4、通过累加器得出的位置$\left(\lambda^{\prime}, \theta^{\prime}\right)$得出图像中对应的直线。</p><h2 id="1-3-消失点检测"><a href="#1-3-消失点检测" class="headerlink" title="1.3 消失点检测"></a>1.3 消失点检测</h2><p>【待补充】</p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征检测与匹配--边缘</title>
      <link href="/2019/05/20/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D-%E8%BE%B9%E7%BC%98/"/>
      <url>/2019/05/20/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D-%E8%BE%B9%E7%BC%98/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-边缘检测"><a href="#1-1-边缘检测" class="headerlink" title="1.1 边缘检测"></a>1.1 边缘检测</h2><p><strong>灰度图像边缘检测</strong></p><p>图像的边缘区域会存在明显的像素值阶跃，因此边缘检测主要是通过获得图像灰度梯度，进而通过梯度大小和变化来判断图像边缘的。<br><img src="bianyuan.png" alt></p><script type="math/tex; mode=display">\begin{aligned} \Delta f_{x}(x, y) &=f(x+1, y)-f(x, y) \\ \Delta f_{y}(x, y) &=f(x, y+1)-f(x, y) \end{aligned}</script><p>或者二阶差分对边缘区域进行判断:</p><script type="math/tex; mode=display">\begin{aligned} \Delta f_{x x}(x, y) &=f(x+1, y)+f(x-1, y)-2 f(x, y) \\ \Delta f_{y y}(x, y) &=f(x, y+1)+f(x, y-1)-2 f(x, y) \end{aligned}</script><p>其中一阶差分可以判断边缘是否存在，二阶差分还可以根据正负号判断像素点在图像边缘亮的一侧还是暗的一侧。<br>其他的边缘检测方法还包括一些梯度算子，例如<strong>Prewitt算子</strong>、<strong>Sobel算子</strong>，<strong>Canny算子</strong>，<strong>LOG</strong>边缘检测算子等，在此不做说明。</p><p><strong>彩色图像边缘检测</strong></p><p>彩色图像的每个像素包含红绿蓝三个分量，这样每个像素可以由一个三维向量来表示。但是在进行图像边缘检测的时候，我们遇到一个问题，那就是向量并不存在梯度概念。单独对每个颜色分量进行边缘检测，其梯度不能反映图像整体彩色的差异变化。<br>一个广为使用的彩色图像梯度方法来自Zenzo[1986]的论文</p><script type="math/tex; mode=display">\begin{array}{l}{\vec{u}=\frac{\partial R}{\partial x} \vec{r}+\frac{\partial G}{\partial x} \vec{g}+\frac{\partial B}{\partial x} \vec{b}} \\ {\vec{v}=\frac{\partial R}{\partial y} \vec{r}+\frac{\partial G}{\partial y} \vec{g}+\frac{\partial B}{\partial y} \vec{b}}\end{array}</script><p>其中$R,G,B$是图像分量，$\vec{r}, \vec{g}, \vec{b}$等是单位向量，表征颜色分量坐标。然后继续计算有:</p><script type="math/tex; mode=display">\begin{array}{c}{g_{x x}=\vec{u}^{T} \vec{u}=\left|\frac{\partial R}{\partial x}\right|^{2}+\left|\frac{\partial G}{\partial x}\right|^{2}+\left|\frac{\partial B}{\partial x}\right|^{2}} \\ {g_{y y}=\vec{v}^{T} \vec{v}=\left|\frac{\partial R}{\partial y}\right|^{2}+\left|\frac{\partial G}{\partial y}\right|^{2}+\left|\frac{\partial B}{\partial y}\right|^{2}} \\ {g_{x y}=\vec{u}^{T} \vec{v}=\frac{\partial R}{\partial x} \frac{\partial R}{\partial y}+\frac{\partial G}{\partial x} \frac{\partial G}{\partial y}+\frac{\partial B}{\partial x} \frac{\partial B}{\partial y}}\end{array}</script><p>注意这里执行的是向量乘法，而不是进一步求导。梯度方向为：</p><script type="math/tex; mode=display">\theta=\frac{1}{2} \arctan \left[\frac{2 g_{x y}}{\left(g_{x x}-g_{y y}\right)}\right]</script><p>由梯度方向才能计算梯度:</p><script type="math/tex; mode=display">F(\theta)=\left\{\frac{1}{2}\left[\left(g_{x x}+g_{y y}\right)+\left(g_{x x}-g_{y y}\right) \cos 2 \theta+2 g_{x y} \sin 2 \theta\right]\right\}^{\frac{1}{2}}</script><p>matlab上自带的edge函数目前没发现可以对彩色图像直接进行边缘检测的方法，C++的openCV库也没有发现。上述工具一般会对彩色图像进行灰度化再执行边缘检测，效果也不算差。</p><h2 id="1-2-边缘检测"><a href="#1-2-边缘检测" class="headerlink" title="1.2 边缘检测"></a>1.2 边缘检测</h2><p>【待补充】</p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征检测与匹配--点与块</title>
      <link href="/2019/05/16/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D-%E7%82%B9%E4%B8%8E%E5%9D%97/"/>
      <url>/2019/05/16/%E7%89%B9%E5%BE%81%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%8C%B9%E9%85%8D-%E7%82%B9%E4%B8%8E%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<p>特征检测就是检测图像中目标的特征。所谓特征就是不管你怎么旋转目标，离目标远近，它的特征都应该不变，这两个特性称为旋转不变性和尺度不变性。当然还有其他特征，如光照不一样等等。特征检测的对象可包括特征点检测、边缘检测等。</p><h2 id="1-1-点与块"><a href="#1-1-点与块" class="headerlink" title="1.1 点与块"></a>1.1 点与块</h2><p>点特征可以用来寻找一个不同图像中对应位置的稀疏集合，称之为关键点，其优点在于它们能够在出现遮挡、大的尺度和方向变化的情况下很好的匹配。<br>匹配分方法有两种：第一种是在第一幅图像中寻找那些可以使用局部搜索方法来精确跟踪的特征，比如相关或最小二乘；第二种方法是在所有考察的图像中独立地检测特征点然后再基于它们的局部表现进行匹配。<br>本节将关键点检测和匹配分成四个阶段。在<strong>特征检测</strong>阶段，从每一幅图像中寻找那些能在其他图像中较好匹配的位置；在<strong>特征描述</strong>阶段，把检测到的关键点周围的每一个区域转化成一个更紧凑和稳定（不变）的描述子，描述子可以和其他描述子进行匹配；<strong>特征匹配</strong>阶段，在其他图像中高效地搜索可能的匹配候选；<strong>特征跟踪</strong>阶段，与第三阶段相似，只在检测到的特征点周围一个小的邻域内寻找匹配，更加适合视频处理。</p><h3 id="1-1-1-特征检测器"><a href="#1-1-1-特征检测器" class="headerlink" title="1.1.1 特征检测器"></a>1.1.1 特征检测器</h3><p>怎样才能找到能够在其他图像中稳定匹配的图像位置，也就是说什么是适合跟踪的特征？<br><img src="duibi.png" alt><br>如上图，对于两幅视角不同的同一幅图像能够被很好的匹配和跟踪。武鸣县纹理结构的图像快几乎不可能定位，而拥有较大对比度变化（梯度）的则比较容易定位，并且至少拥有至少两个（明显）不同方向梯度的图像块最容易定位。</p><p>用最简单的匹配策略来比较两个图像块，加权差的平方和</p><script type="math/tex; mode=display">E_{\mathrm{wssD}}(u)=\sum_{i} w\left(x_{i}\right)\left[I_{1}\left(x_{i}+u\right)-I_{0}\left(x_{i}\right)\right]^{2}</script><p>其中$I_0,I_1$是两幅需要比较的图像，$u=(u,v)$是平移向量，$w(x)$是在空间上变化的权重（或窗口）函数，求和变量$i$作用于块中全体的像素。</p><p>我们用原图像块的自相关函数来衡量该图像块被匹配的”难易程度”|</p><script type="math/tex; mode=display">E_{\mathrm{AC}}(\Delta u)=\sum_{i} w\left(x_{i}\right)\left[I_{0}\left(x_{i}+\Delta u\right)-I_{0}\left(x_{i}\right)\right]^{2}</script><p>如下图所示，对于有纹理花坛的自相关表面存在一个很强的最小值，这表明它很容易定位（如图b,图a右下角红十字），而对于房顶边缘的自相关表面在一个方向上存在很大的歧义性（如图c），而对应于云朵区域的自相关表面则没有稳定的最小值（如图d）<br><img src="weizhi.png" alt></p><p>对上述图像块的自相关函数近似处理</p><script type="math/tex; mode=display">\begin{aligned} E_{\mathrm{AC}}(\Delta u) &=\sum_{i} w\left(x_{i}\right)\left[I_{0}\left(x_{i}+\Delta u\right)-I_{0}\left(x_{i}\right)\right]^{2} \\ & \approx \sum_{i} w\left(x_{i}\right)\left[I_{0}\left(x_{i}\right)+\nabla I_{0}\left(x_{i}\right) \cdot \Delta u-I_{0}\left(x_{i}\right)\right]^{2} \\ &=\sum_{i} w\left(x_{i}\right)\left[\nabla I_{0}\left(x_{i}\right) \cdot \Delta u\right]^{2} \\ &=\Delta u^{T} A \Delta u \end{aligned}</script><p>其中 $\nabla I_{0}\left(\boldsymbol{x}_{i}\right)=\left(\frac{\partial I_{0}}{\partial x}, \frac{\partial I_{0}}{\partial y}\right)\left(x_{i}\right)$是$x_i$处的”图像梯度”。梯度的计算可以采用多种方法。经典的Harris检测器采用了滤波器，现在更为普遍的则是采用水平方向上和垂直方向的高斯函数的导数对图像进行卷积。<br>自相关矩阵$A$可以写作</p><script type="math/tex; mode=display">\boldsymbol{A}=\boldsymbol{w(x,y)} * \left[ \begin{array}{cc}{I_{x}^{2}} & {I_{x} I_{y}} \\ {I_{x} I_{y}} & {I_{y}^{2}}\end{array}\right]</script><p>其中，$w(x,y)$是窗口函数，最简单情形就是窗口内的所有像素所对应的w权重系数均为1。但有时候，我们会将$w(x,y)$函数设定为以窗口中心为原点的二元正态分布。如果窗口中心点是角点时，移动前与移动后，该点的灰度变化应该最为剧烈。<br>根据上述表达式，当窗口处在平坦区域上滑动，可以想象的到，灰度不会发生变化，那么$E_{AC}$ = 0；如果窗口处在比纹理比较丰富的区域上滑动，那么灰度变化会很大。算法最终思想就是计算灰度发生较大变化时所对应的位置，当然这个较大是指针任意方向上的滑动，并非单指某个方向。</p><p><strong>Harris角点检测</strong></p><p>难道我们是直接求上述的$E_{AC}$值来判断角点吗？Harris角点检测并没有这样做，而是通过对窗口内的每个像素的$x$方向上的梯度与y方向上的梯度进行统计分析。这里以$I_x$和$I_y$为坐标轴，因此每个像素的梯度坐标可以表示成$(I_x,I_y)$。针对平坦区域，边缘区域以及角点区域三种情形进行分析：<br><img src="quyuduibi.jpeg" alt></p><p>平坦区域上的每个像素点所对应的$(I_x,I_y)$坐标分布在原点附近，其实也很好理解，针对平坦区域的像素点，他们的梯度方向虽然各异，但是其幅值都不是很大，所以均聚集在原点附近；边缘区域有一坐标轴分布较散，至于是哪一个坐标上的数据分布较散不能一概而论，这要视边缘在图像上的具体位置而定，如果边缘是水平或者垂直方向，那么$I_y$轴方向或者$I_x$方向上的数据分布就比较散；角点区域的x、y方向上的梯度分布都比较散。我们是不是可以根据这些特征来判断哪些区域存在角点呢？</p><p>参考PCA对自相关矩阵$A$进行均值化和对角化，很明显，特征值就是主分量上的方差。如果存在两个主分量所对应的特征值都比较大，说明什么？ 像素点的梯度分布比较散，梯度变化程度比较大，符合角点在窗口区域的特点；如果是平坦区域，那么像素点的梯度所构成的点集比较集中在原点附近，因为窗口区域内的像素点的梯度幅值非常小，此时矩阵A的对角化的两个特征值比较小；如果是边缘区域，在计算像素点的x、y方向上的梯度时，边缘上的像素点的某个方向的梯度幅值变化比较明显，另一个方向上的梯度幅值变化较弱，其余部分的点都还是集中原点附近，这样A对角化后的两个特征值理论应该是一个比较大，一个比较小，当然对于边缘这种情况，可能是呈45°的边缘，致使计算出的特征值并不是都特别的大，总之跟含有角点的窗口的分布情况还是不同的。</p><ul><li>特征值都比较大时，即窗口中含有角点</li><li>特征值一个较大，一个较小，窗口中含有边缘</li><li>特征值都比较小，窗口处在平坦区域</li></ul><p>通常用下面表达式进行度量：</p><script type="math/tex; mode=display">\begin{array}{c}{R=\operatorname{det} A-k(\operatorname{trace} A)^{2}} \\ {\quad \operatorname{det} A=\lambda_{1} \lambda_{2}} \\ {\text { trace } A=\lambda_{1}+\lambda_{2}}\end{array}</script><p>其中k是常量，一般取值为0.04~0.06，这个参数仅仅是这个函数的一个系数，它的存在只是调节函数的形状而已。最后设定R的阈值，进行角点判断。</p><p><em>Harris算子对图像尺度变化非常敏感，因此不适合用于不同尺度的图像匹配。</em></p><p><strong>非极大值抑制</strong>(Non-Maximum Suppression,NMS)</p><p>顾名思义就是抑制不是极大值的元素，可以理解为局部最大搜索。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小。此处主要说明NMS用于目标检测中提取分数最高的窗口的。例如在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。NMS在计算机视觉领域有着非常重要的应用，如视频目标跟踪、数据挖掘、3D重建、目标识别以及纹理分析等。</p><blockquote><p>核心思想：选取那些邻域里分数最高的窗口，同时抑制那些分数低的窗口</p></blockquote><p>原理：对所有检测到的检测框按照他们的得分进行排序（这个得分就是我们利用分类器来进行时，会得到一个概率值，这个概率值就表示当前检测框是我们所需要检测目标的概率大小。）选出得分最大的检测框A，设定阈值b，在剩下的检测框中，计算他们与最大检测框A之间的IoU（Intersection over Union），若IoU大于阈值b，即重叠率高的检测框。删除这些检测框；有可能存在与当前检测框完全不重叠的，或者他们的重叠面积非常小（IoU小于阈值b），接下来会对这些没有处理过的检测框重新进行排序，排序完成后同样选择一个得分最大的检测框，然后计算其他检测框与这个最大检测框的IoU值，然后将IoU大于一定阈值的检测框再进行一次删除，不断的迭代这个过程，直到所有的检测框都被处理之后，输出最后的检测结果。</p><p><img src="nms1.png" alt></p><p><img src="nms2.png" alt></p><p><strong>衡量可重复性</strong></p><p>计算机视觉领域中开发有各种各样的特征检测器，我们如何决定使用哪一个呢? 将这个可重复性定义为在一幅图像中检测到的关键点在另一幅变换过的图像中的对应位置的ε(比如ε=1.5)个像素范围内找到的频率。这种变换包括对平面图像进行各种变换，包括旋转、尺度变化，光照变化、视角变化以及增加噪声等。</p><p><strong>Harris+尺度不变筛选</strong></p><p>对于大多数物体识别应用，图像中物体的尺度是不知道，相比于在多个不同尺度上提取特征后再全部匹配，提取所有位置和尺度都稳定的特征更高效。<br>虽然尺度不变特征变换(SIFT)在实践中效果很好，但它的理论基础并不是基于最大化空间稳定性的，这与基于自相关性的检测器不同。(事实上，它的检测位置经常与那些方法所产生的检测位置互补，因此可以和那些方法一起使用。)为了给Harris角点检测提供-一个 尺度选择的机制，在每个检测到的Harris位置评估高斯拉普拉斯函数(在一个多尺度金字塔上)，然后只保留那些拉普拉斯函数取极值(比它高一级的尺度和低一级的尺度的值都大或者都小）的点。</p><p><strong>旋转不变和方向估计</strong></p><p>为了处理旋转变化，需要设计出旋转不变的描述子。但是这些描述子区分性比较弱，也就是说，对于同一个描述子，它们映射出不同的查找块。<br>一个较好的办法就是在检测到的每一个关键点估计一个”主导方向”，一旦估计出一个关键点的局部方向和尺度，就可以在检测出的关键点附近提取出一个特定尺度和方向的图像块。<br><img src="chidu1.png" alt></p><p><img src="chidu2.png" alt></p><p><strong>仿射不变</strong></p><p>【待补充】</p><h3 id="1-1-2-特征描述子"><a href="#1-1-2-特征描述子" class="headerlink" title="1.1.2 特征描述子"></a>1.1.2 特征描述子</h3><p><a href="https://blog.csdn.net/carson2005/article/details/8708349" target="_blank" rel="noopener">局部特征描述子概述</a></p><p>物体识别的核心问题是将同一目标在不同时间、不同分辨率、不同光照、不同位姿情况下所成的像相相匹配。而为了进行匹配，我们首先要合理的表示图像。由于目标的自身状态、场景所处的环境的影响，同一类物体在不同的图像中所成的像往往会差别很大，但即使这样，人们所能通过同一物体的一些局部共性来识别出物体（正如我们能将不同国家民族的人区分出来）。<strong>所谓局部特征描述子就是用来刻画图像中的这些局部共性的</strong>，而我们也可以将一幅图像映射（变换）为一个局部特征的集合。理想的局部特征应具有平移、缩放、旋转不变性，同时对光照变化、仿射及投影影响也应有很好的鲁棒性。<br>在特征匹配中，特征描述子通常是用于N维向量，在光照不变以及少许透视变形的情况下很理想。另外，优质的描述子可以通过简单的距离测量进行比较，比如欧氏距离。如我们想匹配同一个场景中的两幅图像。首先，我们检测每幅图像中的特征，然后提取他们的描述子。第一幅图像中的每一个特征描述子向量都会与第二幅图中的描述子进行比较，得分最高的一对描述子，也就是两个向量的距离最近，将被视为那个特征的最佳匹配。</p><p><strong>方向梯度直方图（HOG描述子）</strong></p><p>该特征通过计算和统计图像局部区域的梯度方向直方图来构成特征。其优点是可以对几何和光学的形变保持很好的不变形，换句话说，对环境的变化具有很强的鲁棒性。</p><p>该特征的主要思想是：图像中局部目标的表象和性状能够被梯度或边缘的方向密度很好的描述本（本质：梯度的统计信息，而梯度主要存在于边缘的地方）。在实际操作中，将图像分为小的<strong>细胞单元</strong>(cells)，每个细胞单元计算一个梯度方向(或边缘方向)直方图。为了对光照和阴影有更好的不变性，需要对直方图进行对比度归一化，可以通过将细胞单元组成更大的<strong>块</strong>(blocks)并归一化块内的所有细胞单元来实现。我们将归一化的块描述符叫做HOG描述子。将检测窗口中的所有块的HOG描述子组合起来就形成了最终的特征向量。</p><p>下面我们来介绍HOG特征的提取过程：</p><p>1、灰度化，因为Hog特征提取的是纹理特征，颜色信息不起作用，所以现将彩色图转为灰度图；</p><p>２、归一化，为了提高检测器对光照等干扰因素的鲁棒性，需要对图像进行Gamma校正，以完成对整个图像的归一化，目的是调节图像的对比度，降低局部光照和阴影所造成的影响，同时也可以降低噪音的干扰；（当r取1/2时，像素的取值范围就从0~255变换到0~15.97）</p><script type="math/tex; mode=display">G(x, y)=F(x, y)^{1 / \gamma}</script><p>Gamma校正的映射公式，一般ｒ取１/２</p><p>３、计算图像像素的梯度：根据下面的公式计算每个像素的水平方向和竖直方向的梯度，并计算每个像素位置的梯度大小和方向。图像在像素点（ｘ，ｙ）处的水平方向和垂直方向的梯度为：</p><script type="math/tex; mode=display">\left\{\begin{array}{l}{G_{x}(x, y)=G(x+1, y)-G(x-1, y)} \\ {G_{y}(x, y)=G(x, y+1)-G(x, y-1)}\end{array}\right.</script><p>Gx(x,y) 和Gy(x,y) 分别表示当前像素点（x,y）处的水平方向和垂直方向梯度值</p><p>接下来我们计算像素点（x,y）处的梯度幅值和梯度方向:</p><script type="math/tex; mode=display">\left\{\begin{array}{l}{\nabla \mathrm{G}(x, y)=\sqrt{G_{x}(x, y)^{2}+G_{y}(x, y)^{2}}} \\ {\theta(x, y)=\tan ^{-1} \frac{G_{y}(x, y)}{G_{x}(x, y)}}\end{array}\right.</script><p>４、统计细胞单元（Cell）的梯度方向直方图：将图像划分成小的Cell，将梯度方向映射到180度的范围内，将像素的梯度幅值作为权值进行投影，用梯度方向决定向哪一维进行投影，假如该像素的梯度方向为20度,梯度幅值为10，那么直方图的第二维就加10。下图是一个细胞单元内的方向梯度直方图，角度分辨率是在180度的范围内，以20度等分，即一个细胞单元的HOG特征是一个9维的向量。</p><p><img src="cell.png" alt></p><p>一个细胞单元的梯度方向直方图</p><p>５、统计块（Block）的梯度方向直方图：统计每个细胞单元内的梯度直方图，形成每个细胞单元的描述子，由cell组成更大的描述子，称为块，将一个块内四个cell的特征向量串联起来就构成了该块的梯度方向直方图，按照一个细胞单元是9维的Hog特征，则一个块的Hog特征为4x9=36维。由于局部光照的变化，以及前景背景对比度的变化，使得梯度强度的变化范围非常大，这就需要对梯度做局部对比度归一化。这里的策略是针对每个块进行对比度归一化，一般使用L2-norm。</p><p><img src="guiyi.png" alt></p><p>6、统计窗口（Window）的梯度方向直方图：只需要将窗口内所有块的Hog特征向量串联起来就得到了Window的Hog特征；</p><p>7、统计整幅图像的梯度方向直方图：一幅图像可以无重叠的划分为多个Window，这时将所有Window的特征向量串联起来就是整幅图像的Hog特征了，如果Window的大小和图像的大小相同，那么Window的Hog特征就是整幅图像的Hog特征，这也是最终分类使用的特征向量。大功告成！</p><p> <strong>尺度不变特征变换（SIFT）</strong></p><p>成像匹配的核心问题是将同一目标在不同时间、不同分辨率、不同光照、不同位姿情况下所成的像相对应。传统的匹配算法往往是直接提取角点或边缘，对环境的适应能力较差，急需提出一种鲁棒性强、能够适应不同光照、不同位姿等情况下能够有效识别目标的方法。1999年British Columbia大学大卫.劳伊（ David G.Lowe）教授总结了现有的基于不变量技术的特征检测方法，并正式提出了一种基于尺度空间的、对图像缩放、旋转甚至仿射变换保持不变性的图像局部特征描述算子－SIFT（尺度不变特征变换），这种算法在2004年被加以完善。</p><p><img src="ex.jpeg" alt></p><p><em>算法思想</em></p><p>将一幅图像映射（变换）为一个局部特征向量集；特征向量具有平移、缩放、旋转不变性，同时对光照变化、仿射及投影变换也有一定不变性。</p><p><em>步骤简述</em></p><p>SIFT算法的实质可以归为在不同尺度空间上查找特征点（关键点）的问题。</p><p><img src="liu.jpeg" alt></p><p>1、提取关键点；<br>2、对关键点附加详细的信息（局部特征）也就是所谓的描述器；<br>3、通过两方特征点（附带上特征向量的关键点）的两两比较找出相互匹配的若干对特征点，也就建立了景物间的对应关系。</p><p><em>算法细节</em></p><p>1、构建尺度空间</p><p>这是一个初始化操作，尺度空间理论目的是模拟图像数据的多尺度特征。高斯核是唯一可以产生多尺度空间的核，一个图像的尺度空间， L（ x,y,σ) ,定义为原始图像I(x,y)与一个可变尺度的2维高斯函数G(x,y,σ) 卷积运算。尺度是自然存在的，不是人为创造的！高斯卷积只是表现尺度空间的一种形式</p><script type="math/tex; mode=display">\begin{array}{c}{L(x, y, \sigma)=G(x, y, \sigma)^{*} I(x, y)} \\ {G\left(x_{i}, y_{i}, \sigma\right)=\frac{1}{2 \pi \sigma^{2}} \exp \left(-\frac{\left(x-x_{i}\right)^{2}+\left(y-y_{i}\right)^{2}}{2 \sigma^{2}}\right)}\end{array}</script><p>其中$ G(x,y,σ) $是尺度可变高斯函数$（x，y）$是空间坐标，是尺度坐标。σ大小决定图像的平滑程度，大尺度对应图像的概貌特征，小尺度对应图像的细节特征。大的σ值对应粗糙尺度(低分辨率)，反之，对应精细尺度(高分辨率)。为了有效的在尺度空间检测到稳定的关键点，提出了高斯差分尺度空间（DOG scale-space）。利用不同尺度的高斯差分核与图像卷积生成。</p><script type="math/tex; mode=display">\begin{aligned} D(x, y, \sigma) &=[G(x, y, k \sigma)-G(x, y, \sigma)] * I(x, y) \\ &=L(x, y, k \sigma)-L(x, y, \sigma) \end{aligned}</script><p>下图所示不同σ下图像尺度空间：<br><img src="chidu.jpeg" alt></p><p>图像金字塔的建立：</p><p>对于一幅图像I,建立其在不同尺度(scale)的图像，也成为子八度（octave），这是为了scale-invariant，也就是在任何尺度都能够有对应的特征点，第一个子八度的scale为原图大小，后面每个octave为上一个octave降采样的结果，即原图的1/4（长宽分别减半），构成下一个子八度（高一层金字塔）。</p><p><img src="jin1.jpeg" alt></p><p><img src="jin2.jpeg" alt></p><p>由图片size决定建几个塔，每塔几层图像(S一般为3-5层)。0塔的第0层是原始图像(或你double后的图像)，往上每一层是对其下一层进行Laplacian变换（高斯卷积，其中σ值渐大，例如可以是σ, k<em>σ, k</em>k*σ…），直观上看来越往上图片越模糊。塔间的图片是降采样关系，例如1塔的第0层可以由0塔的第3层down sample得到，然后进行与0塔类似的高斯卷积操作。</p><p>2、关键点检测</p><p>为了寻找尺度空间的极值点，每一个采样点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。 一个点如果在DOG尺度空间本层以及上下两层的26个领域中是最大或最小值时，就认为该点是图像在该尺度下的一个特征点,如图所示。<br><img src="jiance.jpeg" alt></p><p>同一组中的相邻尺度（由于k的取值关系，肯定是上下层）之间进行寻找，在极值比较的过程中，每一组图像的首末两层是无法进行极值比较的，为了满足尺度变化的连续性，我们在每一组图像的顶层继续用高斯模糊生成了3幅图像，高斯金字塔有每组S+3层图像。 DOG金字塔每组有S+2层图像。下图中s=3</p><p><img src="lianxu.jpeg" alt></p><p>这里解释下尺度变化的连续性：</p><p>假设s=3，也就是每个塔里有3层，则k=21/s=21/3，那么按照上图可得Gauss Space和DoG space 分别有3个（s个）和2个（s-1个）分量，在DoG space中，1st-octave两项分别是σ,kσ; 2nd-octave两项分别是2σ,2kσ;由于无法比较极值，我们必须在高斯空间继续添加高斯模糊项，使得形成σ,kσ,k2σ,k3σ,k4σ这样就可以选择DoG space中的中间三项kσ,k2σ,k3σ（只有左右都有才能有极值），那么下一octave中（由上一层降采样获得）所得三项即为2kσ,2k2σ,2k3σ，其首项2kσ=24/3。刚好与上一octave末项k3σ=23/3尺度变化连续起来，所以每次要在Gaussian space添加3项，每组（塔）共S+3层图像，相应的DoG金字塔有S+2层图像。</p><p>3、消除错配点</p><p>由于DoG值对噪声和边缘较敏感,因此,在上面DoG尺度空间中检测到局部极值点还要经过进一步的检验才能精确定位为特征点。为了提高关键点的稳定性，需要对尺度空间DoG函数进行曲线拟合。利用DoG函数在尺度空间的Taylor展开式：</p><script type="math/tex; mode=display">D(X)=D+\frac{\partial D^{T}}{\partial X} X+\frac{1}{2} X^{T} \frac{\partial^{2} D}{\partial X_{}^{2}} X</script><p>对上式求导,并令其为0,得到精确的位置, 得</p><script type="math/tex; mode=display">\hat{\mathrm{x}}=-\frac{\partial^{2} D^{-1}}{\partial \mathrm{x}^{2}} \frac{\partial D}{\partial \mathrm{x}}</script><p>在已经检测到的特征点中,要去掉低对比度的特征点和不稳定的边缘响应点。去除低对比度的点：把上式代入其中，即在DoG Space的极值点处D(x)取值，只取前两项可得：</p><script type="math/tex; mode=display">D(\hat{\mathbf{x}})=D+\frac{1}{2} \frac{\partial D^{T}}{\partial \mathbf{x}} \hat{\mathbf{x}}</script><p>若$|D(\hat x)|\geq 0.03$，该特征点就保留下来，否则丢弃。</p><p>4、关键点描述</p><p>上一步中确定了每幅图中的特征点，为每个特征点计算一个方向，依照这个方向做进一步的计算， 利用关键点邻域像素的梯度方向分布特性为每个关键点指定方向参数，使算子具备旋转不变性。</p><script type="math/tex; mode=display">\begin{array}{l}{m(x, y)=\sqrt{(L(x+1, y)-L(x-1, y))^{2}+(L(x, y+1)-L(x, y-1))^{2}}} \\ {\theta(x, y)=a \tan 2((L(x, y+1)-L(x, y-1)) /(L(x+1, y)-L(x-1, y)))}\end{array}</script><p>为(x,y)处梯度的模值和方向公式。其中<em>L</em>所用的尺度为每个关键点各自所在的尺度。至此，图像的关键点已经检测完毕，每个关键点有三个信息：位置，所处尺度、方向，由此可以确定一个SIFT特征区域。</p><p>计算keypoint周围的16*16的window中每一个像素的梯度，而且使用高斯下降函数降低远离中心的权重（高斯下降函数使得离关键点越近权重越大，越远越小）。</p><p><img src="16.jpeg" alt></p><p>在每个44的1/16象限中，通过加权梯度值加到直方图8个方向区间中的一个，计算出一个梯度方向直方图。这样就可以对每个feature形成一个448=128维的描述子，每一维都可以表示44个格子中一个的scale/orientation. 将这个向量归一化之后，就进一步去除了光照的影响。</p><p>5、关键点匹配</p><p>生成了A、B两幅图的描述子，（分别是k1<em>128维和k2</em>128维），就将两图中各个scale（所有scale）的描述子进行匹配，匹配上128维即可表示两个特征点match上了。</p><p>此时SIFT特征向量已经去除了尺度变化、旋转等几何变形因素的影响，再继续将特征向量的长度归一化，则可以进一步去除光照变化的影响。 当两幅图像的SIFT特征向量生成后，下一步我们采用关键点特征向量的欧式距离来作为两幅图像中关键点的相似性判定度量。取图像1中的某个关键点，并找出其与图像2中欧式距离最近的前两个关键点，在这两个关键点中，如果最近的距离除以次近的距离少于某个比例阈值，则接受这一对匹配点。降低这个比例阈值，SIFT匹配点数目会减少，但更加稳定。</p><h3 id="1-1-3-特征匹配"><a href="#1-1-3-特征匹配" class="headerlink" title="1.1.3 特征匹配"></a>1.1.3 特征匹配</h3><p>分两个阶段来考虑，第一阶段是选择一个匹配策略，用来确定哪些匹配将被传到下一阶段进行进一步处理；第二阶段是设计出行之有效的数据结构和算法来尽可能快的完成这个匹配。</p><p><strong>匹配策略和错误率</strong></p><p>给定一个欧式距离度量，最简单的一个匹配策略就是先设定-一个阈值(最大距离)，然后返回在这个阈值范围之内的其他图像中的所有匹配。这个阈值如果设的太高，就会产生很多“误报”(false positive)，也就是说，返回了不正确的匹配。这个阈值设的太低的话就会产生很多“漏报”(false negative), 也就是说，很多正确的匹配被丢失了。</p><p>我们可以在一个特定阈值上对一个匹配算法的性能进行量化，通过使用下面的定义(Fawcett2006)来计算正确和错误匹配及匹配失败的数目。<br>TP：正确肯定，也就是正确匹配的数目;<br>FN：漏报，没有正确找到的匹配的数目;<br>FP：误报，给出的匹配是不正确的;<br>TN：正确否定，正确拒绝的非匹配对。</p><p>则混淆矩阵：</p><p><img src="hunxiao.png" alt></p><p>正确肯定率（TPR）：</p><script type="math/tex; mode=display">\mathrm{TPR}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}=\frac{\mathrm{TP}}{\mathrm{P}}</script><p>错误肯定率（FPR）：</p><script type="math/tex; mode=display">\mathrm{FPR}=\frac{\mathrm{FP}}{\mathrm{FP}+\mathrm{TN}}=\frac{\mathrm{FP}}{\mathrm{N}}</script><p>肯定预测值（PPV）：</p><script type="math/tex; mode=display">\operatorname{PPV}=\frac{T P}{T P+F P}=\frac{T P}{P^{}}</script><p>精确度（ACC）：</p><script type="math/tex; mode=display">\mathrm{ACC}=\frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{P}+\mathrm{N}}</script><p>一个启发式的匹配策略是比较最近邻距离和次近邻距离，这个次近邻距离是从已知的和目标不匹配的一幅图像中取得的。我们可以定义这个最近邻距离比率</p><script type="math/tex; mode=display">\mathrm{NNDR}=\frac{d_{1}}{d_{2}}=\frac{ \| D_{A}-D_{B} |}{ \| D_{A}-D_{C} |}</script><p>其中$d_1$和$d_2$是最近邻的和次近邻距离，$D_A$是目标描述子（特征向量），$D_B$和$D_C$是它的最近的两个邻居。</p><p><strong>高效匹配</strong></p><p>匹配策略已经确定，接下来就需要确定搜索匹配策略，两幅图像匹配的一般策略的复杂度是提取特征数目的二次方，在应用中不太现实，所以需要改进搜索匹配策略。</p><p>【此部分待补充】</p><h3 id="1-1-4-特征跟踪"><a href="#1-1-4-特征跟踪" class="headerlink" title="1.1.4 特征跟踪"></a>1.1.4 特征跟踪</h3><p>在所有候选图像中独立地寻找特征然后将它们进行匹配，另一种替代策略是，在第一幅图像中寻找可能的特征位置集合，然后在后续的图像中搜索它们的对应位置。这类“先检测后跟踪”(detect and track)的方法在视频跟踪应用中使用得非常广泛，这里，所期望的相邻帧之间的运动和表观的变形比较小。<br>选择好特征来跟踪的过程和选择好特征来进行更一般的识别应用紧密相关。在实际中，那些在两个方向上梯度值均大的区域，也就是，自相关矩阵拥有大的特征<br>值的区域，提供了可用于寻找对应的稳定的位置。</p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数字图像处理基础</title>
      <link href="/2019/05/14/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/"/>
      <url>/2019/05/14/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="1-图像处理"><a href="#1-图像处理" class="headerlink" title="1 图像处理"></a>1 图像处理</h2><h3 id="1-1-点算子"><a href="#1-1-点算子" class="headerlink" title="1.1 点算子"></a>1.1 点算子</h3><p>操作特征：每个像素的输出值只取决于相应的输入像素值。 </p><h4 id="1-1-1-像素变换"><a href="#1-1-1-像素变换" class="headerlink" title="1.1.1 像素变换"></a>1.1.1 像素变换</h4><p>一般的图像处理算子是指一个或多个输入图像到一个输出图像的函数，在连续域中可表示为</p><script type="math/tex; mode=display">g(\boldsymbol{x})=h(f(\boldsymbol{x})) \text { or } g(\boldsymbol{x})=h\left(f_{0}(\boldsymbol{x}), \ldots, f_{n}(\boldsymbol{x})\right)</script><p>$x$属于函数的$D$维定义域，函数$f$和$g$在某个值域上操作。对于离散图像，定义域由有限个像素位置组成，$x=(i,j)$，此时$g(i, j)=h(f(i, j))$</p><p>常用的两个点算子是乘以和加上一个常数，$g(x)=af(x)+b$，$a$称为增益参数，$b$称为偏差参数。$a,b$也可以随着空间位置的不同而变化。</p><script type="math/tex; mode=display">g(\boldsymbol{x})=a(\boldsymbol{x}) f(\boldsymbol{x})+b(\boldsymbol{x})</script><p>二元算子是线性混合算子：</p><script type="math/tex; mode=display">g(\boldsymbol{x})=(1-\alpha) f_{0}(\boldsymbol{x})+\alpha f_{1}(\boldsymbol{x})</script><p>$\alpha \in[0,1]$，此算子可以实现两幅图像或视频间的时间上的淡入淡出。</p><p>伽马矫正是图像预处理阶段经常使用的非线性算子，它可以去除输入辐射量和量化的像素值之间的非线性映射</p><script type="math/tex; mode=display">g(\boldsymbol{x})=[f(\boldsymbol{x})]^{1 / \gamma}</script><p>$\gamma$经常取2.2</p><h4 id="1-1-2-彩色变换"><a href="#1-1-2-彩色变换" class="headerlink" title="1.1.2 彩色变换"></a>1.1.2 彩色变换</h4><p>彩色变换是对彩色图像的三个通道分别操作，比如色彩平衡（白炽光光照的补偿）可以通过对每个通道乘以不同的尺度因子来实现，也可以采用更复杂的处理过程，将RGB映射到XYZ彩色空间。</p><h4 id="1-1-3-合成与抠图"><a href="#1-1-3-合成与抠图" class="headerlink" title="1.1.3 合成与抠图"></a>1.1.3 合成与抠图</h4><p>覆盖算子：$C=(1-\alpha)B+\alpha F$，这个算子通过$(1-\alpha)$因子减弱了背景图像$B$的影响，加入了对应于前景层图像$F$的彩色值（和不透明度，一共4维）</p><h4 id="1-1-4-直方图均衡化"><a href="#1-1-4-直方图均衡化" class="headerlink" title="1.1.4 直方图均衡化"></a>1.1.4 直方图均衡化</h4><p>见其他笔记</p><h2 id="1-2-线性滤波"><a href="#1-2-线性滤波" class="headerlink" title="1.2 线性滤波"></a>1.2 线性滤波</h2><p><strong>何谓图像滤波？</strong></p><p>图像滤波即在尽量保留图像细节特征的条件下对目标图像的噪声进行抑制，是图像预处理中不可缺少的操作，其处理效果的好坏将直接影响到后续图像处理和分析的有效性和可靠性。</p><p>信号或图像的能量大部分集中在幅度谱的低频和中频段是很常见的，而在较高频段，感兴趣的信息经常被噪声淹没。因此一个能降低高频成分幅度的滤波器就能够减弱噪声的影响。</p><p> 低通滤波能保留图像的大致轮廓信息是因为，一张图像所记录到的主要信息（由于受到关照等必然因素的影响）在图像上灰度值的变化是缓慢的，因此主要信息集中在低频区域。而噪音等偶然因素是突然附加到图像上使得灰度值快速变化，而且密密麻麻，这导致N个像元内，灰度值的变化不仅频繁，而且变化的范围还很大。因此，噪音就位于图像频谱的高频区域，表现为高灰度值。</p><p><strong>图像滤波的目的</strong></p><p>一是抽出对象的特征作为图像识别的特征模式;<br>二是为适应图像处理的要求，消除图像数字化时所混入的噪声。</p><p><strong>图像滤波的要求</strong></p><p>一是不能损坏图像的轮廓及边缘等重要信息;<br>二是使图像清晰视觉效果好。</p><p>邻域算子（局部算子）是利用给定像素周围的像素的值决定次像素的最终输出值。可用于局部色调调整，还可用于图像滤波，实现图像的平滑和锐化，图像边缘的增强或者图像噪声的去除。</p><p>关于滤波器，一种形象的比喻法是:我们可以把滤波器想象成一个包含加权系数的窗口，当使用这个滤波器平滑处理图像时，就把这个窗口放到图像之上，透过这个窗口来看我们得到的图像。如下邻域算子的介绍。</p><p><img src="juanji.png" alt></p><p>线性滤波算子是一种常用的邻域算子，指用不同的权重结合一个小的邻域内的像素。</p><script type="math/tex; mode=display">g(i, j)=\sum_{k . l} f(i+k \cdot j+l) h(k . l)</script><p>其中权重核或掩膜$h(k,l)$常称为”滤波系数”，上面公式可简写为：$g=f \otimes h$<br>上述公式也常变形为：</p><script type="math/tex; mode=display">g(i, j)=\sum_{k . l} f(i-k, j-l) h(k, l)=\sum_{k, l} f(k, l) h(i-k, j-l)</script><p>此公式称为”卷积公式”，记做$g=f * h$</p><p>相关和卷积运算都可以用矩阵和向量的乘法来表示，如：<br><img src="juzhenjuanji.png" alt></p><p><strong>填塞（边界效应）</strong></p><p>如上图所示的卷积矩阵运算会产生边界效应，即采用这种形式的图像滤波会使角点处的像素变黑（乘积为0）。主要是因为当卷积核超出原始图像边界时，原始图像边界外的部分被认为是有效的，并用0填充（0为黑）</p><p>为了抵消这种效应，可以采用一些对图像填塞或扩展的模式</p><ul><li>0填塞：将原图像之外的像素的值设置为0</li><li>常数填塞（边框彩色）：在原图像外的像素的值设置为确定的边界值</li><li>夹取填塞（复制或夹取边缘）：不限定地复制边缘像素的值</li><li>重复填塞：以环状形态环绕图像进行循环</li><li>镜像填塞：像素围绕图像边界进行镜像反射</li><li>延长：通过在边缘像素值中减去镜像信号的方式延长信号</li></ul><h3 id="1-2-1-可分离的滤波"><a href="#1-2-1-可分离的滤波" class="headerlink" title="1.2.1 可分离的滤波"></a>1.2.1 可分离的滤波</h3><p>对于卷积运算的实现，每个像素需要$K^2$次操作（乘-加），$K$是卷积核的大小。在许多情况下，这种运算可以采用如下计算方式来大幅度提高运算速度：先用一维行向量进行卷积，接着用一维列向量进行卷积。这样每个像素总共需要$2K$次操作。如果一个卷积核可以采用上述方式进行计算，则称其为可分离的。</p><p><img src="fenlijuanji.png" alt></p><p>如果给定一个核函数$K$，如何判断它是不是可分离的呢？更直接的方法是将$2D$核函数看成一个$2D$矩阵$K$并且对其进行奇异值分解（SVD）</p><script type="math/tex; mode=display">\boldsymbol{K}=\sum_{i} \sigma_{i} \boldsymbol{u}_{i} \boldsymbol{v}_{i}^{T}</script><p>当仅有第一个奇异值$\sigma_0$是非$0$值时，核函数是可分离的，$\sqrt{\sigma_{0}} u_{0}$和$\sqrt{\sigma_{0}} v_{0}^{T}$分别提供了垂直核函数和水平核函数。</p><h3 id="1-2-2-带通和导向滤波器"><a href="#1-2-2-带通和导向滤波器" class="headerlink" title="1.2.2 带通和导向滤波器"></a>1.2.2 带通和导向滤波器</h3><p><strong>高斯滤波器</strong>平滑图像：</p><script type="math/tex; mode=display">G(x, y ; \sigma)=\frac{1}{2 \pi \sigma^{2}} e^{-\frac{x^{2}+y^{2}}{2 \sigma^{2}}}</script><p><strong>Laplacian算子</strong>（带通滤波器）对二维图像求二阶导数（无方向）:</p><script type="math/tex; mode=display">\nabla^{2} f=\frac{\partial^{2} f}{\partial x^{2}}+\frac{\partial^{2} f}{\partial y^{2}}</script><p><strong>LoG</strong>（Laplacian of Gaussian）算子：首先用高斯核平滑图像，再用Laplacian算子作用于图像。</p><script type="math/tex; mode=display">\nabla^{2} G(x, y ; \sigma)=\left(\frac{x^{2}+y^{2}}{\sigma^{4}}-\frac{2}{\sigma^{2}}\right) G(x, y ; \sigma)</script><p><strong>Sobel 算子</strong>是一个主要用作<strong>边缘检测</strong>的离散微分算子 (discrete differentiation operator)。 Sobel算子结合了高斯平滑和微分求导，用来计算图像灰度函数的近似梯度。在图像的任何一点使用此算子，将会产生对应的梯度矢量或是其法矢量（带方向）。</p><p><img src="sobel.png" alt></p><p><img src="sobel2.png" alt></p><p>Sobel算子根据像素点上下、左右邻点灰度加权差，在边缘处达到极值这一现象检测边缘。对噪声具有平滑作用，提供较为精确的边缘方向信息，边缘定位精度不够高。当对精度要求不是很高时，是一种较为常用的边缘检测方法。<a href="https://my.oschina.net/freeblues/blog/727561" target="_blank" rel="noopener">https://my.oschina.net/freeblues/blog/727561</a></p><p><strong>区域求和表</strong></p><p>区域求和表是指一定区域内所有像素的值的和：</p><script type="math/tex; mode=display">s(i, j)=\sum_{k=0}^{i} \sum_{l=0}^{j} f(k, l)</script><p>从图像的左上角元素开始递归计算，则区域求和的增量公式，即区域求和表的每个元素值为：</p><script type="math/tex; mode=display">s(i, j)=s(i-1, j)+s(i, j-1)-s(i-1, j-1)+f(i, j)</script><p>图像$s(i,j)$也被称为积分图像。在计算机视觉中，人脸检测可利用区域求和表来计算简单的多尺度上的底层特征。<br><img src="qiuhe.png" alt></p><p>（a）为原始图像；（b）为区域求和表</p><p><strong>递归滤波器</strong></p><p>区域求和的增量公式是递归滤波器的一个典型例子。递归滤波器是指输出值取决于前一个滤波器的输出值。这种滤波器又称为”无限脉冲响应（IIR）”，因为对于脉冲信号（只有一个非零值），IIR的输出是无限的。本章前面所研究的用一个有限区域核卷积图像的滤波器称作”有限脉冲响应（FIR）”。<br>IIR滤波器常用于可分离的一维滤波阶段，计算大范围的平滑核。</p><h2 id="1-3-更多的邻域算子"><a href="#1-3-更多的邻域算子" class="headerlink" title="1.3 更多的邻域算子"></a>1.3 更多的邻域算子</h2><h3 id="1-3-1-非线性滤波"><a href="#1-3-1-非线性滤波" class="headerlink" title="1.3.1 非线性滤波"></a>1.3.1 非线性滤波</h3><p>前面考虑的是线性滤波，然而在很多情况下，使用邻域像素的非线性组合可能会得到更好的效果。例如当噪声是散粒噪声，而不是高斯噪声，即图像偶尔会出现很大的值。这种情况下，用高斯滤波器对图像进行模糊，噪声像素是不会被去除的，只会转换为更加柔和但仍然可见的散粒。</p><p><strong>中值滤波</strong></p><p>对于散粒噪声这种情况，使用中值滤波是一个较好的选择。中值滤波器选择每个像素的邻域像素的中值作为输出。这个邻域称之为窗，窗开的越大，输出的结果越平滑，但过大的窗也可能把我们有用的信号特征给抹除。由于散粒噪声通常位于邻域内正常值的两端，故中值滤波可以对这类异常像素进行过滤。</p><p>中值滤波有个不足，即由于中值滤波只选择一个像素作为输出像素，所以一般很难有效去除规则的高斯噪声。</p><p>$\alpha$<strong>截尾均值滤波</strong>会对散粒噪声和高斯噪声做一个折衷，具体做法是指去除百分率为$\alpha$的最小值和最大值后剩下的像素的均值。</p><p>另一种方法是<strong>加权中值滤波</strong>：加权中值滤波是将窗口内的每一个像素都乘上一个相应的权值，然后利用乘上权值后的值进行排序，取中值替换中心元素的灰度值即可。中值滤波可以看做是每个像素的权值都是1的加权中值滤波。权重目标函数最小化如下：</p><script type="math/tex; mode=display">\sum_{k, l} w(k, l)|f(i+k, j+l)-g(i, j)|^{p}</script><p><strong>双边滤波器</strong></p><p>双边滤波器与高斯滤波器相比，对于图像的边缘信息能够更好的保存，其原理为一个与空间距离相关的高斯函数与一个灰度距离相关的高斯函数相乘。等于是双边滤波器既结合了空间距离信息，又结合了灰度距离（值域）信息。</p><p>在双边滤波器中，输出像素的值依赖于邻域像素的值的加权组合：</p><script type="math/tex; mode=display">g(i, j)=\frac{\sum_{k, l} f(k, l) w(i, j, k, l)}{\sum_{k, l} w(i, j, k, l)}</script><p>权重系数$w(i,j,k,l)$取决于定义域核</p><script type="math/tex; mode=display">d(i, j, k, l)=\exp \left(-\frac{(i-k)^{2}+(j-l)^{2}}{2 \sigma_{d}^{2}}\right)</script><p>和依赖于数据的值域核</p><script type="math/tex; mode=display">r(i, j, k, l)=\exp \left(-\frac{\|f(i, j)-f(k, l)\|^{2}}{2 \sigma_{r}^{2}}\right)</script><p>的乘积。它们相乘后，就会产生依赖于数据的双边权重函数</p><script type="math/tex; mode=display">w(i, j, k, l)=\exp \left(-\frac{(i-k)^{2}+(j-l)^{2}}{2 \sigma_{d}^{2}}-\frac{\|f(i, j)-f(k, l)\|^{2}}{2 \sigma_{r}^{2}}\right)</script><h3 id="1-3-2-形态学"><a href="#1-3-2-形态学" class="headerlink" title="1.3.2 形态学"></a>1.3.2 形态学</h3><p>形态学，即数学形态学(mathematical Morphology)，是图像处理中应用最为广泛的技术之一，主要用于从图像中提取对表达和描绘区域形状有意义的图像分量，使后续的识别工作能够抓住目标对象最为本质（最具区分能力一most discriminative)的形状特征，如边界和连通区域等。同时像细化、像素化和修剪毛刺等技术也常应用于图像的预处理和后处理中，成为图像增强技术的有力补充。在数字图像处理中，形态学是借助集合论的语言来描述的。</p><p>设有两幅图像A, S。若A是被处理的对象， 而S是用来处理A的， 则称S为结构元素。结构元素通常都是一些比较小的图像， A与S的关系类似于滤波中图像和模板的关系。</p><p>以下介绍的是二值图像的基本形态学操作，包括腐蚀、膨胀、以及开、闭运算。所有形态学运算都是针对图像的前景物体进行的，在二值图像中，默认白色（接近255）为前景物体，黑色（接近0）为背景。</p><p><strong><em>腐蚀</em></strong></p><p>腐蚀和膨胀是两种最基本的形态学操作，其他的形态学算法都是由这两种基本运算复合而成的。<br><img src="fushi.png" alt></p><p>腐蚀的作用“ 顾名思义，腐蚀能够消融物体的边界，而具体的腐蚀结果与图像本身和结构元素的形状有关。如果物体整体上大于结构元素，腐蚀的结构是使物体变“ 瘦”一圈，而 这一圈到底有多大是由结构元素决定的：如果物体本身小于结构元素， 则在腐蚀后的图像中物体将完全消失：如物体仅有部分区域小于结构元素〈如细小的连通3，则腐蚀后物体会在细连通处断裂，分离为两部分。</p><p>随着腐蚀结构元素的逐步增大，小于结构元素的物体相继消失。由于腐蚀运算具有上述的特点，可以用于滤波。选择适当大小和形状的结构元素，可以滤除掉所有不能 完全包含结构元素的噪声点。然而，利用腐蚀滤除噪声有一个缺点，即在去除噪声点的同时，对图像中前景物体的形状也会有影响，但当我们只关心物体的位置或者个数时，则影响不大。</p><p><strong><em>膨胀</em></strong></p><p><img src="pengzhang.png" alt></p><p>膨胀的作用和腐蚀相反， 膨胀能使物体边界扩大， 具体的膨胀结果与图像本身和结构元素的形状有关。膨胀常用于将图像中原本断裂开来的同一物体桥接起来， 对图像进行二值化之后， 很容易使一个连通的物体断裂为两个部分， 而这会给后续的图像分析（如要基于连通区域的分析统计物体的个数〉造成困扰，此时就可借助膨胀桥接断裂的缝隙。</p><p><strong><em>开运算</em></strong></p><p>开运算和闭运算都由腐蚀和膨胀复合而成， 开运算是先腐蚀后膨胀， 而闭运算是先膨胀后腐蚀。</p><p>一般来说， 开运算可以使图像的轮廓变得光滑， 还能使狭窄的连接断开和消除细毛刺。 如图8.11所示， 开运算断开了团中两个小区域间两个像素宽的连接〈断开了狭窄连接〉，并且去除了右侧物体上部突出的一个小于结构元素的2×2的区域〈去除细小毛刺〉： 但与腐蚀不同的是， 图像大的轮廓并没有发生整体的收缩， 物体位置也没有发生任何变化。 </p><p>根据图8.12 的开运算示意图， 可以帮助大家更好地理解开运算的特点。为了比较， 图中也标示出了相应的腐蚀运算的结果： </p><p><img src="kai.png" alt></p><p><img src="kai2.png" alt></p><p><strong><em>闭运算</em></strong></p><p>闭运算同样可以使轮廓变得光滑， 但与开运算相反， 它通常能够弥合狭窄的间断， 填充小的孔洞。 </p><p><img src="bi.png" alt></p><h3 id="1-3-3-距离变换"><a href="#1-3-3-距离变换" class="headerlink" title="1.3.3 距离变换"></a>1.3.3 距离变换</h3><p>图像的距离变换实现了像素与图像区域的距离变换，对于变换后的距离图像来说，图像中的每个像素的灰度值为该像素与距离其最近的背景像素间的距离，也就是说，给每个像素赋值为离它最近的背景像素点与其距离。这样可以实现二值图像转化为灰度图像。</p><p>根据度量距离的方法不同，距离变换有几种不同的方法，假设像素点$P_1(x_1,y_1),P_2(x_2,y_2)$计算距离的方法常见的有：<br>1、欧式距离，$Distance=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$<br>2、曼哈顿距离，$Distance=|x_2-x_1|+|y_2-y_1|$</p><p>距离变换的一般步骤如下：<br>1、将输入图片转换为二值图像，前景设置为1，背景设置为0；<br>2、自左上起依次进行距离变换：</p><script type="math/tex; mode=display">D(i, j)=\min _{k, l : b(k . l)=0} d(i-k, j-l)</script><p><img src="juli.png" alt></p><p>(a)为原始的二值图像，(b)自顶向下扫描，距离变换，(c)递归计算，(d)距离变换的结果</p><h3 id="1-3-4-连通量"><a href="#1-3-4-连通量" class="headerlink" title="1.3.4 连通量"></a>1.3.4 连通量</h3><p><img src="linyu.jpg" alt></p><h2 id="1-4-傅里叶变换"><a href="#1-4-傅里叶变换" class="headerlink" title="1.4 傅里叶变换"></a>1.4 傅里叶变换</h2><p>傅立叶变换公式，在连续域中</p><script type="math/tex; mode=display">H(\omega)=\int_{-\infty}^{\infty} h(x) e^{-j \omega x} d x</script><p>在离散域中</p><script type="math/tex; mode=display">H(k)=\frac{1}{N} \sum_{x=0}^{N-1} h(x) e^{-j \frac{2 \pi k x}{N}}</script><p>傅立叶变换的性质：<br><img src="xingzhi.png" alt></p><p>傅立叶变换对：<br><img src="dui.png" alt></p><p>图像处理领域用到的傅里叶变换是二维的（长宽方向进行离散傅立叶变换），其目的是得到空间图像的频率分布情况，之后在频率域对图像进行各种处理可以有目的地实现很多功能。如降噪是弱化频率过高的像素点，图像压缩是对图像高频部分的信息进行简化处理，其余的应用还有图像边缘增强、纹理分析等。DC在二维图像信号中表示整幅图像的平均亮度。二维傅里叶图谱中越亮的点对应图像中对比度越大的点，原图频率越集中，对应的频谱图中亮点就越集中。 </p><h3 id="1-4-1-维纳滤波"><a href="#1-4-1-维纳滤波" class="headerlink" title="1.4.1 维纳滤波"></a>1.4.1 维纳滤波</h3><p>在数学应用上，对于运动引起的图像模糊，最简单的方法是直接做逆滤波，但是逆滤波对加性噪声特别敏感，使得恢复的图像几乎不可用。<strong>最小均方差</strong>（维纳）滤波用来去除含有噪声的模糊图像，其目标是找到未污染图像的一个估计，使它们之间的均方差最小，可以去除噪声，同时清晰化模糊图像。</p><p><strong>定义</strong></p><p>给定一个系统</p><script type="math/tex; mode=display">y(t)=h(t) * x(t)+n(t)</script><p>这里，$*$是卷积符号。<br>$x(t)$是在时间tt刻输入的信号（未知）<br>$h(t)$是一个线性时间不变系统的脉冲响应（已知）<br>$n(t)$是加性噪声，与x(t)x(t)不相关（未知）<br>$y(t)$是我们观察到的信号 </p><p>我们的目标是找出这样的卷积函数$g(t)$，这样我们可以如下得到估计的$x(t)$： </p><script type="math/tex; mode=display">\hat{x}(t)=g(t) * y(t)</script><p>这里$\hat x(t)$是$x(t)$的最小均方差估计。<br>基于这种误差度量，滤波器可以在频率域如下描述：</p><script type="math/tex; mode=display">\begin{aligned} G(f) &=\frac{H^{*}(f) S(f)}{|H(f)|^{2} S(f)+N(f)} \\ &=\frac{H^{*}(f)}{|H(f)|^{2}+N(f) / S(f)} \end{aligned}</script><p>这里：<br>$G(f)$ 和$H(f)$是$g$和$h$在频率域ff的傅里叶变换。<br>$S(f)$是输入信号$x(t)$的功率谱。<br>$N(f)$是噪声的$n(t)$的功率谱。<br>上标$*$代表复数共轭。 </p><p>滤波过程可以在频率域完成： </p><script type="math/tex; mode=display">\hat{X}(f)=G(f) * Y(f)</script><p>这里 $\hat X (f)$是 $\hat x (t)$的傅里叶变换，通过逆傅里叶变化可以得到去卷积后的结果$\hat x (t)$。</p><p><strong>解释</strong></p><p>上面的式子可以改写成更为清晰的形式 </p><script type="math/tex; mode=display">\begin{aligned} G(f) &=\frac{1}{H(f)}\left[\frac{|H(f)|^{2}}{|H(f)|^{2}+\frac{N(f)}{S( )}}\right] \\ &=\frac{1}{H(f)}\left[\frac{|H(f)|^{2}}{|H(f)|^{2}+\frac{1}{S N R(f)}}\right] \end{aligned}</script><p>这里$H(f)$是$h$在频率域ff的傅里叶变换。$SNR(f)=S(f)/N(f)$是信号噪声比。当噪声为零时（即信噪比趋近于无穷），方括号内各项也就等于1，意味着此时刻维纳滤波也就简化成逆滤波过程。但是当噪声增加时，信噪比降低，方括号里面值也跟着降低。这说明，维纳滤波的带通频率依赖于信噪比。</p><p><strong>推导</strong></p><p>上面直接给出了维纳滤波的表达式，接下来介绍推导过程。<br>上面提到，维纳滤波是建立在最小均方差，可以如下表示： </p><script type="math/tex; mode=display">e(f)=E|X(f)-\hat{X}(f)|^{2}</script><p>这里$E$是期望。<br>如果我们替换表达式中的$\hat X(f)$，上面可以重新组合成 </p><script type="math/tex; mode=display">\begin{aligned} e(f) &=E|X(f)-G(f) Y(f)|^{2} \\ &=E|X(f)-G(f)[H(f) X(f)+V(f)]|^{2} \\ &=E|[1-G(f) H(f)] X(f)-G(f) V(f)|^{2} \end{aligned}</script><p>展开二次方，得到下式</p><script type="math/tex; mode=display">\begin{aligned} e(f) &=[1-G(f) H(f)][1-G(f) H(f)]^{*} E|\mathrm{X}(\mathrm{f})|^{2} \\ &-[1-G(f) H(f)] G^{*}(f) E\left\{X(f) V^{*}(f)\right\} \\ &-G(f)[1-G(f) H(f)]^{*} E\left\{V(f) X^{*}(f)\right\} \\ &+G(f) G^{*}(f) E|V(f)|^{2} \end{aligned}</script><p>然而，我们假设噪声与信号独立无关，这样有 </p><script type="math/tex; mode=display">E\left\{X(f) V^{*}(f)\right\}=E\left\{V(f) X^{*}(f)\right\}=0</script><p>并且我们如下定义功率谱 </p><script type="math/tex; mode=display">\begin{aligned} S(f) &=E|X(f)|^{2} \\ N(f) &=E|V(f)|^{2} \end{aligned}</script><p>这样有</p><script type="math/tex; mode=display">e(f)=[1-G(f) H(f)][1-G(f) H(f)]^{*} S(f)+G(f) G^{*}(f) N(f)</script><p>为了得到最小值，我们对$G(f)$求导，令方程等于零。</p><script type="math/tex; mode=display">\frac{\mathrm{d}(f)}{\mathrm{d} G(f)}=G^{*}(f) N(f)-H(f)[1-G(f) H(f)]^{*} S(f)=0</script><p>由此最终推出维纳滤波器。</p><h2 id="1-5-金字塔与小波"><a href="#1-5-金字塔与小波" class="headerlink" title="1.5 金字塔与小波"></a>1.5 金字塔与小波</h2><p>前面所研究的是所有图像变换所产生的图像都与输入图像大小相同。但是在一些情况下需要得到不同大小的图像，比如在人脸识别中，由于我们不知道人脸可能出现的尺寸，所以需要生成一个不同大小的图像组成的金字塔，扫描其中每幅图像来寻找可能的人脸。生物视觉系统也会处理分层次的尺寸。通过这样的金字塔，可以先粗粒度的寻找，再细粒度的寻找。<br>改变图像分辨率的操作叫做上采样（插值）和下采样（降采样）。</p><h3 id="1-5-1-上采样（插值）"><a href="#1-5-1-上采样（插值）" class="headerlink" title="1.5.1 上采样（插值）"></a>1.5.1 上采样（插值）</h3><p>要将一幅图像插值到较高分辨率，我们需要选择一些插值核来卷积图像。</p><script type="math/tex; mode=display">g(i, j)=\sum_{k, l} f(k, l) h(i-r k, j-r l)</script><p>这个公式与离散卷积公式有关，我们只是将$h()$中的$k$和$l$替换为$rk$和$rl$，其中，$r$为上采样率。<br>目前比较常用的插值算法有：最近邻插值、双线性内插法、三次内插法</p><p><strong>最近邻插值</strong></p><p>这是最简单的插值方法，不需计算，在待求象素的四邻象素中，将距离待求象素最近的邻象素灰度赋给待求象素。<br><img src="zuijinlin.png" alt><br>最近邻法计算量小，但可能会造成插值生成的图像灰度上的不连续，在灰度变化的地方可能出现明显的锯齿状。</p><p><strong>双线性内插法</strong></p><p>双线性内插法是利用待求象素四个邻象素的灰度在两个方向上作线性内插，如下图所示：<br><img src="shuangxianxing.png" alt></p><p>$f(i+u,j+v)=(1-u)<em>(1-v)</em>f(i,j)+(1-u)<em>v</em>f(i,j+1)+u<em>(1-v)</em>f(i+1,j)+u<em>v</em>f(i+1,j+1)$</p><p>双线性内插法的计算比最邻近点法复杂，计算量较大，但没有灰度不连续的缺点，结果基本令人满意。它具有低通滤波性质，使高频分量受损，图像轮廓可能会有一点模糊。</p><p><strong>三次内插法</strong></p><p>该方法利用三次多项式$S(x)$求逼近理论上最佳插值函数$sin(x)/x$, 其数学表达式为：</p><script type="math/tex; mode=display">S(x)=\left\{\begin{array}{ll}{1-2|x|^{2}+|x|^{3}} & {0 \leq|x|<1} \\ {4-8|x|+5|x|^{2}-|x|^{3}} & {1 \leq|x|<2} \\ {0} & {|x| \geq 2}\end{array}\right.</script><p>待求像素(x, y)的灰度值由其周围16个灰度值加权内插得到，如下图：<br><img src="sanci.png" alt><br>待求像素的灰度计算式如下：</p><script type="math/tex; mode=display">f(x, y)=f(i+u, j+v)=A B C</script><p>其中：<br>$A=\left( \begin{array}{c}{S(1+v)} \\ {S(v)} \\ {S(1-v)} \\ {S(2-v)}\end{array}\right)^{\top}$ $C=\left( \begin{array}{c}{\mathrm{S}(1+\mathrm{u})} \\ {\mathrm{S}(\mathrm{u})} \\ {\mathrm{S}(1-\mathrm{u})} \\ {\mathrm{S}(2-\mathrm{u})}\end{array}\right)$</p><script type="math/tex; mode=display">B=\left( \begin{array}{cccc}{f(i-1, j-1)} & {f(i-1, j)} & {f(i-1, j+1)} & {f(i-1, j+2)} \\ {f(i, j-1)} & {f(i, j)} & {f(i, j+1)} & {f(i, j+2)} \\ {f(i+1, j-1)} & {f(i+1, j)} & {f(i+1, j+1)} & {f(i+1, j+2)} \\ {f(i+2, j-1)} & {f(i+2, j)} & {f(i+2, j+1)} & {f(i+2, j+2)}\end{array}\right)</script><p>三次曲线插值方法计算量较大，但插值后的图像效果最好。</p><h3 id="1-5-2-降采样"><a href="#1-5-2-降采样" class="headerlink" title="1.5.2 降采样"></a>1.5.2 降采样</h3><p>降采样则要求降低分辨率，与插值一样，我们用一个低通滤波器来卷积图像，平滑核$h(k,l)$常常是一个插值核的拉伸和重缩放版本。</p><script type="math/tex; mode=display">g(i, j)=\frac{1}{r} \sum_{k, l} f(k, l) h(i-k / r, j-l / r)</script><p>插值核降采样中使用的核函数$h(k,l)$是相同的。</p><h3 id="1-5-3-多分辨率表达"><a href="#1-5-3-多分辨率表达" class="headerlink" title="1.5.3 多分辨率表达"></a>1.5.3 多分辨率表达</h3><p>图像金字塔是一种以多分辨率来解释图像的结构，通过对原始图像进行多尺度像素采样的方式，生成N个不同分辨率的图像。把具有最高级别分辨率的图像放在底部，以金字塔形状排列，往上是一系列像素（尺寸）逐渐降低的图像，一直到金字塔的顶部只包含一个像素点的图像，这就构成了传统意义上的图像金字塔。<br><img src="jinzita.jpg" alt></p><p>获得图像金字塔一般包括二个步骤：<br>1、利用低通滤波器平滑图像<br>2、对平滑图像进行抽样（采样）<br>有两种采样方式——上采样（分辨率逐级升高）和下采样（分辨率逐级降低）</p><p><strong>高斯金字塔</strong></p><p>高斯金字塔式在Sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是有很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval）。</p><p>高斯金字塔构建过程：</p><ol><li>先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（其实就是高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层，高斯卷积函数为：<script type="math/tex; mode=display">G(x, y)=\frac{1}{2 \pi \sigma^{2}} e^{-\frac{\left(x-x_{0}\right)^{2}+\left(y-y_{0}\right)^{2}}{2 \sigma^{2}}}</script></li></ol><p>​       对于参数σ，在Sift算子中取的是固定值1.6。</p><ol><li>将σ乘以一个比例系数k,等到一个新的平滑因子σ=k*σ，用它来平滑第1组第2层图像，结果图像作为第3层。</li><li>如此这般重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：0，σ，kσ，k^2σ,k^3σ……k^(L-2)σ。</li><li>将第1组倒数第三层图像作比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像做平滑因子为σ的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：0，σ，kσ，k^2σ,k^3σ……k^(L-2)σ。但是在尺寸方面第2组是第1组图像的一半。</li></ol><p>这样反复执行，就可以得到一共O组，每组L层，共计O*L个图像，这些图像一起就构成了高斯金字塔，结构如下：<br><img src="gaosijinzita.png" alt></p><p>在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子σ是前一层图像平滑因子的k倍；<br>在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</p><p><strong>尺度空间</strong></p><p>图像的尺度空间解决的问题是如何对图像在所有尺度下描述的问题。<br>在高斯金字塔中一共生成O组L层不同尺度的图像，这两个量合起来（O，L）就构成了高斯金字塔的尺度空间，也就是说以高斯金字塔的组O作为二维坐标系的一个坐标，不同层L作为另一个坐标，则给定的一组坐标（O,L）就可以唯一确定高斯金字塔中的一幅图像。<br>尺度空间的形象表述：<br><img src="chidukongjian.png" alt></p><p>上图中尺度空间中k前的系数n表示的是第一组图像尺寸是当前组图像尺寸的n倍。</p><p><strong>DOG金字塔</strong></p><p>差分金字塔，DOG（Difference of Gaussian）金字塔是在高斯金字塔的基础上构建起来的，其实生成高斯金字塔的目的就是为了构建DOG金字塔。<br>DOG金字塔的第1组第1层是由高斯金字塔的第1组第2层减第1组第1层得到的。以此类推，逐组逐层生成每一个差分图像，所有差分图像构成差分金字塔。概括为DOG金字塔的第o组第l层图像是有高斯金字塔的第o组第l+1层减第o组第l层得到的。<br>DOG金字塔的构建可以用下图描述：</p><p><img src="DOG.png" alt></p><p>每一组在层数上，DOG金字塔比高斯金字塔少一层。后续Sift特征点的提取都是在DOG金字塔上进行的。<br>DOG金字塔的显示效果如下：<br><img src="DOG1.png" alt></p><p>这些长得黑乎乎的图像就是差分金字塔的实际显示效果，只在第1组第1层差分图像上模糊可以看到一个轮廓。但其实这里边包含了大量<strong>特征点信息</strong>，只是我们人眼已经分辨不出来了。<br>下边对这些DOG图像进行归一化，可有很明显的看到差分图像所蕴含的特征，并且有一些特征是在不同模糊程度、不同尺度下都存在的，这些特征正是Sift所要提取的“稳定”特征：<br><img src="DOG2.png" alt></p><p><strong>拉普拉斯金字塔</strong></p><p>在高斯金字塔的运算过程中，图像经过卷积和下采样操作会丢失部分高频细节信息。为描述这些高频信息，人们定义了拉普拉斯金字塔(Laplacian Pyramid， LP)。用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像即为 LP 分解图像。</p><h3 id="1-5-4-小波"><a href="#1-5-4-小波" class="headerlink" title="1.5.4 小波"></a>1.5.4 小波</h3><p>傅里叶变换可以将信号表示为无限三角函数的累加形式，从而实现将信号从空间域到频率域的转换。然而这种转换丢失了信号时空域的信息（只知道频率及其幅值，但不知道该频率发生的空间位置，可以类比直方图），因此无法做局部分析。<br>短时傅里叶变换通过引入一个时间窗函数试图改进傅里叶的局部缺陷，但由于窗函数的尺寸是固定的，不能同时对信号高频和低频做精确分析。<br>小波变换基于可自动调节尺寸的窗函数（图像金字塔），在时域和频域均具有良好的局部化性能，被誉为“数学显微镜”。<br>小波变换在图像处理上可用于去噪、边缘提取（实质就是突出低频或高频），但最主要的应用在于图像压缩。</p><p>既然图像金字塔和小波都将一幅图像分解为空间和频率内的多分辨率描述，它们有什么不同呢?通常的答案是，传统金字塔过于完备，即它们比原图使用更多像素来描述图像分解，而小波提供了一个紧致框架，即它们保持分解图像与原图像大小相等。但是实际上，有一些小波族也是过完备的，以提供更好的移位能力或者方向导向。因此，更好的区别可能是，与常规的带通金字塔相比，小波的方向选择性更佳。</p><p>傅里叶变换将信号分解为不同频率的三角函数之和的形式，小波变换则以尺度函数和小波函数为基，将信号分解。<br>在这里，尺度是通过不断对图像做下采样以建立图像金字塔得到的。<br>尺度函数由低通滤波器构造，小波函数由高通滤波器实现。一次分解有一组小波函数组成（类似傅里叶变换中不同频率的三角函数），这组小波函数由一个母小波函数通过缩放和平移生成。</p><p><img src="xiaobo1.png" alt></p><p>如图2-1所示，h0为尺度函数，h1为小波函数，相应的操作为卷积。结果的f0为上一级的低频近似，f1为上一级水平方向的高频近似，f2为上一级垂直方向的高频近似，f3为上一级对角线方向的高频近似。</p><p><img src="xiaobo2.png" alt></p><p>这里每次的分解都是从上级的低频近似开始，因为图像的大部分信息在低频区域；而<strong>小波包分解</strong>则对低频和高频都做分解。</p><h3 id="1-5-5-金字塔应用：图像融合"><a href="#1-5-5-金字塔应用：图像融合" class="headerlink" title="1.5.5 金字塔应用：图像融合"></a>1.5.5 金字塔应用：图像融合</h3><p><img src="ronghe.png" alt></p><p>如上图所示，将两幅图像拼接融合到一起可以用金字塔模型实现。</p><p><strong>算法原理</strong></p><ol><li><p>首先建立两幅图像高斯金字塔，然后建立一定层数的拉普拉斯金字塔。拉普拉斯金字塔的层数越高，融合效果越好。层数N作为一个参数。</p></li><li><p>传入一个mask掩膜，代表了融合的位置。比如说想在两图的中间进行融合，那么掩膜图像的左半为255，右半为0，反过来是一样的。根据这个mask建立一个高斯金字塔，用于后续融合，层数为N+1。</p></li><li><p>根据mask将两幅图像的拉普拉斯金字塔的图像进行相加，mask为权值。相加的结果即为一个新的金字塔。同时，两幅图像的高斯金字塔的N+1层也进行这个操作，记这个图像为IMG1。</p></li><li><p>根据这个新的金字塔重建出最终的图像，重建的过程跟一般的拉普拉斯金字塔一样。首先对IMG1上采样，然后跟新金字塔的顶层相加，得到IMG2。IMG2进行上采样后跟下一层相加，得到IMG3。重复这个过程，最终得到的结果就是拉普拉斯金字塔融合算法的结果。</p></li></ol><blockquote><p>因为mask建立金字塔的过程中使用了高斯模糊，所以融合的边缘是比较平滑的。</p></blockquote><h2 id="1-6-几何变换"><a href="#1-6-几何变换" class="headerlink" title="1.6 几何变换"></a>1.6 几何变换</h2><p>包含相同内容的两幅图像可能由于成像角度、透视关系乃至镜头自身原因所造成的几何失真而呈现出截然不同的外观，这就给观测者或是图像识别程序带来了困扰。通过适当的几何变换可以最大程度地消除这些几何失真所产生的负面影响，有利于我们在后续的处理和识别工作中将注意力集中子图像内容本身，更确切地说是图像中的对象，而不是该对象的角度和位置等。 因此，几何变换常常作为其他图像处理应用的预处理步骤。</p><p><strong>解决几何变换的一般思路</strong><br>图像几何变换又称为图像空间变换， 它将一幅图像中的坐标位置映射到另一幅图像中的新坐标位置。我们学习几何变换的关键就是要确定这种空间映射关系， 以及映射过程中的变换参数。<br>几何变换不改变图像的像素值， 只是在图像平面上进行像素的重新安排。一个几何变换需要两部分运算：首先是空问变换所需的运算， 如平移、旋转和镜像等， 需要用它来表示输出图像与输入图像之间的〈像素〉映射关系：此外， 还需要使用灰度插值算法， 因为按照这种变换关系进行计算， 输出图像的像素可能被映射到输入图像的非整数坐标上。<br>图像的位置变换主要是用于目标识别中的目标配准。</p><h3 id="1-6-1-全局变化"><a href="#1-6-1-全局变化" class="headerlink" title="1.6.1 全局变化"></a>1.6.1 全局变化</h3><p><strong>图像集合变换的表达式</strong></p><script type="math/tex; mode=display">(x, y)=T\{(u, v)\}</script><ul><li>$(x,y) $为变换后图像像素的笛卡尔坐标，$(u,v)$为原始图像中像素的笛卡尔坐标。</li><li>变换后，如果$(x,y)=(u,v)$，则变换后的图像仅仅是原图像的简单拷贝。</li><li>注意，几何变换不改变像素值，而是改变像素所在的位置。这说明像素的亮度和色彩并不发生变化，仅仅是像素位置发生改变。</li></ul><p><strong>齐次坐标表示</strong></p><ul><li>所谓齐次坐标就是用$N+1$维向量表示N NN维向量。</li><li>平面上的点P PP的坐标为$(x,y)$，其齐次坐标表示为$(wx,wy,w)$ ,其中$w$为任意常数。</li><li>如果规定齐次坐标的第三个分量$w$为1，则称为规范齐次坐标。</li></ul><p><strong>引入齐次坐标的原因</strong></p><ul><li><p>在对图像进行操作时候，经常要对图像连续做几次变换。例如做了平移后再做旋转与缩放。因为旋转、缩放都是线性变换，因此可将旋转和缩放合并成一个变换矩阵来表示，如：</p><script type="math/tex; mode=display">\left[ \begin{array}{lll}{x} & {y} & {1}\end{array}\right]=\left[ \begin{array}{lll}{x_{0}} & {y_{0}} & {1}\end{array}\right]^{T}</script></li><li><p>在直角坐标系中，平移不是线性变换，因此不能与旋转、缩放等操作合并成一个变换矩阵。</p></li><li><strong>引入齐次坐标后，平移变为线性变换，从而可以采用一个通用的变换模型（仿射变换模型）表示图像的各种几何变换。</strong></li></ul><p><strong>仿射变换</strong></p><script type="math/tex; mode=display">\left[ \begin{array}{lll}{x} & {y} & {1}\end{array}\right]=\left[ \begin{array}{lll}{x_{0}} & {y_{0}} & {1}\end{array}\right]^{T}</script><ul><li><p>T仿射矩阵</p><script type="math/tex; mode=display">T=\left[ \begin{array}{lll}{a} & {b} & {p} \\ {c} & {d} & {q} \\ {m} & {n} & {s}\end{array}\right]</script></li><li><p>$a b c d$：实现比例变换、旋转变换、偏移变换m</p></li><li>$m n$：实现平移变换、$m $和$n$分别为$X$和$Y$方向的平移量。</li><li>$s$：实现等比例变换</li><li>$p q $：实现透视变换</li></ul><p><img src="pingyi.png" alt></p><p><img src="jingxiang.png" alt></p><p><img src="xuanzhuan.png" alt></p><p><img src="xingzhuang.png" alt></p><p><img src="bili.png" alt></p><h3 id="1-6-2-基于网格的卷绕"><a href="#1-6-2-基于网格的卷绕" class="headerlink" title="1.6.2 基于网格的卷绕"></a>1.6.2 基于网格的卷绕</h3><p>在一些情况下需要对局部的图像进行几何变化。例如，人脸从皱眉到微笑的表观变化。 怎样才能在这个情况下将嘴角向上卷翘而保持脸的其他部分不动呢？要进行这样的变换，在图像的不同部分需要不同数量的运动。下图展示了一些常用的方法。<br><img src="juanrao.png" alt><br>(a)稀疏控制点-&gt;变形网格；(b)控制点对应的稠密集；(c)有向直线对应；(d)一致的四边形网格</p><h3 id="1-6-3-应用：基于特征的变形"><a href="#1-6-3-应用：基于特征的变形" class="headerlink" title="1.6.3 应用：基于特征的变形"></a>1.6.3 应用：基于特征的变形</h3><p>尽管卷绕可以用于改变单幅图像的外观或使其成为一个动画，但用一个通常称为“变形”的过程将两幅或更多图像卷绕并混合起来可以获得更强大的效果。<br>下图展示了图像变形的本质。在两幅图像中进行简单地渐隐渐现(cross-dissolving)会导致上面一行所显示的鬼影，取而代之，每幅图像在融合之前经过向另一幅图像卷绕，如下面一行所示。如果建立了好的对应关系(用上图所展示的任何一种方法)，对应的特征便会对齐，因而不会有鬼影结果。<br><img src="bianxing.png" alt></p><p>上行：如果两幅图像直接混合，会导致可见的鬼影。下行：先将两幅图像都卷绕到同样的中间位置（例如向另一幅图像的中间），然后将得到的卷绕图像混合，产生一个无缝的变形。</p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Show and Tell-A Neural Image Caption Generator</title>
      <link href="/2019/05/12/%5B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%5DShow-and-Tell-A-Neural-Image-Caption-Generator/"/>
      <url>/2019/05/12/%5B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%5DShow-and-Tell-A-Neural-Image-Caption-Generator/</url>
      
        <content type="html"><![CDATA[<blockquote><p>论文题目：《Show and Tell: A Neural Image Caption Generator》</p><p>论文链接：<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf</a></p><p>代码链接：<a href="https://github.com/joczu/Show_and_Tell" target="_blank" rel="noopener">https://github.com/joczu/Show_and_Tell</a></p></blockquote><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>图像内容描述是人工智能领域的基础问题，是计算机视觉与自然语言处理的交叉领域。众所周知，CNN在目标检测和识别中的效果非常的出色，而RNN在机器翻译中也得到了充分的发挥。本文就是在两者的基础上对两种模型进行组合形成一个新的生成式模型称为NIC，实现图像内容描述的任务。</p><p><img src="NIC.png" alt></p><p>作者的思想源泉来自于目前比较前沿的机器翻译，给定一个源句子$S$，将其输入到模型中得到目标语言的句子$T$，模型所要做的就是$\max P(T|S)$。<br>目前机器翻译中比较火的模型莫属RNNs，RNNs可作为Encoder，把源句子编码成一个固定长度的词向量表示，又可作为Decoder生成目标句子。<br>在本文中，作者使用CNN来代替RNNs的Encoder功能，将输入图像编码成固定长度的词向量表示，这样做的原因在于CNN在图像特征提取中表现极为出色。CNN+RNNs这种端到端的神经网络使用起来相当方便。</p><p>由于普通的RNN会出现梯度消失和梯度爆炸的现象，所以采用更加优良的LSTM模型。</p><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p><img src="cnnrnn.png" alt></p><p>如图所示，LSTM+CNN模型就是一个图像内容生成器。CNN将输入图像进行特征表示，生成512维的表示向量输入到第一个LSTM单元中，作为$t=-1$时刻，$S_i$代表某个单词的向量，采用one-hot编码，长度为整个词表的长度，$W_e$是词向量表示，$W_eS_i$为隐含层的词向量表示，长度也为512维。前向传播的过程如下：</p><script type="math/tex; mode=display">\begin{aligned} x_{-1} &=\operatorname{CNN}(I) \\ x_{t} &=W_{e} S_{t}, \quad t \in\{0 \ldots N-1\} \\ p_{t+1} &=\operatorname{LSTM}\left(x_{t}\right), \quad t \in\{0 \ldots N-1\} \end{aligned}</script><p>上面说到，模型训练的目标为：</p><script type="math/tex; mode=display">\theta^{\star}=\arg \max _{\theta} \sum_{(I, S)} \log p(S | I ; \theta) \\ \log p(S | I)=\sum_{t=0}^{N} \log p\left(S_{t} | I, S_{0}, \ldots, S_{t-1}\right)</script><p>其中$I$为输入的图像，$S$为生成的句子，$\theta$是模型的参数，我们要做的就是最大化这个目标函数，获得模型的参数$\theta$。(此处最大似然之后取log形式)</p><p>上述Log似然公式，恰好对应到RNN的网络中，在$t$时刻，需要计算当前词$S_t$的概率，则可以将历史词$S_0$到$S_{t-1}$表示为一个确定长度的隐含层神经元向量$h_t$，同时输入图像$x_t$，在$t+1$时刻，隐含层向量被更新：</p><script type="math/tex; mode=display">h_{t+1}=f\left(h_{t}, x_{t}\right)</script><h2 id="推断策略"><a href="#推断策略" class="headerlink" title="推断策略"></a>推断策略</h2><ul><li>Sampling：直接将前一个词输入下一个时间点</li><li>BeamSearch：第一个时间点，输出top k个候选词，这k个候选词分别输入第二个时间点，得到若干个第一个和第二个词组合，从这选择得分top k的，输入到第三个时间点，依次迭代</li></ul><h2 id="需要注意的点"><a href="#需要注意的点" class="headerlink" title="需要注意的点"></a>需要注意的点</h2><ul><li>每个时刻的LSTM单元共享一套参数</li><li>单词采用one-hot的表示方法</li><li>每个句子前后都有标志词，表示句子的开始和结束</li><li>图像只需要初始时输入一次（每个时刻都输入，会因噪声很容易过拟合，效果不好）</li><li>本文使用VGG16训练好的模型参数初始化CNN网络</li></ul>]]></content>
      
      
      <categories>
          
          <category> Image Caption </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MTCNN</title>
      <link href="/2019/05/06/%E3%80%8AJoint-Face-Detection-and-Alignment-using-Multi-task-Cascaded-Convolutional-Networks%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/05/06/%E3%80%8AJoint-Face-Detection-and-Alignment-using-Multi-task-Cascaded-Convolutional-Networks%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<blockquote><p>论文题目：《Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks》<br>论文链接：<a href="https://arxiv.org/abs/1604.02878" target="_blank" rel="noopener">https://arxiv.org/abs/1604.02878</a><br>官方代码链接：<a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment" target="_blank" rel="noopener">https://github.com/kpzhang93/MTCNN_face_detection_alignment</a><br>其他代码链接：<a href="https://github.com/YYuanAnyVision/mxnet_mtcnn_face_detection" target="_blank" rel="noopener">https://github.com/YYuanAnyVision/mxnet_mtcnn_face_detection</a><br>其他代码链接：<a href="https://github.com/Seanlinx/mtcnn" target="_blank" rel="noopener">https://github.com/Seanlinx/mtcnn</a></p></blockquote><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>传统的人脸检测和人脸对齐任务忽略了它们之间固有的联系而各自分析，这样在本文作者看来是不可取的。本文提出了采用深度级联多任务网络（MTCNN）<strong>同时</strong>解决检测和对齐任务。MTCNN网络包含三个阶段的卷积网络（Proposal Network、Refine Network、Output Network）用来检测人脸和检测关键点位置。另外，本文提出一种Online hard sample mining strategy极大提高了算法在实践中的速度。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="3.png" alt></p><p>首先把图像resize成不同尺度的图像金字塔作为网络的输入；</p><ul><li>Stage 1:  Proposal Network, P-Net<br>获得人脸的候选窗口和候选框的回归向量，然后候选框依据估计的边框回归向量进行校准，最后利用Non-maximum suppression(NMS)归并重叠范围比较大的候选框。</li><li>Stage 2: Refine Network, R-Net<br>将第一阶段产生的候选框输入到R-Net，筛选掉大量的非人脸候选框，并且使用边框回归向量进行校准，利用NMS进行归并；</li><li>Stage 3: Output Network, O-Net<br>与第二阶段相似，增加了输出5个人脸关键点位置。</li></ul><p><img src="full.png" alt></p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>与网络的三阶段对应，MTCNN训练过程可以考虑三个阶段的损失，分别是人脸/非人脸二分类、边框回归、面部关键点位置。</p><ol><li><p>人脸识别<br>这是个二分类问题，对于每一个样本$x_i$，$p_i$是样本$x_i$为人脸的概率，真实标签$y_i^{det}\in {\lbrace 0,1\rbrace}$则采用交叉熵损失函数：</p><script type="math/tex; mode=display">L_{i}^{d e t}=-\left(y_{i}^{d e t} \log \left(p_{i}\right)+\left(1-y_{i}^{d e t}\right)\left(1-\log \left(p_{i}\right)\right)\right)</script></li><li><p>边框回归<br>采用欧式距离损失（L2 Loss）,最小化生成的边框坐标与真实边框坐标的欧式距离。对于每个样本$x_i$，$\hat y_i^{box}$表示其回归生成的边框坐标，$y_{i}^{b o x}$是真实的边框坐标。</p><script type="math/tex; mode=display">L_{i}^{b o x}=\left\|\hat{y}_{i}^{b o x}-y_{i}^{b o x}\right\|_{2}^{2}</script></li><li><p>人脸关键点位置<br>与边框回归相似，最小化回归生成的关键点坐标$\widehat{y}_{i}^{l a n d m a r k}$与真实的关键点坐标$y_{i}^{l a n d m a r k}$的欧式距离。$\widehat{y}_{i}^{l a n d m a r k}$代表左右眼睛/鼻子/左右嘴巴角的坐标，共10维向量。</p><script type="math/tex; mode=display">L_{i}^{l a n d m a r k}=\left\|\widehat{y}_{i}^{l a n d m a r k}-y_{i}^{l a n d m a r k}\right\|_{2}^{2}</script></li><li><p>Three Tasks’ loss Sum<br>在实践中对于每个阶段的网络都定义总的损失函数<strong>同时</strong>计算三种损失，这样不至于在求一种损失时，另外两种损失为零。作者在文章中提出在P-Net和R-Net中使用（$\alpha _{det}=1,\alpha_{box}=0.5,\alpha _{landmark}=0.5$）而在O-Net中使用（$\alpha _{det}=1,\alpha_{box}=0.5,\alpha _{landmark}=1$）这说明每个阶段的训练目标有所差异，在P-Net和R-Net中主要是检测人脸和产生边框，O-Net主要是产生关键点位置。</p><script type="math/tex; mode=display">\min \sum_{i=1}^{N} \sum_{j \in\{\text {det}, b o x, l a n d m a r k\}} \alpha_{j} \beta_{i}^{j} L_{i}^{j}</script></li><li><p>Online Hard Sample mining<br>传统的人脸二分类最小化误差时，是对每个样本都进行反向误差传播，这样计算量比较大。本文提出一种新的方法来解决人脸识别在线应用问题。<br>对于每一个mini-batch前向传播产生的loss进行降序排序，从全部的sample中挑选出Top 70%作为hard sample，然后在反向传播中仅仅计算这些hard sample产生的梯度。</p></li></ol><h2 id="其他参考"><a href="#其他参考" class="headerlink" title="其他参考"></a>其他参考</h2><p><a href="https://blog.csdn.net/u014380165/article/details/78906898" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/78906898</a></p>]]></content>
      
      
      <categories>
          
          <category> Face Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MTCNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Improving GAN</title>
      <link href="/2019/04/28/Improving-GAN/"/>
      <url>/2019/04/28/Improving-GAN/</url>
      
        <content type="html"><![CDATA[<p>本文对GAN进行更加深入的探讨，主要参考<a href="https://www.bilibili.com/video/av9770302/?p=16" target="_blank" rel="noopener">哔哩哔哩-李宏毅深度学习2017</a>视频的讲解。</p><h2 id="1-统一架构-FGAN"><a href="#1-统一架构-FGAN" class="headerlink" title="1. 统一架构-FGAN"></a>1. 统一架构-FGAN</h2><h3 id="1-1-f-divergence"><a href="#1-1-f-divergence" class="headerlink" title="1.1 f-divergence"></a>1.1 f-divergence</h3><p>这一章节是为了说明GAN中描述$P_G$和$P_{data}$两个分布差异不一定非要用JS divergence，还有其他的divergence可以替代。</p><p><img src="f.png" alt></p><p>其中P和Q表示两个分布，$p(x)$和$q(x)$是采样出来的x的可能性。f是一个凸函数，并且其极值是$f(1)=0$，$D_f(P||Q)$衡量PQ两个分布之间的差异。<br>如果$p(x)=q(x)$，代入等式可得$D_f(P||Q)=0$；<br>当$p(x)!=q(x)$，$D_f(P||Q) \geq f(\int \limits_xq(x) \frac {p(x)}{q(x)})=f(x)=0$<br>当P和Q两个同分布时，$D_f(P||Q)$有最小值0。</p><p>当然f函数可以取很多形式，如下所示<br><img src="fall.png" alt></p><h3 id="1-2-Fenchel-Conjugate"><a href="#1-2-Fenchel-Conjugate" class="headerlink" title="1.2 Fenchel Conjugate"></a>1.2 Fenchel Conjugate</h3><p>细节内容见<a href="/2019/04/27/凸优化-Jensen不等式-共轭函数-Fenchel不等式/" title="凸优化:Jensen不等式-共轭函数-Fenchel不等式">凸优化:Jensen不等式-共轭函数-Fenchel不等式</a></p><p><img src="fc.png" alt></p><p><img src="fc2.png" alt></p><p><img src="fc3.png" alt></p><p><img src="fc4.png" alt></p><h2 id="2-WGAN"><a href="#2-WGAN" class="headerlink" title="2. WGAN"></a>2. WGAN</h2><p>对于传统的GAN来说，选定特定的Divergence度量函数之后，就开始训练使得两个分布的差异尽可能接近。但是使用f-Divergence也会有很多的问题，比如最严重的问题就是当两个分布之间完全没有重叠时，分布间距离的大小并不会直接体现在Divergence 上，这对于基于迭代的优化算法是致命的。<br>WGAN与传统的GAN却别就是度量分布差异的方式不用，WGAN使用Earth mover’s distance（EMD），顾名思义就是把一个分布变成另一个分布需要花费的最小力气。</p><h3 id="2-1-Earth-Mover’s-Distance"><a href="#2-1-Earth-Mover’s-Distance" class="headerlink" title="2.1 Earth Mover’s Distance"></a>2.1 Earth Mover’s Distance</h3><p><img src="emd.png" alt></p><p>如上图图所示，如何把P分布经过’搬运’变成Q分布，并且使得’搬运’的代价最小，显然有很多方法取移动，那么如何评估’搬运’的代价大小呢，方法很多，如果我们假定衡量代价大小的标准是”移动的数量”或者”移动的平均距离”那么这两个移动方案肯定能分出优劣的。</p><p><img src="emd2.png" alt></p><p>当我们用分布$Q$上不同颜色的色块对应$P$的相应位置，就可以将最好的移动方案化成上面的样子。为了便于形式化定义，我们将这个变化画成一个矩阵，如下图：</p><p><img src="plan.png" alt></p><p>矩阵内的红色色块代表从$P$分布到$Q$分布对应位置’搬运’的量。<br>$\gamma$’搬运’方法的平均移动距离表示为：</p><script type="math/tex; mode=display">B(\gamma )=\sum \limits_{x_p,x_q} \gamma (x_p,x_q)||x_p-x_q||</script><p>Earth Mover’s Distance指的是上述所有方案中平均移动距离最小的那个方案：</p><script type="math/tex; mode=display">W(P,Q)=\min \limits_{\gamma}B(\gamma)</script><p>为什么可以说EMD的方法比JSD的方法好呢，我们可以从下面的图可以看出：<br><img src="bijiao.png" alt><br>在前50轮训练中，JSD的值一直是$log2$，不能很好的衡量两个分布的差异；而EMD的值可以一直的变化，这样收敛的速度就相对较快了。</p><h3 id="2-2-Related-to-GAN"><a href="#2-2-Related-to-GAN" class="headerlink" title="2.2 Related to GAN"></a>2.2 Related to GAN</h3><p>由上节内容知 F-Divergence定义为：<br>$D_f(P_{data}||P_G) = \max \limits_{D} \lbrace E_{x\sim P_{data}}[D(x)]-E_{x \sim P_{G}}[f^*(D(x))] \rbrace$<br>EMD也可以类似的表示出来：<br>$W(P_{data},P_G)=\max \limits_{x \sim 1-Lipschitz} \lbrace E_{x \sim P_{data}}[D(x)]-E_{x \sim P_G}[D(x)] \rbrace$<br>公式中$1-Lipschitz$表示一个函数集，当$f$是一个Lipschitz函数时，它应该满足$||f(x_1)-f(x_2)||\leq K||x_1-x_2||$。当$K=1$时，这个函数就是$1-Lipschitz$函数，直观来说，这个限制是为了让函数的变化更加缓慢一些。如下图所示，绿色的线属于$1-Lipschitz$函数，而蓝色的线不是。<br><img src="lip.png" alt></p><p>为什么要限制生成器D是$1-Lipschitz$函数呢，我们来分析一下当D不是$1-Lipschitz$函数时的情况。<br>我们假设有两个一维分布，$x_1$和$x_2$的距离是$d$，显然他们之间的EMD也是$d$<br><img src="d.png" alt><br>此时我们优化$W(P_{data},P_G)=\max \limits_D \lbrace E_{x \sim P_{data}}[D(x)]-E_{x \sim P_G}[D(x)] \rbrace$时，只需要$D(x_1)=+\infty$，$D(x_2)=-\infty$即可，这样判别器的区分能力太强了，训练起来很困难，很难驱使生成器提高生成分布数据质量。</p><p>如果我们加上$||D(x_1)-D(x_2)|| \leq ||x_1-x_2||=d$的限制，如果我们想要满足上面的优化目标，就可以让$D(x_1)=k+d,D(x_2)=k$，其中$k$具体是什么无所谓，关键是我们通过$d$将判别器在不同分布上的结果限制在了一个较小的范围。</p><p>这样做有什么好处呢？因为传统GAN的判别器是一个最终经过sigmoid函数输出的神经网络，它输出的曲线是S型的，在真实分布附近是1，在生成分布附近是0。当我们加上$||D(x_1)-D(x_2)|| \leq ||x_1-x_2||=d$的限制时，判别器最后一层就不再需要sigmoid函数。<br><img src="sig.png" alt><br>传统的判别器有饱和区（靠近真实和生成分布的地方，函数变化平缓，梯度趋于0），经过限制之后，输出成为了一条直线，训练过程得到加快。</p><blockquote><ol><li>判别器输出层不需再用sigmoid函数</li><li>换成受限的$1-Lipschitz$来实现类似sigmoid的范围限制功能</li><li>生成器和判别器的Loss不需再取log（因为换了Divergence方式）</li></ol></blockquote><p>如何对判别器网络添加$1-Lipschitz$的限制呢？文章中采用简单暴力的方法：截取权重，将权重限制到$[-c,c]$之间，这样限制变成了$K-Lipschitz$，如何调整$K$，只能靠多次调试了。<br><img src="clip.png" alt><br>图中斜率比较陡峭的就是没有截断的函数，截断之后函数会逆时针旋转，产生$1-Lipschitz$的效果。</p><p>原始的GAN算法流程如下：<br><img src="gan.png" alt><br>WGAN的算法如下：<br><img src="wgan.png" alt></p><h2 id="3-改进WGAN"><a href="#3-改进WGAN" class="headerlink" title="3. 改进WGAN"></a>3. 改进WGAN</h2><p>在上节原始的WGAN中，我们通过截取权重（Weight Clipping）的方法实现对判别器D的$1-Lipschitz$限制。$1-Lipschitz$函数有一个特性：当一个函数是$1-Lipschitz$函数时，它的梯度的范数将永远小于等于1，即:</p><p><script type="math/tex">D \in 1-Lipschitz \leftrightarrow ||\nabla_xD(x) \leq 1</script>  for all x<br>此时WGA你的优化目标就是在$1-Lipschitz$中挑选一个函数作为判别器D。</p><p>在Improved WGAN中这样定义：（W相当于Origin GAN中的V，越大越好）<br>$W(P_{data},P_G)=\max \limits_D \lbrace E_{x \sim P_{data}}[D(x)]-E_{x \sim P_G}[D(x)] \rbrace -\lambda \int_xmax(0,||\nabla_xD(x)||-1)dx$<br>也就是说判别器的寻找范围不再是$1-Lipschitz$中的函数，而是任意函数。但是后面增加了一项惩罚项。这个惩罚项能够让选中的判别函数倾向于是一个”对输入梯度为1”的函数，这样就近似的实现了Weight Clipping的效果。</p><p>但与之前一样，求积分无法计算，我们还是采用采样的方法去加惩罚项，即：<br>$W(P_{data},P_G)=\max \limits_D \lbrace E_{x \sim P_{data}}[D(x)]-E_{x \sim P_G}[D(x)] \rbrace -\lambda E_{x \sim P_{penalty}}max(0,||\nabla_xD(x)||-1)dx$</p><p>也就是说，在训练过程中，从$P_{penalty}$中采样使得每一个$x$都能满足$||\nabla_xD(x)||\leq 1$</p><p>Improved WGAN设计了一个特别的$P_{penalty}$，产生过程如下：</p><ol><li>从$P_{data}$中采样一个点</li><li>从$P_G$中采样一个点</li><li>将两个点连线</li><li>在连线上采样得到一个点，这就是从$P_{penalty}$中采样的点</li></ol><p>重复以上过程就能不断采样得到$x \sim P_{penalty}$，最终蓝色的区域就可以看作是$P_{penalty}$<br><img src="penalty.png" alt></p><p>也就是说，我们采样的范围不是整个$x$，而是P_G和$P_{data}$之间的部分。<br>进一步整理，Improved GAN真正做的事是这样：<br>$W(P_{data},P_G)=\max \limits_D \lbrace E_{x \sim P_{data}}[D(x)]-E_{x \sim P_G}[D(x)] \rbrace -\lambda E_{x \sim P_{penalty}}(||\nabla_xD(x)||-1)^2 \rbrace dx$<br>这个惩罚项的目的是让梯度尽可能趋向于1。大于1小于1都会受到惩罚。这样的好处就像是SVM中强调最大类间距离一样，找到可以将数据划分开的最好超平面；这里要做的目的是由于可能存在多个判别器，我们想要找到的那个分类器应该有一个”最好的形状”。<br>一个”好”的判别器应该在$P_{data}$附近是尽可能大，在$P_G$附近尽可能的小。也就是说处于$P_{data}$和$P_G$之间的$P_{penalty}$区域应该有一个比较”陡峭的“梯度，但是这个陡峭的梯度是有限制的，最好是1。</p><h2 id="4-参考阅读"><a href="#4-参考阅读" class="headerlink" title="4. 参考阅读"></a>4. 参考阅读</h2><p><a href="https://alberthg.github.io/2018/05/13/wgan/" target="_blank" rel="noopener">生成对抗网络-FGAN和WGAN</a></p>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> Earth Mover&#39;s Distance </tag>
            
            <tag> f-divergence </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>凸优化:Jensen不等式-共轭函数-Fenchel不等式</title>
      <link href="/2019/04/27/%E5%87%B8%E4%BC%98%E5%8C%96-Jensen%E4%B8%8D%E7%AD%89%E5%BC%8F-%E5%85%B1%E8%BD%AD%E5%87%BD%E6%95%B0-Fenchel%E4%B8%8D%E7%AD%89%E5%BC%8F/"/>
      <url>/2019/04/27/%E5%87%B8%E4%BC%98%E5%8C%96-Jensen%E4%B8%8D%E7%AD%89%E5%BC%8F-%E5%85%B1%E8%BD%AD%E5%87%BD%E6%95%B0-Fenchel%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="凸函数"><a href="#凸函数" class="headerlink" title="凸函数"></a>凸函数</h2><p>凸函数的定义：$f(\theta x+(1-\theta)y) \leq \theta f(x)+(1-\theta)f(y)$<br>其含义就是：函数图像在直线下边。</p><h2 id="Jensen不等式"><a href="#Jensen不等式" class="headerlink" title="Jensen不等式"></a>Jensen不等式</h2><p>凸函数定义推广到一般形式，即可得到Jensen不等式，即<br>$\theta_1,…\theta_k\geq0, \theta_1+…+\theta_k=1$时，<br>$f(\theta_1x_1+…+\theta_kx_k) \leq \theta_1f(x_1)+…+\theta_kf(x_k)$</p><p>扩展理解：对于$\theta_1,…\theta_k\geq0, \theta_1+…+\theta_k=1$，如果把$\theta_k$看出$x_k$的概率的话，那$\theta_1x_1+…+\theta_kx_k$就表示x的期望，右边式子就表示$f(x)$的期望，于是上式就可以写成$f(E(x))\leq E(f(x))$，这就是Jensen不等式，注意函数f要满足凸函数。</p><h2 id="共轭函数"><a href="#共轭函数" class="headerlink" title="共轭函数"></a>共轭函数</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>原函数$f:R^n\to R$共轭函数定义：<br><img src="gonge.png" alt><br>这个式子的意思是：求$xt-f(x)$关于x和y函数在定义域内的上界，将这个上界形成的函数定义为共轭函数。下图红色部分就是上界<br><img src="sub.png" alt></p><ol><li><p>定义式中$f(x)$不一定是凸函数</p></li><li><p>共轭函数一定是凸函数（由图可知）</p></li><li><p>凸函数的共轭函数的共轭函数是其本身</p></li></ol><h3 id="如何求共轭函数"><a href="#如何求共轭函数" class="headerlink" title="如何求共轭函数"></a>如何求共轭函数</h3><p><img src="fan.png" alt></p><h2 id="Fenchel不等式"><a href="#Fenchel不等式" class="headerlink" title="Fenchel不等式"></a>Fenchel不等式</h2><p>由共轭函数定义可知，$f^<em>(t) \geq xt-f(x)$ 移项可得 $f(x)+f^</em>(t) \geq xt$ 这就是Fenchel不等式。</p>]]></content>
      
      
      <categories>
          
          <category> 凸优化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jensen不等式 </tag>
            
            <tag> 共轭函数 </tag>
            
            <tag> Fenchel不等式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo填坑</title>
      <link href="/2019/04/26/Hexo%E5%A1%AB%E5%9D%91/"/>
      <url>/2019/04/26/Hexo%E5%A1%AB%E5%9D%91/</url>
      
        <content type="html"><![CDATA[<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><ul><li>创建Hexo工程</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init blog</span><br></pre></td></tr></table></figure><p>此处blog可以替换成你想要的名字。</p><ul><li>新建博文</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd blog</span><br><span class="line">$ hexo new &apos;blog-name&apos;</span><br></pre></td></tr></table></figure><p>此时会在/blog/sources/_post/目录下生成’blog-name.md’文件和’blog-name’的文件夹。md文件用于编辑博文，文件夹用于存放此博文内容照片。</p><ul><li>运行服务器</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>本地访问<a href="http://0.0.0.0:4000/" target="_blank" rel="noopener">http://0.0.0.0:4000/</a>，查看Hexo网站。</p><ul><li>生成上传至GitHub</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g -d</span><br></pre></td></tr></table></figure><ul><li>安装主题</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd /blog/themes</span><br><span class="line">$ git clone https://github.com/wuchong/jacman.git ./jacman</span><br><span class="line">$ cd ./jacman</span><br><span class="line">$ git pull</span><br></pre></td></tr></table></figure><p>然后修改站点配置文件/blog/config.yml，将其中的theme改成jacman</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: jacman</span><br></pre></td></tr></table></figure><ul><li>LaTex数学公式渲染</li></ul><p>先把node_modules文件夹下的渲染器删掉，再输入下面命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm i hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><ul><li>插入图片</li></ul><p>将照片放在与博文同名的文件夹下面，在博文中输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![](pic.png)</span><br></pre></td></tr></table></figure><p>即可饮用，但是这种方法不能改变图片大小，可采用下面命令修改图片大小</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;img src=&apos;pic.png&apos; width = &apos;80%&apos; height = &apos;80%&apos; &gt;</span><br></pre></td></tr></table></figure><ul><li>文件下载链接</li></ul><p>在blog/sources/files内放入上传的文件，在博文中输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[](/files/filename)</span><br></pre></td></tr></table></figure><h2 id="LaTex公式编辑"><a href="#LaTex公式编辑" class="headerlink" title="LaTex公式编辑"></a>LaTex公式编辑</h2><ul><li>插入数学公式</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$数学公式$ 或者 $$数学公式$$</span><br></pre></td></tr></table></figure><p>前者是行内公式，后者是行间公式</p><ul><li>区块引用</li></ul><p><code>&gt;</code>后面书写引用</p><ul><li><p>分割线</p><p><code>***</code>或者<code>---</code></p></li><li><p>上下标</p></li></ul><p>使用^表示上标，表示下标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x^2 </span><br><span class="line">x_&#123;1,2...,n&#125;</span><br><span class="line">\sum \limits^n \limits_&#123;i=1&#125;</span><br><span class="line">\hat x              //字母上加^</span><br><span class="line">$\overline x$       //字母上加横线 </span><br><span class="line">$\widetilde x$      //字母上加波浪线</span><br><span class="line">$\dot&#123;x&#125;$           //字母上加一个点 </span><br><span class="line">$\ddot&#123;x&#125;$          //字母上加两个点</span><br></pre></td></tr></table></figure><ul><li>波浪线</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\sim</span><br></pre></td></tr></table></figure><ul><li>公式换行对齐</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;equation&#125;</span><br><span class="line">\begin&#123;split&#125;</span><br><span class="line">y &amp;= a(x + b) \\&amp;= ax+ab  </span><br><span class="line">\end&#123;split&#125;</span><br><span class="line">\end&#123;equation&#125;</span><br></pre></td></tr></table></figure><ul><li>括号</li></ul><p><code>()</code>和<code>[]</code>都表示它们自己，但是<code>{}</code>因为有特殊作用需要用<code>\lbrace \rbrece</code>表示。</p><ul><li>分数</li></ul><p><code>\frac{分母}{分子}</code>来表示分数</p><ul><li>开方</li></ul><p><code>\sqrt[次数][被开方数]</code>来表示开方</p><ul><li>求期望</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathbb&#123;E&#125;</span><br></pre></td></tr></table></figure><ul><li>正负无穷</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">+\infty</span><br><span class="line">-\infty</span><br></pre></td></tr></table></figure><ul><li>希腊字母</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">代码</th><th style="text-align:center">大写</th><th style="text-align:center">代码</th><th style="text-align:left">小写</th></tr></thead><tbody><tr><td style="text-align:center"><code>A</code></td><td style="text-align:center">$A$</td><td style="text-align:center"><code>\alpha</code></td><td style="text-align:left">$\alpha$</td></tr><tr><td style="text-align:center"><code>B</code></td><td style="text-align:center">$B$</td><td style="text-align:center"><code>\beta</code></td><td style="text-align:left">$\beta$</td></tr><tr><td style="text-align:center"><code>\Gamma</code></td><td style="text-align:center">$\Gamma$</td><td style="text-align:center"><code>\gamma</code></td><td style="text-align:left">$\gamma$</td></tr><tr><td style="text-align:center"><code>\Delta</code></td><td style="text-align:center">$\Delta$</td><td style="text-align:center"><code>\delta</code></td><td style="text-align:left">$\delta$</td></tr><tr><td style="text-align:center"><code>E</code></td><td style="text-align:center">$E$</td><td style="text-align:center"><code>\epsilon</code></td><td style="text-align:left">$\epsilon$</td></tr><tr><td style="text-align:center"><code>Z</code></td><td style="text-align:center">$Z$</td><td style="text-align:center"><code>\zeta</code></td><td style="text-align:left">$\zeta$</td></tr><tr><td style="text-align:center"><code>H</code></td><td style="text-align:center">$H$</td><td style="text-align:center"><code>\eta</code></td><td style="text-align:left">$\eta$</td></tr><tr><td style="text-align:center"><code>\Theta</code></td><td style="text-align:center">$\Theta$</td><td style="text-align:center"><code>\theta</code></td><td style="text-align:left">$\theta$</td></tr><tr><td style="text-align:center"><code>I</code></td><td style="text-align:center">$I$</td><td style="text-align:center"><code>\iota</code></td><td style="text-align:left">$\iota$</td></tr><tr><td style="text-align:center"><code>K</code></td><td style="text-align:center">$K$</td><td style="text-align:center"><code>\kappa</code></td><td style="text-align:left">$\kappa$</td></tr><tr><td style="text-align:center"><code>\Lambda</code></td><td style="text-align:center">$\Lambda$</td><td style="text-align:center"><code>\lambda</code></td><td style="text-align:left">$\lambda$</td></tr><tr><td style="text-align:center"><code>M</code></td><td style="text-align:center">$M$</td><td style="text-align:center"><code>\mu</code></td><td style="text-align:left">$\mu$</td></tr><tr><td style="text-align:center"><code>N</code></td><td style="text-align:center">$N$</td><td style="text-align:center"><code>\nu</code></td><td style="text-align:left">$\nu$</td></tr><tr><td style="text-align:center"><code>\Xi</code></td><td style="text-align:center">$\Xi$</td><td style="text-align:center"><code>\xi</code></td><td style="text-align:left">$\xi$</td></tr><tr><td style="text-align:center"><code>O</code></td><td style="text-align:center">$O$</td><td style="text-align:center"><code>\omicron</code></td><td style="text-align:left">$\omicron$</td></tr><tr><td style="text-align:center"><code>\Pi</code></td><td style="text-align:center">$\Pi$</td><td style="text-align:center"><code>\pi</code></td><td style="text-align:left">$\pi$</td></tr><tr><td style="text-align:center"><code>P</code></td><td style="text-align:center">$P$</td><td style="text-align:center"><code>\rho</code></td><td style="text-align:left">$\rho$</td></tr><tr><td style="text-align:center"><code>\Sigma</code></td><td style="text-align:center">$\Sigma$</td><td style="text-align:center"><code>\sigma</code></td><td style="text-align:left">$\sigma$</td></tr><tr><td style="text-align:center"><code>T</code></td><td style="text-align:center">$T$</td><td style="text-align:center"><code>\tau</code></td><td style="text-align:left">$\tau$</td></tr><tr><td style="text-align:center"><code>\Upsilon</code></td><td style="text-align:center">$\Upsilon$</td><td style="text-align:center"><code>\upsilon</code></td><td style="text-align:left">$\upsilon$</td></tr><tr><td style="text-align:center"><code>\Phi</code></td><td style="text-align:center">$\Phi$</td><td style="text-align:center"><code>\phi</code></td><td style="text-align:left">$\phi$</td></tr><tr><td style="text-align:center"><code>X</code></td><td style="text-align:center">$X$</td><td style="text-align:center"><code>\chi</code></td><td style="text-align:left">$\chi$</td></tr><tr><td style="text-align:center"><code>\Psi</code></td><td style="text-align:center">$\Psi$</td><td style="text-align:center"><code>\psi</code></td><td style="text-align:left">$\psi$</td></tr><tr><td style="text-align:center"><code>\Omega</code></td><td style="text-align:center">$\Omega$</td><td style="text-align:center"><code>\omega</code></td><td style="text-align:left">$\omega$</td></tr></tbody></table></div><ul><li><p>其他字符</p><ul><li>关系运算符</li></ul><p>|     符号     | 代码         |<br>| :—————: | :—————- |<br>|    $\pm$     | <code>\pm</code>        |<br>|   $\times$   | <code>\times</code>     |<br>|    $\div$    | <code>\div</code>       |<br>|    $\mid$    | <code>\mid</code>       |<br>|   $\nmid$    | <code>\nmid</code>      |<br>|   $\cdot$    | <code>\cdot</code>      |<br>|   $\circ$    | <code>\circ</code>      |<br>|    $\ast$    | <code>\ast</code>       |<br>|  $\bigodot$  | <code>\bigodot</code>   |<br>| $\bigotimes$ | <code>\bigotimes</code> |<br>| $\bigoplus$  | <code>\bigoplus</code>  |<br>|    $\leq$    | <code>\leq</code>       |<br>|    $\geq$    | <code>\geq</code>       |<br>|    $\neq$    | <code>\neq</code>       |<br>|  $\approx$   | <code>\approx</code>    |<br>|   $\equiv$   | <code>\equiv</code>     |<br>|    $\sum$    | <code>\sum</code>       |<br>|   $\prod$    | <code>\prod</code>      |<br>|  $\coprod$   | <code>\coprod</code>    |</p><ul><li>集合运算符</li></ul><p>|    符号     | 代码        |<br>| :————-: | :————— |<br>| $\emptyset$ | <code>\emptyset</code> |<br>|    $\in$    | <code>\in</code>       |<br>|  $\notin$   | <code>\notin</code>    |<br>|  $\subset$  | <code>\subset</code>   |<br>|  $\supset$  | <code>\supset</code>   |<br>| $\subseteq$ | <code>\subseteq</code> |<br>| $\supseteq$ | <code>\supseteq</code> |<br>|  $\bigcap$  | <code>\bigcap</code>   |<br>|  $\bigcup$  | <code>\bigcup</code>   |<br>|  $\bigvee$  | <code>\bigvee</code>   |<br>| $\bigwedge$ | <code>\bigwedge</code> |<br>| $\biguplus$ | <code>\biguplus</code> |<br>| $\bigsqcup$ | <code>\bigsqcup</code> |</p><ul><li>对数运算符</li></ul><p>|  符号  | 代码   |<br>| :——: | :——- |<br>| $\log$ | <code>\log</code> |<br>| $\lg$  | <code>\lg</code>  |<br>| $\ln$  | <code>\ln</code>  |</p><ul><li>三角运算符</li></ul><p>|   符号   | 代码     |<br>| :———: | :———- |<br>|  $\bot$  | <code>\bot</code>   |<br>| $\angle$ | <code>\angle</code> |<br>|  $\sin$  | <code>\sin</code>   |<br>|  $\cos$  | <code>\cos</code>   |<br>|  $\tan$  | <code>\tan</code>   |<br>|  $\cot$  | <code>\cot</code>   |<br>|  $\sec$  | <code>\sec</code>   |<br>|  $\csc$  | <code>\csc</code>   |</p><ul><li>微积分运算符</li></ul><p>|     符号     | 代码         |<br>| :—————: | :—————- |<br>|   $\prime$   | <code>\prime</code>     |<br>|    $\int$    | <code>\int</code>       |<br>|   $\iint$    | <code>\iint</code>      |<br>|   $\iiint$   | <code>\iiint</code>     |<br>|  $\iiiint$   | <code>\iiiint</code>    |<br>|   $\oint$    | <code>\oint</code>      |<br>|    $\lim$    | <code>\lim</code>       |<br>|   $\infty$   | <code>\infty</code>     |<br>|   $\nabla$   | <code>\nabla</code>     |<br>| $\mathrm{d}$ | <code>\mathrm{d}</code> |</p><ul><li>箭头</li></ul><p><img src="jiantou.png" alt></p><ul><li>不常用符号</li></ul><p><img src="buchangyong.png" alt></p><ul><li>非数学符号</li></ul><p><img src="feishuxue.png" alt></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> LaTex </tag>
            
            <tag> MarkDown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN初识</title>
      <link href="/2019/04/25/GAN%E5%88%9D%E8%AF%86/"/>
      <url>/2019/04/25/GAN%E5%88%9D%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<p>GAN的相关知识主要是跟着李宏毅老师入门的，具体内容可以访问<a href="https://www.bilibili.com/video/av9770302/?p=15" target="_blank" rel="noopener">哔哩哔哩-李宏毅深度学习2017</a>进行学习。这篇文章主要对学习内容进行总结。</p><h2 id="1-传统生成模型"><a href="#1-传统生成模型" class="headerlink" title="1.传统生成模型"></a>1.传统生成模型</h2><h3 id="AutoEncoder"><a href="#AutoEncoder" class="headerlink" title="AutoEncoder"></a>AutoEncoder</h3><blockquote><p>AutoEncoder是前馈神经网络的一种，曾经重要用于数据的降维或者特征的抽取，而现在也被广泛用于生成模型。与其他前馈神经网络不同的是，其他前馈神经网络关注的是Output Layer和错误率，而AutoEncoder关注点是Hidden Layer；并且普通前馈神经网络一般比较深，而AutoEncoder通常只有一层Hidden Layer。Hidden Layer中神经元组成的向量（Code）用来表示Input</p></blockquote><img src="/2019/04/25/GAN初识/autoencoder.png"><p>如图该模型的作用是生成与原图像相似的图像。将原始图像输入神经网络，经过Encoder的压缩，表示成Code；再经过Decoder的解压生成图像；最后计算生成图像与输入图像的MSE（Mean Square Error），这样就可以对模型进行训练。</p><p><img src="Decoder.png" alt></p><p>若只取AutoEncoder的Decoder部分，随机生成Code向量输入网络进行解码，这样就可以生成图像。</p><p>但是从上图可以看出AutoEncoder的图像生成效果非常的差，从计算loss方式分析其原因。</p><p><img src="7.png" width="40%" height="40%"></p><p>可以从上图中看出，两幅图像仅仅一个像素点的位置不同，但是用MSE计算loss是一样大的，这就说明MSE不能衡量图像像素点的位置信息。</p><p>GAN就出场了，设计了Generator和Discriminator结构进行前馈运算，采用KL/JSD等方式，很好的解决了衡量两个图像分布之间‘difference’的问题。</p><h2 id="2-GAN前馈流程图"><a href="#2-GAN前馈流程图" class="headerlink" title="2.GAN前馈流程图"></a>2.GAN前馈流程图</h2><p><img src="generator.png" width="70%" height="70%"></p><p><img src="discriminator.png" width="25%" height="25%"></p><p>初始化Generator和Discriminator网络参数，服从特定分布的随机变量输入Generator网络生成图像（标签为0），再和真实图像（标签为1）一块输入到Discriminator进行判断。</p><p>若是Discriminator对生成图像的判分较低，则Generator参数进行梯度下降更新（此时固定Discriminator）；再将第二轮Generator生成的图像输入到Discriminator进行判断，若是Discriminator对其判分较高，则更新Discriminator参数。</p><h2 id="3-GAN原理"><a href="#3-GAN原理" class="headerlink" title="3.GAN原理"></a>3.GAN原理</h2><ul><li><h3 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum Likelihood Estimation"></a>Maximum Likelihood Estimation</h3></li></ul><p>给定真实数据分布$ P_{data}(x)$，此处的x代表真实图像构成的向量；设生成模型的分布$P_{G}(x;\theta)$，这个生成分布由$\theta$决定，生成图像模型的目标就是使得生成模型分布$P_{G}(x;\theta)$尽可能的接近真实数据分布$ P_{data}(x)$，也就是要计算$\theta$。</p><p>这样就可以采用最大似然估计的方法来，具体方法如下：</p><ol><li>从真实数据分布$ P_{data}(x)$中采样得到${x^1,x^2,…,x^m}$；</li><li>计算每个数据的概率$P_G(x^i;\theta)$</li><li>计算似然：$L = \prod_{i=1}^mP_G(x^i;\theta)$</li><li>求得$\theta$使得似然最大化</li></ol><p><img src="MLE.png" width="75%" height="75%"></p><p>使用最大似然估计求得$\theta$的过程如上图所示，对似然求log变成log似然；真实分布中的所有x的期望等价于概率积分，所以可以转化成积分运算，因为减号之后的积分与$\theta$无关，所以添加上去之后还是等价的；经过这样拼凑之后最大似然估计可以变成求两个分布之间的KL散度，两个分布越相似，KL散度值越小。</p><p>在求$\theta$之前必须要假定生成分布的类型，比如是高斯混合模型，但是在实践中这种假设的效果不太好，所以如何能设计出更加一般化的生成模型分布呢？</p><p>这里采用神经网络来产生生成分布$P_{G}(x;\theta)$，$\theta$也就是神经网络的权重参数。神经网络只要有非线性激活函数，理论上可以去拟合任意函数，概率分布也可以看作是函数映射，所以可以采用神经网络去学习复杂的概率分布。</p><p><img src="GAN%20Distribution.png" width="70%" height="70%"></p><ul><li><p>Generator G</p><p>生成器G是一个函数，输入向量z，输出向量x</p><p>$P_{prior}(z)$表示输入向量z的先验分布，$P_G(x)$由生成器G决定</p></li><li><p>Discriminator D</p><p>判别器D是一个函数，输入向量x，输出标量值</p><p>D用来衡量$P_G(x)$与$P_{data}(x)$之间的不同</p></li><li><p>GAN公式</p><p>$G^*=arg\min\limits_{G}\max\limits_{D}V(G,D)$    </p><p>$V=E_{x \sim P_{data}}[logD(x)]+E_{x \sim P_{G}}[log(1-D(x))]$ 衡量$P_G$与$P_{data}$的不同</p><p>在G一定的情况，寻找D使得$V(G,D)$最大化，也就是对于真实分布中的x，D(x)要接近1，对于生成分布中的x，D(x)要接近于0，这样使得判别器的能力增强；<br>再固定D，寻找G使得$\max\limits_{D}V(G,D)$最小，也就是让来自于生成分布中的x的D(x)尽可能的接近1，这样使得生成器的能力增强。</p></li></ul><p>接下来对$G^*=arg\min\limits_{G}\max\limits_{D}V(G,D)$进行求解。</p><ul><li><h3 id="求解-min-limits-G-max-limits-D-V-G-D"><a href="#求解-min-limits-G-max-limits-D-V-G-D" class="headerlink" title="求解$\min \limits_{G}\max \limits_{D}V(G,D)$"></a>求解$\min \limits_{G}\max \limits_{D}V(G,D)$</h3></li></ul><p>给定G，求得最优的$D^*$使得V最大。</p><p><img src="maxv.png" width="70%" height="70%"></p><p>接下来给定x，求$D^*$使得被积函数取极大值。$P_{data}(x)$和$P_{G}(x)$是已知值，只   需要对D求导即可得到极大值。</p><p><img src="D*.png" width="70%" height="70%"></p><p>将$D^*$代入V式进行整理。</p><p><img src="maxv%E6%8E%A8%E5%AF%BC.png" width="70%" height="70%"></p><p>$log2P_{data}(x)$对x积分之后得$log2$，概率积分为1。</p><p><img src="maxv%E6%8E%A8%E5%AF%BC2.png" width="70%" height="70%"></p><p>上图的推导主要是凑出JSD分布的形式，JS Divergence是KL散度的对称平滑版本，也是描述了两个分布之间的差异。因为JSD值域[0,log2]所以 $\max \limits_DV(G,D)$的取值范围为[-2log2,0]。</p><p>接下来的问题就是如何优化G，使得$P_G(x)$尽可能接近$P_{data}(x)$</p><p><img src="G.png" width="40%" height="40%"></p><p>如上图，将$\max \limits_DV(G,D)$视为损失函数$L(G)$，采用梯度下降的方法进行优化</p><p><img src="G2.png" width="40%" height="40%"></p><h2 id="4-GAN训练"><a href="#4-GAN训练" class="headerlink" title="4.GAN训练"></a>4.GAN训练</h2><p><img src="%E8%AE%AD%E7%BB%83.png" width="65%" height="65%"></p><p>如图所示，在实践训练中，我们不可能求得$P_G$和$P_{data}$的期望，所以只能从真实数据分布和生成数据分布中分别采样，代入到损失函数求的交叉熵。</p><p>具体的算法流程如下</p><p><img src="%E7%AE%97%E6%B3%95.png" width="65%" height="65%"></p><h2 id="5-问题优化"><a href="#5-问题优化" class="headerlink" title="5.问题优化"></a>5.问题优化</h2><ul><li><h3 id="训练初期缓慢"><a href="#训练初期缓慢" class="headerlink" title="训练初期缓慢"></a>训练初期缓慢</h3></li></ul><p><img src="%E7%94%9F%E6%88%90%E5%99%A8%E4%BC%98%E5%8C%96.png" width="25%" height="25%"></p><p>在生成模型的优化过程中，生成器的loss Function是$V=E_{x\sim P_{G}}[-log(1-D(x))]$。如上图所示，当D(x)接近0的时候，梯度非常的小。这就导致在训练的初期，生成器G如果想要骗过判别器D变化是非常的缓慢的。所以就将生成器的loss修改成$V=E_{x\sim P_{G}}[-log(D(x))]$这样可以提高训练的速度。</p><ul><li><h3 id="Loss不变"><a href="#Loss不变" class="headerlink" title="Loss不变"></a>Loss不变</h3></li></ul><p>在实际训练中发现，loss一直不发生变化，即$\max \limits_DV(G,D)=0$</p><p>因为JSD值域是[0,log2]，这也就是说明$P_G$和$P_{data}$没有相似之处，但是实际上两个分布是有相似之处的，出现问题的原因是我们在积分运算中国使用采样的方法，当训练过拟合的时候，D还是能把两部分的点给分开的，如下图所示。</p><p><img src="%E8%BF%87%E6%8B%9F%E5%90%88.png" width="40%" height="40%"></p><p>我们是不是应该让D变得弱一点，减弱它的分类能力，但是我们的初衷是让D变得更强，这就产生了矛盾。</p><p>还有一种原因可能是，两个分布都是高维的，但是两个分布都十分的窄，交集相当的小，这就导致JSD比较大。</p><p>解决方法：添加噪声，让两个分布变得更宽一些，这样可以增大它们之间的交集，在训练过程中，再使噪声逐渐减小。</p><ul><li><h3 id="Mode-Collapse"><a href="#Mode-Collapse" class="headerlink" title="Mode Collapse"></a>Mode Collapse</h3></li></ul><p><img src="mode.png" width="50%" height="50%"></p><p>如上图所示，实际训练过程种可能出现这样的情况，真实的数据分布是双峰分布的，而生成的数据分布只拟合了其中一个峰的分布，也就是说没有学到整个分布。</p><p>造成这种情况的原因是，KL散度中两个分布写反了。</p><p><img src="mode2.png" width="50%" height="50%"></p><p>如上图所示，若是第一KL散度的写法，为了防止出现无穷大，所有有$P_{data}$出现的地方都必须有$P_G$覆盖，这样就不回出现Mode Collapse。</p><h2 id="6-代码"><a href="#6-代码" class="headerlink" title="6.代码"></a>6.代码</h2><p><a href="/files/originGAN.py">GAN代码实现</a></p><h2 id="7-参考"><a href="#7-参考" class="headerlink" title="7.参考"></a>7.参考</h2><p><a href="https://www.cnblogs.com/bonelee/p/9166084.html" target="_blank" rel="noopener">https://www.cnblogs.com/bonelee/p/9166084.html</a></p>]]></content>
      
      
      <categories>
          
          <category> GAN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
            <tag> MLE </tag>
            
            <tag> AutoEncoder </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/04/14/404/"/>
      <url>/2019/04/14/404/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>数据结构知识点（4）——串、数组和广义表</title>
      <link href="/2018/09/17/2018-09-17-data-struct-summary-4/"/>
      <url>/2018/09/17/2018-09-17-data-struct-summary-4/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}<h3 id="串的定义、存储结构以及计算"><a href="#串的定义、存储结构以及计算" class="headerlink" title="串的定义、存储结构以及计算"></a>串的定义、存储结构以及计算</h3><h4 id="串的定义"><a href="#串的定义" class="headerlink" title="串的定义"></a>串的定义</h4></li><li>计算机上的非数值处理的对象大部分是字符串数据，字符串一般简称为串。串是一种特殊的线性表，其特殊性体现在数据元素是一个字符；    </li><li>零个字符的串称为空串；只有空格的字符串称为空格串；<h4 id="串的存储结构"><a href="#串的存储结构" class="headerlink" title="串的存储结构"></a>串的存储结构</h4>串也有两种基本的存储结构：顺序存储和链式存储，但考虑到存储效率和算法的方便性，串多采用<strong>顺序存储结构</strong>。</li><li>串的顺序存储<blockquote><p>串都是从下标为1的数组分量开始存储的，下标为0的分量闲置不用。    </p></blockquote></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//---串的定长顺序存储结构---</span><br><span class="line">#define MAXLEN 255    //串的最大长度</span><br><span class="line">typedef struct&#123;</span><br><span class="line">    char ch[MAXLEN+1];</span><br><span class="line">    int length;    //串的当前长度</span><br><span class="line">&#125;SString;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//---串的堆式顺序存储结构---</span><br><span class="line">typedef struct&#123;</span><br><span class="line">     char *ch;//若是非空串，则按串长分配存储区，否则为空</span><br><span class="line">     int length;//串的当前长度</span><br><span class="line">&#125;HString;</span><br></pre></td></tr></table></figure><ul><li>串的链式存储<br>链表的结点可以存放一个字符，也可以存放多个字符，称为结点的大小。链表的最后一个结点不一定全被串值占满，此时通常补上“#”或其他的非串值字符。    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//---串的链式存储结构---</span><br><span class="line">#define CHUNKSIZE 80</span><br><span class="line">typedef struct Chunk&#123;    //定义每个结点的存储结构</span><br><span class="line">     char ch[CHUNKSIZE];</span><br><span class="line">     struct Chunk *next;</span><br><span class="line">&#125;Chunk;</span><br><span class="line">typedef struct&#123;</span><br><span class="line">     Chunk *head,*tail;   //串的头和尾指针</span><br><span class="line">     int length;</span><br><span class="line">&#125;LString;</span><br></pre></td></tr></table></figure></li></ul><h3 id="串的模式匹配算法"><a href="#串的模式匹配算法" class="headerlink" title="串的模式匹配算法"></a>串的模式匹配算法</h3><p>确定主串中所含子串第一次出现的位置（定位）</p><h4 id="BF（Brute-Force）算法"><a href="#BF（Brute-Force）算法" class="headerlink" title="BF（Brute Force）算法"></a>BF（Brute Force）算法</h4><ul><li>算法思想<br>（1）将主串的第pos个字符和模式的第一个字符比较，若相等，继续逐个比较后续字符；若不等，从主串的下一字符起，重新与模式的第一个字符比较；<br>（2）直到主串的一个连续子串字符序列与模式相等 。返回值为S中与T匹配的子序列第一个字符的序号，即匹配成功；<br>（3）否则，匹配失败，返回值 0；<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/BF%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B.PNG" alt="BF算法"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int  Index(Sstring S,Sstring T,int pos)&#123;</span><br><span class="line">    i=pos;j=1;</span><br><span class="line">   while (i&lt;=S[0] &amp;&amp; j&lt;=T[0])&#123;</span><br><span class="line">       if (S[i]=T[j]) &#123;++i;++j;&#125;</span><br><span class="line">       else&#123;i=i-j+2;j=1;&#125;</span><br><span class="line">   if (j&gt;T[0])   return i－T[0];</span><br><span class="line">   else return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h4><p>利用已经<strong>部分匹配</strong>的结果而加快模式串的滑动速度，且主串S的指针i不必回溯！可提速到O(n+m)！<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/KMP%E7%AE%97%E6%B3%95%E6%B1%82next%E5%80%BC.PNG" alt="KMP算法求next值"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">int Index_KMP(SString S,SString T,int pos,int next[])</span><br><span class="line">&#123; // 利用模式串T的next函数求T在主串S中第pos个字符之后的位置的KMP算法</span><br><span class="line">//其中，T非空，1≤pos≤StrLength(S)</span><br><span class="line">int i=pos, j=1;</span><br><span class="line">while (i&lt;=S[0] &amp;&amp; j&lt;=T[0])</span><br><span class="line">if (j==0||S[i]==T[j]) // 继续比较后继字</span><br><span class="line">&#123;</span><br><span class="line">    ++i;</span><br><span class="line">    ++j;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">    j=next[j]; // 模式串向右移动</span><br><span class="line">if (j&gt;T[0]) // 匹配成功</span><br><span class="line">    return i-T[0];</span><br><span class="line">else</span><br><span class="line">    return 0;</span><br><span class="line">&#125;//Index_KMP</span><br></pre></td></tr></table></figure></p><p><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/KMP%E7%AE%97%E6%B3%95%E5%8C%B9%E9%85%8D%E6%AD%A5%E9%AA%A4.PNG" alt="KMP算法匹配步骤"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">//---计算next函数值---</span><br><span class="line">void get_next(SString T, int next[])</span><br><span class="line">&#123; //求模式串T的next函数值并存入数组next</span><br><span class="line">int i=1, j=0;</span><br><span class="line">next[1]=0;</span><br><span class="line">while(i&lt;T[0])</span><br><span class="line">if (j==0||T[i]==T[j])</span><br><span class="line">&#123;</span><br><span class="line">    ++i;</span><br><span class="line">    ++j;</span><br><span class="line">    next[i]=j;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">  j=next[j];</span><br><span class="line">&#125;//get_next</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">//计算next函数的修正值</span><br><span class="line">void get_nextval(SString T,int nextval[])</span><br><span class="line">&#123;</span><br><span class="line">     i=1;nextval[1]=0;j=0;</span><br><span class="line">     while(i&lt;T.length)</span><br><span class="line">    &#123;</span><br><span class="line">        if(j==0||T.ch[i]==T.ch[j])</span><br><span class="line">        &#123;</span><br><span class="line">            ++i;++j;</span><br><span class="line">            if(T.ch[i]!=T.ch[j]) nextval[i]=j;</span><br><span class="line">            else nextval[i]=nextval[j];</span><br><span class="line">         &#125;</span><br><span class="line">         else j=nextval[j];</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/KMP%E7%AE%97%E6%B3%95%E6%B1%82nextval%E5%80%BC.PNG" alt="KMP求nextval值"></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构知识点（3）——栈与队列</title>
      <link href="/2018/09/13/2018-09-13-data-struct-summary-3/"/>
      <url>/2018/09/13/2018-09-13-data-struct-summary-3/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}<h3 id="栈的表示和操作的实现"><a href="#栈的表示和操作的实现" class="headerlink" title="栈的表示和操作的实现"></a>栈的表示和操作的实现</h3><h4 id="顺序栈的表示和实现"><a href="#顺序栈的表示和实现" class="headerlink" title="顺序栈的表示和实现"></a>顺序栈的表示和实现</h4></li><li><strong>顺序栈的存储结构</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef struct     //栈的存储结构</span><br><span class="line">&#123;</span><br><span class="line">    ElemType *base;</span><br><span class="line">    ElemType *top;</span><br><span class="line">    int stacksize;</span><br><span class="line">&#125;SqStack;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>（1） base为栈底指针，初始化完成后，栈底指针base始终指向栈底的位置，若base为NULL，则表明栈结构不存在；<br>（2） top为栈顶指针，其初值指向栈底。每当插入新的栈顶元素时，指针top增1；删除栈顶元素时，指针top减1；<br>（3） 栈空时，top和base的值相等，都指向栈底；栈非空时，top始终指向栈顶元素的上一个位置；<br>（4） stacksize为栈可使用的最大容量；    </p></blockquote><ul><li><p><strong>顺序栈的初始化</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status InitStack(SqStack &amp;S)    //栈的初始化</span><br><span class="line">&#123;</span><br><span class="line">     S.base=new ElemType[MAXSIZE];    //为顺序栈分配一个MAXSIZE的数组空间</span><br><span class="line">     if(!S.base) return ERROR;</span><br><span class="line">     S.top=S.base;</span><br><span class="line">     S.stacksize=MAXSIZE;</span><br><span class="line">     return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>压栈</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Status Push(SqStack &amp;S,ElemType e)    //压栈</span><br><span class="line">&#123;</span><br><span class="line">    if(S.top-S.base==S.stacksize) return ERROR;    //判断是否到达最大容量</span><br><span class="line">    *S.top=e;</span><br><span class="line">    ++S.top;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>出栈</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Status Pop(SqStack &amp;S,ElemType &amp;e)    //出栈</span><br><span class="line">&#123;</span><br><span class="line">    if(S.top==S.base) return ERROR;     //判断栈是否为空</span><br><span class="line">    e=*--S.top;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>取栈顶元素</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Status GetTop(SqStack S)    //获取栈顶元素</span><br><span class="line">&#123;</span><br><span class="line">    if(S.top!=S.base)    //判断栈是否为空</span><br><span class="line">       return *(S.top-1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="链栈的表示和实现"><a href="#链栈的表示和实现" class="headerlink" title="链栈的表示和实现"></a>链栈的表示和实现</h4><ul><li><strong>链栈的存储结构</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">typedef struct StackNode</span><br><span class="line">&#123;</span><br><span class="line">    ElemType data;</span><br><span class="line">    struct StackNode *next;</span><br><span class="line">&#125;StackNode,*LinkStack;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>链栈的存储结构与点链表的存储结构相同，由于栈的主要操作是在栈顶插入和删除，显然以链表的头部作为栈顶是最方便的，因此链栈不需设置头结点。    </p><ul><li><strong>初始化</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Status InitStack(LinkStack &amp;S)</span><br><span class="line">&#123;</span><br><span class="line">    S=NULL;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></blockquote><ul><li><p><strong>压栈</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status Push(LinkStack &amp;S,ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">    StackNode *p;</span><br><span class="line">    InitStack(p);    //为结点开辟内存空间</span><br><span class="line">    p-&gt;data=e;</span><br><span class="line">    p-&gt;next=S;</span><br><span class="line">    S=p;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>出栈</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status Pop(LinkStack &amp;S,ElemType &amp;e)</span><br><span class="line">&#123;</span><br><span class="line">    StackNode *p;</span><br><span class="line">    e=S-&gt;data;</span><br><span class="line">    p=S;</span><br><span class="line">    S=S-&gt;next;</span><br><span class="line">    delete p;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>取栈顶元素</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ElemType GetTop(LinkStack S)</span><br><span class="line">&#123;</span><br><span class="line">    if(S!=NULL)return S-&gt;data;</span><br><span class="line">    return ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="队列的表示和操作的实现"><a href="#队列的表示和操作的实现" class="headerlink" title="队列的表示和操作的实现"></a>队列的表示和操作的实现</h3><h4 id="循环队列—队列的顺序表示和实现"><a href="#循环队列—队列的顺序表示和实现" class="headerlink" title="循环队列—队列的顺序表示和实现"></a>循环队列—队列的顺序表示和实现</h4><ul><li><strong>队列的存储结构</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">typedef struct     </span><br><span class="line">&#123;</span><br><span class="line">    ElemType *base;</span><br><span class="line">    int front; //整型变量，在此叫做头指针</span><br><span class="line">    int rear;  //整型变量，在此叫做尾指针</span><br><span class="line">&#125;SqQueue;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>（1） 初始化创建空队列时，令<code>front=rear=0</code>；<br>（2） 每当插入新的队列尾元素时，尾指针rear增1；每当删除队列头元素时，头指针front增1；<br>（3） 在非空队列中，头指针始终指向队列头元素，尾指针始终指向队列尾元素的下一位置；<br>（4） 队空的条件：<code>Q.front=Q.rear</code><br>（5） 队满的条件：<code>(Q.rear+1)%MAXSIZE==Q.front</code>    </p><ul><li><strong>初始化</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Status InitQueue(SqQueue &amp;Q)    //初始化</span><br><span class="line">&#123;</span><br><span class="line">    Q.base=new ElemType[MAXSIZE];   //Q.base指向数组空间的首地址</span><br><span class="line">    if(!Q.base) return ERROR;</span><br><span class="line">    Q.front=Q.rear=0;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></blockquote><ul><li><p><strong>求队列长度</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Status QueueLength(SqQueue Q)    //队列的长度</span><br><span class="line">&#123;</span><br><span class="line">    return (Q.rear-Q.front+MAXSIZE)%MAXSIZE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>入队</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status EnQueue(SqQueue &amp;Q,ElemType e)    //进队列</span><br><span class="line">&#123;</span><br><span class="line">    if((Q.rear+1)%MAXSIZE==Q.front)</span><br><span class="line">        return ERROR;</span><br><span class="line">    Q.base[Q.rear]=e;</span><br><span class="line">    Q.rear=(Q.rear+1)%MAXSIZE;     //队尾指针加1</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>出队</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Status DeQueue(SqQueue &amp;Q,ElemType &amp;e)    //出队列</span><br><span class="line">&#123;</span><br><span class="line">    if(Q.rear==Q.front) return ERROR;</span><br><span class="line">    e=Q.base[Q.front];</span><br><span class="line">    Q.front=(Q.front+1)%MAXSIZE;    //队头指针加1</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>获取队头元素</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ElemType GetHead(SqQueue Q)     //获取队列头元素</span><br><span class="line">&#123;</span><br><span class="line">    if(Q.front!=Q.rear)</span><br><span class="line">        return Q.base[Q.front];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="链队—队列的链式表示和实现"><a href="#链队—队列的链式表示和实现" class="headerlink" title="链队—队列的链式表示和实现"></a>链队—队列的链式表示和实现</h4><ul><li><strong>链队的初始化</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">typedef struct QNode</span><br><span class="line">&#123;</span><br><span class="line">    ElemType data;</span><br><span class="line">    struct QNode *next;</span><br><span class="line">&#125;QNode,*QueuePtr;</span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">    QueuePtr front;</span><br><span class="line">    QueuePtr rear;</span><br><span class="line">&#125;LinkQueue;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>一个链队显然需要两个分别指向队头和队尾的指针才能确定；<br>这里为操作方便，给链队添加一个头结点，并令头指针指向头结点；    </p><ul><li><strong>初始化</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Status InitQueue(LinkQueue &amp;Q)</span><br><span class="line">&#123;</span><br><span class="line">    Q.front=Q.rear=new QNode;</span><br><span class="line">    Q.front-&gt;next=NULL;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></blockquote><ul><li><p><strong>链队的入队</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status EnQueue(LinkQueue &amp;Q,ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">    QNode *p;</span><br><span class="line">    p=new QNode;</span><br><span class="line">    p-&gt;data=e;</span><br><span class="line">    p-&gt;next=NULL;</span><br><span class="line">    Q.rear-&gt;next=p;</span><br><span class="line">    Q.rear=p;</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>链队的出队</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status DeQueue(LinkQueue &amp;Q,ElemType &amp;e)</span><br><span class="line">&#123;</span><br><span class="line">    if(Q.front==Q.rear) return ERROR;</span><br><span class="line">    QNode *p;</span><br><span class="line">    p=Q.front-&gt;next;</span><br><span class="line">    Q.front-&gt;next=p-&gt;next;</span><br><span class="line">    if(Q.rear==p) Q.rear=Q.front;</span><br><span class="line">        delete p;</span><br><span class="line">        return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>取队头元素</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ElemType GetHead(LinkQueue Q)</span><br><span class="line">&#123;</span><br><span class="line">    if(Q.front!=Q.rear)</span><br><span class="line">        return Q.front-&gt;next-&gt;data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构知识点（2）——线性表</title>
      <link href="/2018/09/08/2018-09-08-data-struct-summary-2/"/>
      <url>/2018/09/08/2018-09-08-data-struct-summary-2/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}</li></ul><h3 id="线性表的定义和特点"><a href="#线性表的定义和特点" class="headerlink" title="线性表的定义和特点"></a>线性表的定义和特点</h3><p><strong>线性表</strong>：由n（n≥0）个数据特性相同的元素构成的有限序列。<br>特点：<br>① 存在唯一的一个被称为“第一个”的数据元素；<br>② 存在唯一的一个被称为“最后一个”的数据元素；<br>③ 除第一个之外，结构中的每个数据元素均只有一个前驱；<br>④ 出最后一个之外，结构中的每个数据元素均只有一个后继。    </p><h3 id="线性表的类型定义"><a href="#线性表的类型定义" class="headerlink" title="线性表的类型定义"></a>线性表的类型定义</h3><p>ADT List{<br>            数据对象：D＝{ ai | ai ∈ElemSet, i=1,2,…,n,  n≥0 }<br>            数据关系：R1＝{ <ai-1 ,ai>|ai-1 ,ai∈D,  i=2,…,n } i是位序<br>            基本操作：<br>            InitList(&amp;L){构造空的线性表L}<br>            Destroy（&amp;L）{销毁}<br>            ListEmpty（L）{若L为空 返回TRUE}<br>            ListLength（L）{返回L中的元素个数，即表长}<br>            PriorElem（L,cur_e,&amp;pre_e）{cur_e为一个元素且不是第一个，则用pre_e返回它的前驱}<br>            NextElem（L,cur_e,&amp;next_e）<br>            GetElem(L,i,&amp;e){用e返回L中第i个元素的值}<br>            LocateElem（L,e,compare()）{返回L中第一个与e满足compare()的元素位序，否则返回0}<br>            ListTraverse（L,visit()）{依次对L的每个元素调用visit()函数}<br>            ClearList（&amp;L）{置空}<br>            PutElem（&amp;L，i,e）{把e覆盖第i个位置，是改变元素，不是插入}<br>            ListInsert（&amp;L,i,e）{插入的位置是i的前面}<br>            ListDelete(&amp;L,i,&amp;)<br>}ADT List     </ai-1></p><h3 id="线性表的顺序表示和实现"><a href="#线性表的顺序表示和实现" class="headerlink" title="线性表的顺序表示和实现"></a>线性表的顺序表示和实现</h3><h4 id="线性表的顺序存储表示"><a href="#线性表的顺序存储表示" class="headerlink" title="线性表的顺序存储表示"></a>线性表的顺序存储表示</h4><p>线性表的顺序存储表示指的是用一组地址连续的存储单元依次存储线性表的数据元素，通常也称这种存储结构额线性表为顺序表。<br>只要确定了存储线性表的起始位置，线性表中任一数据元素都可以随机存取，所以线性表的顺序存储结构是一种随机存取的存储结构。    </p><blockquote><p>由于线性表的长度可变，且所需最大的存储空间随问题不同而不同，则在C语言中可用动态分配的一维数组表示线性表。    </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//---顺序表的存储结构---    </span><br><span class="line">#define MAXSIZE 100    //顺序表可能达到的最大长度    </span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">&amp;nbsp;&amp;nbsp;ElemType *elem;    //存储空间的基地址，ElemType可由用户自定义</span><br><span class="line">&amp;nbsp;&amp;nbsp;int length;    //当前长度</span><br><span class="line">&#125;SqList;    //顺序表的结构类型为SqList</span><br></pre></td></tr></table></figure><p>案例一：多项式的顺序存储结构类型定义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#define MAXSIZE 100    //顺序表可能达到的最大长度    </span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">&amp;nbsp;&amp;nbsp;float coef;    //系数</span><br><span class="line">&amp;nbsp;&amp;nbsp;float expn;    //指数</span><br><span class="line">&#125;Polynomial;</span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">&amp;nbsp;&amp;nbsp;Polynomial *elem;    //存储空间的基地址，Polynomial由用户自定义</span><br><span class="line">&amp;nbsp;&amp;nbsp;int length;    //当前长度</span><br><span class="line">&#125;SqList;    //顺序表的结构类型为SqList</span><br></pre></td></tr></table></figure></p><p>案例二：图书数据的顺序存储结构类型定义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#define MAXSIZE 10000    //图书表可能达到的最大长度    </span><br><span class="line">typedef struct    //图书信息定义</span><br><span class="line">&#123;</span><br><span class="line">  char no[20];    //图书ISBN</span><br><span class="line">  char name[50];  //图书名字</span><br><span class="line">&#125;Book;</span><br><span class="line">typedef struct</span><br><span class="line">&#123;</span><br><span class="line">  Book *elem;    //存储空间的基地址，Book由用户自定义</span><br><span class="line">  int length;    //当前长度</span><br><span class="line">&#125;SqList;    //顺序表的结构类型为SqList</span><br></pre></td></tr></table></figure></p><p>在上述定以后，可通过变量定义语句<code>SqList L;</code>将L定义成SqList类型的变量；<br>使用<code>L.elem[i-1]</code>访问序号为i的图书记录。    </p><h4 id="顺序表中基本操作的实现"><a href="#顺序表中基本操作的实现" class="headerlink" title="顺序表中基本操作的实现"></a>顺序表中基本操作的实现</h4><ul><li><strong>初始化</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Status InitList_Sq(SqList *L)&#123;    //构造一个空的顺序表L</span><br><span class="line">    L-&gt; elem=new ElemType[MAXSIZE];   //为顺序表分配空间</span><br><span class="line">    if(! L-&gt; elem) exit(OVERFLOW);       //存储分配失败</span><br><span class="line">    L-&gt; length=0;              //空表长度为0</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>或者：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Status InitList_Sq(SqList *L)&#123;    //构造一个空的顺序表L</span><br><span class="line">    L.elem=new ElemType[MAXSIZE];   //为顺序表分配空间</span><br><span class="line">    if(! L.elem) exit(OVERFLOW);       //存储分配失败</span><br><span class="line">    L.length=0;              //空表长度为0</span><br><span class="line">    return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li><p><strong>销毁</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void DestroyList(SqList &amp;L)</span><br><span class="line">&#123;</span><br><span class="line">  if (L.elem) delete[]L.elem;    //释放存储空间</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>清空</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void ClearList(SqList &amp;L) </span><br><span class="line">&#123;</span><br><span class="line">   L.length=0;                //将线性表的长度置为0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>线性表长度</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int GetLength(SqList L)</span><br><span class="line">&#123;</span><br><span class="line">   return (L.length);             </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>判断线性表是否为空</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int IsEmpty(SqList L)</span><br><span class="line">&#123;</span><br><span class="line">  if (L.length==0) return 1;      </span><br><span class="line">   else return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>取值</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//根据指定位置，获取相应位置数据元素的内容</span><br><span class="line">int GetElem(SqList L,int i,ElemType &amp;e)</span><br><span class="line">&#123;</span><br><span class="line">  if (i&lt;1||i&gt;L.length) return ERROR;   </span><br><span class="line">   //判断i值是否合理，若不合理，返回ERROR</span><br><span class="line">  e=L.elem[i-1];   //第i-1的单元存储着第i个数据</span><br><span class="line">  return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>查找</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int LocateELem(SqList L,ElemType e)</span><br><span class="line">&#123;</span><br><span class="line">  for (i=0;i&lt; L.length;i++)</span><br><span class="line">      if (L.elem[i]==e) return i+1;                </span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>插入</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status ListInsert_Sq(SqList &amp;L,int i ,ElemType e)&#123;</span><br><span class="line">   if(i&lt;1 || i&gt;L.length+1) return ERROR;         //i值不合法</span><br><span class="line">   if(L.length==MAXSIZE) return ERROR;    //当前存储空间已满     </span><br><span class="line">   for(j=L.length-1;j&gt;=i-1;j--) </span><br><span class="line">       L.elem[j+1]=L.elem[j];    //插入位置及之后的元素后移</span><br><span class="line">    L.elem[i-1]=e;                     //将新元素e放入第i个位置</span><br><span class="line">  ++L.length;     //表长增1</span><br><span class="line">  return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>删除</strong>    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status ListDelete_Sq(SqList &amp;L,int i,ElemType &amp;e)&#123;</span><br><span class="line">   if((i&lt;1)||(i&gt;L.length)) return ERROR; //i值不合法</span><br><span class="line">   e=L.elem[i-1];                              //将欲删除的元素保留在e中</span><br><span class="line">  for (j=i;j&lt;=L.length-1;j++)                   </span><br><span class="line">　  　L.elem[j-1]=L.elem[j];       //被删除元素之后的元素前移  </span><br><span class="line">   --L.length;                     //表长减1</span><br><span class="line">  return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="线性表的链式表示和实现"><a href="#线性表的链式表示和实现" class="headerlink" title="线性表的链式表示和实现"></a>线性表的链式表示和实现</h3><h4 id="单链表的定义和表示"><a href="#单链表的定义和表示" class="headerlink" title="单链表的定义和表示"></a>单链表的定义和表示</h4><ul><li><strong>结点</strong>：存储本身的信息以及存储指示其后继信息的存储映像；</li><li><strong>数据域</strong>：存储数据元素信息的域称为数据域；</li><li><strong>指针域</strong>：存储直接后继存储位置的域；</li><li>n个结点链接成一个链表，又由于此链表的每个结点只包含一个指针域，故又称<strong>线性链表</strong>或<strong>单链表</strong>；</li><li>链表分为：单链表、循环链表、双向链表、二叉链表、十字链表、邻接表、邻接多重表；</li><li>其中单链表、循环链表和双向链表用于实现线性表的链式存储，其他形式多用于实现树和图等非线性结构；</li><li>单链表时非随机存取的存储结构，取第i个数据元素必须从头指针出发顺链进行寻找，也称为顺序存取的存取结构。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//---单链表的存储结构---</span><br><span class="line">typedef struct LNode&#123;</span><br><span class="line">     ElemType   data;       //数据域</span><br><span class="line">     struct LNode  *next;   //指针域</span><br><span class="line">&#125;LNode,*LinkList;   // *LinkList为Lnode类型的指针</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>LinkList与LNode<em>本质上是等价的。通常使用LinkList定义单链表，强调定义的是某个单链表的头指针；<br>用LNode</em>定义指向单链表中任一结点的指针变量。<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%A4%B4%E6%8C%87%E9%92%88%E5%A4%B4%E7%BB%93%E7%82%B9%E9%A6%96%E5%85%83%E7%BB%93%E7%82%B9.png" alt="头指针头节点首元结点">    </p></blockquote><p>链表增加头结点的作用：<br>（1）便于首元结点的处理：首元结点地址保存在头结点的指针域中，使其和其他数据元素操作一样；<br>（2）便于空表和非空表的统一处理：当不设头结点时，假设L为单链表的头指针，则当单链表的长度n为0的空表时，L指针为空（L==NULL）；当增加头结点后，无论链表是否为空，头指针都是指向头结点的非空结点，即若为空表，头结点的指针域为空（L-&gt;next==NULL)；    </p><h4 id="单链表基本操作的实现"><a href="#单链表基本操作的实现" class="headerlink" title="单链表基本操作的实现"></a>单链表基本操作的实现</h4><ul><li><p>初始化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Status InitList_L(LinkList &amp;L)&#123; </span><br><span class="line">   L=new LNode;                    </span><br><span class="line">   L-&gt;next=NULL;　　　　　</span><br><span class="line">   return OK; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>销毁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status DestroyList_L(LinkList &amp;L)&#123;</span><br><span class="line">    LinkList p;</span><br><span class="line">       while(L)</span><br><span class="line">        &#123;</span><br><span class="line">            p=L;  </span><br><span class="line">            L=L-&gt;next;</span><br><span class="line">            delete p;  </span><br><span class="line">        &#125;</span><br><span class="line">     return OK;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>清空</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status ClearList(LinkList &amp; L)&#123;</span><br><span class="line">  // 将L重置为空表 </span><br><span class="line">   LinkList p,q;</span><br><span class="line">   p=L-&gt;next;   //p指向第一个结点</span><br><span class="line">   while(p)       //没到表尾 </span><br><span class="line">      &#123;  q=p-&gt;next; delete p; p=q;   &#125;</span><br><span class="line">   L-&gt;next=NULL;   //头结点指针域为空 </span><br><span class="line">   return OK;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>求表长</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int  ListLength_L(LinkList L)&#123;</span><br><span class="line">//返回L中数据元素个数</span><br><span class="line">    LinkList p;</span><br><span class="line">    p=L-&gt;next;         //p指向第一个结点</span><br><span class="line">     i=0;             </span><br><span class="line">     while(p)&#123;           //遍历单链表,统计结点数</span><br><span class="line">           i++;</span><br><span class="line">           p=p-&gt;next;    &#125; </span><br><span class="line">    return i;                             </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>判断是否为空</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">int ListEmpty(LinkList L)&#123; </span><br><span class="line">//若L为空表，则返回1，否则返回0 </span><br><span class="line">   if(L-&gt;next)   //非空 </span><br><span class="line">     return 0;</span><br><span class="line">   else</span><br><span class="line">     return 1;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li><li><p>取值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Status GetElem_L(LinkList L,int i,ElemType &amp;e)&#123; </span><br><span class="line">    p=L-&gt;next;j=1; //初始化</span><br><span class="line">     while(p&amp;&amp;j&lt;i)&#123;//向后扫描，直到p指向第i个元素或p为空 </span><br><span class="line">       p=p-&gt;next; ++j; </span><br><span class="line">     &#125; </span><br><span class="line">     if(!p || j&gt;i)return ERROR; //第i个元素不存在 </span><br><span class="line">     e=p-&gt;data; //取第i个元素 </span><br><span class="line">     return OK; </span><br><span class="line">&#125;//GetElem_L</span><br></pre></td></tr></table></figure></li><li><p>查找</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">LNode *LocateELem_L (LinkList L，Elemtype e) &#123; </span><br><span class="line">  p=L-&gt;next; </span><br><span class="line">  while(p &amp;&amp;p-&gt;data!=e)  </span><br><span class="line">        p=p-&gt;next;                </span><br><span class="line">  return p; //返回L中值为e的数据元素的位置，查找失败返回NULL </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>插入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status ListInsert_L(LinkList &amp;L,int i,ElemType e)&#123; </span><br><span class="line">     p=L;j=0; </span><br><span class="line">      while(p&amp;&amp;j&lt;i−1)&#123;p=p-&gt;next;++j;&#125;//寻找第i−1个结点 </span><br><span class="line">      if(!p||j&gt;i−1)return ERROR;//i大于表长 + 1或者小于1  </span><br><span class="line">      s=new LNode;//生成新结点s </span><br><span class="line">      s-&gt;data=e;                 //将结点s的数据域置为e </span><br><span class="line">      s-&gt;next=p-&gt;next;             //将结点s插入L中 </span><br><span class="line">      p-&gt;next=s; </span><br><span class="line">      return OK; </span><br><span class="line">&#125;//ListInsert_L</span><br></pre></td></tr></table></figure></li><li><p>删除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Status ListDelete_L(LinkList &amp;L,int i,ElemType &amp;e)&#123;</span><br><span class="line">    p=L;j=0; </span><br><span class="line">    while(p-&gt;next &amp;&amp;j&lt;i-1)&#123;//寻找第i个结点，并令p指向其前驱 </span><br><span class="line">        p=p-&gt;next; ++j; </span><br><span class="line">    &#125; </span><br><span class="line">    if(!(p-&gt;next)||j&gt;i-1) return ERROR; //删除位置不合理 </span><br><span class="line">    q=p-&gt;next; //临时保存被删结点的地址以备释放 </span><br><span class="line">    p-&gt;next=q-&gt;next; //改变删除结点前驱结点的指针域 </span><br><span class="line">    e=q-&gt;data; //保存删除结点的数据域 </span><br><span class="line">    delete q; //释放删除结点的空间 </span><br><span class="line"> return OK; </span><br><span class="line">&#125;//ListDelete_L</span><br></pre></td></tr></table></figure></li><li><p>创建单链表（前插法）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void CreateList_F(LinkList &amp;L,int n)&#123; </span><br><span class="line">     L=new LNode; </span><br><span class="line">      L-&gt;next=NULL; //先建立一个带头结点的单链表 </span><br><span class="line">      for(i=n;i&gt;0;--i)&#123; </span><br><span class="line">        p=new LNode; //生成新结点 </span><br><span class="line">        cin&gt;&gt;p-&gt;data; //输入元素值 </span><br><span class="line">        p-&gt;next=L-&gt;next;L-&gt;next=p; //插入到表头 </span><br><span class="line">     &#125; </span><br><span class="line">&#125;//CreateList_F</span><br></pre></td></tr></table></figure></li><li><p>创建单链表（后插法）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void CreateList_L(LinkList &amp;L,int n)&#123; </span><br><span class="line">      //正位序输入n个元素的值，建立带表头结点的单链表L </span><br><span class="line">      L=new LNode; </span><br><span class="line">      L-&gt;next=NULL; </span><br><span class="line">      r=L; //尾指针r指向头结点 </span><br><span class="line">      for(i=0;i&lt;n;++i)&#123; </span><br><span class="line">        p=new LNode;　//生成新结点 </span><br><span class="line">        cin&gt;&gt;p-&gt;data;   //输入元素值 </span><br><span class="line">        p-&gt;next=NULL; r-&gt;next=p;     //插入到表尾 </span><br><span class="line">        r=p; //r指向新的尾结点 </span><br><span class="line">      &#125; </span><br><span class="line">&#125;//CreateList_L</span><br></pre></td></tr></table></figure></li></ul><h4 id="循环链表"><a href="#循环链表" class="headerlink" title="循环链表"></a>循环链表</h4><p>循环链表：最后一个结点的指针域指向头结点，形成一个环，因此从表中任一结点出发均可找到表中其他结点。<br>循环单链表的操作和单链表基本一致，差别在于：当链表遍历时，判别当前指针p是否指向表尾的终止条件不同。在单链表中，判断条件为<code>p!=NULL或p-&gt;next!=NULL</code>再循环单链表中判断条件为<code>p!=L或p-&gt;next!=L</code><br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%BE%AA%E7%8E%AF%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%90%88%E5%B9%B6.PNG" alt="循环链表的合并"></p><h4 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//---双向链表的存储结构---</span><br><span class="line">typedef struct DuLNode&#123;</span><br><span class="line">    ElemType   data;              </span><br><span class="line">    struct DuLNode  *prior;  </span><br><span class="line">    struct DuLNode  *next;  </span><br><span class="line">&#125;DuLNode, *DuLinkList</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E5%90%91%E5%BE%AA%E7%8E%AF%E9%93%BE%E8%A1%A8.PNG" alt="双向循环链表"></p><ul><li><p>双向链表的插入<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E7%9A%84%E6%8F%92%E5%85%A5.PNG" alt="双向链表的插入"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Status ListInsert_DuL(DuLinkList &amp;L,int i,ElemType e)&#123;</span><br><span class="line">   if(!(p=GetElemP_DuL(L,i))) return ERROR;</span><br><span class="line">    s=new DuLNode; </span><br><span class="line">   s-&gt;data=e;</span><br><span class="line">   s-&gt;prior=p-&gt;prior;  ①</span><br><span class="line">   p-&gt;prior-&gt;next=s;   ②</span><br><span class="line">   s-&gt;next=p;          ③</span><br><span class="line">   p-&gt;prior=s;         ④</span><br><span class="line">   return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>双向链表的删除<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E7%9A%84%E5%88%A0%E9%99%A4.PNG" alt="双向链表的删除"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status ListDelete_DuL(DuLinkList &amp;L,int i,ElemType &amp;e)&#123;</span><br><span class="line">   if(!(p=GetElemP_DuL(L,i)))     return ERROR;</span><br><span class="line">   e=p-&gt;data;</span><br><span class="line">   p-&gt;prior-&gt;next=p-&gt;next;     ①</span><br><span class="line">   p-&gt;next-&gt;prior=p-&gt;prior;    ②</span><br><span class="line">   delete p; </span><br><span class="line">   return OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简单算法实现</title>
      <link href="/2018/09/08/2018-09-08-Algorithm-demo/"/>
      <url>/2018/09/08/2018-09-08-Algorithm-demo/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}</li></ul><h3 id="复数抽象数据类型的定义及操作"><a href="#复数抽象数据类型的定义及操作" class="headerlink" title="复数抽象数据类型的定义及操作"></a>复数抽象数据类型的定义及操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">#define ERROR 0 </span><br><span class="line">typedef float status;</span><br><span class="line"></span><br><span class="line">typedef struct    //抽象数据类型的存储结构</span><br><span class="line">&#123;</span><br><span class="line">    float Realpart;</span><br><span class="line">    float Imagepart;</span><br><span class="line">&#125;Complex;</span><br><span class="line"></span><br><span class="line">void Create(Complex &amp;C,float x,float y)   //构建复数</span><br><span class="line">&#123;</span><br><span class="line">    C.Realpart=x;</span><br><span class="line">    C.Imagepart=y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">status GetReal(Complex C)    //取实部</span><br><span class="line">&#123;</span><br><span class="line">    return C.Realpart;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">status GetImag(Complex C)    //取虚部</span><br><span class="line">&#123;</span><br><span class="line">    return C.Imagepart;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Complex Add(Complex C1,Complex C2)    //复数相加</span><br><span class="line">&#123;</span><br><span class="line">    Complex sum;</span><br><span class="line">    sum.Realpart=C1.Realpart+C2.Realpart;</span><br><span class="line">    sum.Imagepart=C1.Imagepart+C2.Imagepart;</span><br><span class="line">    return sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Complex Sub(Complex C1,Complex C2)    //复数相减</span><br><span class="line">&#123;</span><br><span class="line">    Complex dif;</span><br><span class="line">    dif.Realpart=C1.Realpart-C2.Realpart;</span><br><span class="line">    dif.Imagepart=C1.Imagepart-C2.Imagepart;</span><br><span class="line">    return dif;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">    Complex C1,C2,C3,C4;</span><br><span class="line">    cout&lt;&lt;&quot;请输入第一个复数！&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">    cin&gt;&gt;C1.Realpart;</span><br><span class="line">    cin&gt;&gt;C1.Imagepart;</span><br><span class="line">    cout&lt;&lt;&quot;请输入第二个复数！&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">    cin&gt;&gt;C2.Realpart;</span><br><span class="line">    cin&gt;&gt;C2.Imagepart;</span><br><span class="line">    cout&lt;&lt;&quot;C1实部为：&quot;&lt;&lt;GetReal(C1)&lt;&lt;&quot;C1虚部为：&quot;&lt;&lt;GetImag(C1)&lt;&lt;&quot;\n&quot;;</span><br><span class="line">    C3=Add(C1,C2);</span><br><span class="line">    C4=Sub(C1,C2);</span><br><span class="line">    cout&lt;&lt;&quot;和为：&quot;&lt;&lt;C3.Realpart&lt;&lt;&quot;+&quot;&lt;&lt;C3.Imagepart&lt;&lt;&quot;i&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">    cout&lt;&lt;&quot;差为：&quot;&lt;&lt;C4.Realpart&lt;&lt;&quot;+&quot;&lt;&lt;C4.Imagepart&lt;&lt;&quot;i&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="两个有序表的合并（顺序表）"><a href="#两个有序表的合并（顺序表）" class="headerlink" title="两个有序表的合并（顺序表）"></a>两个有序表的合并（顺序表）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">#define ERROR 0</span><br><span class="line">#define MAXSIZE 100</span><br><span class="line">#define OK 1</span><br><span class="line">typedef int status;</span><br><span class="line">typedef int Elemtype;</span><br><span class="line"></span><br><span class="line">typedef struct    //抽象数据类型的存储结构</span><br><span class="line">&#123;</span><br><span class="line">    Elemtype *elem;</span><br><span class="line">int length;</span><br><span class="line">&#125;SqList;</span><br><span class="line"></span><br><span class="line">status initlist(SqList &amp;L)</span><br><span class="line">&#123;</span><br><span class="line">L.elem=new Elemtype[MAXSIZE];</span><br><span class="line">if(!L.elem) return ERROR;</span><br><span class="line">L.length=0;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">SqList createlist(int n)</span><br><span class="line">&#123;</span><br><span class="line">SqList L;</span><br><span class="line">initlist(L);</span><br><span class="line">for(int i=0;i&lt;n;i++)</span><br><span class="line">&#123;</span><br><span class="line">cin&gt;&gt;L.elem[i];</span><br><span class="line">++L.length;</span><br><span class="line">&#125;</span><br><span class="line">return L;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void merge(SqList L1,SqList L2,SqList &amp;L)</span><br><span class="line">&#123;</span><br><span class="line">int *p,*p1,*p2,*p1_last,*p2_last;</span><br><span class="line">initlist(L);</span><br><span class="line">L.length=L1.length+L2.length;</span><br><span class="line">p=L.elem;p1=L1.elem;p2=L2.elem;</span><br><span class="line">p1_last=L1.elem+L1.length-1;</span><br><span class="line">p2_last=L2.elem+L2.length-1;</span><br><span class="line">while((p1&lt;=p1_last)&amp;&amp;(p2&lt;=p2_last))</span><br><span class="line">&#123;</span><br><span class="line">    if(*p1&lt;=*p2) *p++=*p1++;</span><br><span class="line">else *p++=*p2++;</span><br><span class="line">&#125;</span><br><span class="line">while(p1&lt;=p1_last) *p++=*p1++;</span><br><span class="line">while(p2&lt;=p2_last) *p++=*p2++;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">void main()</span><br><span class="line">&#123; </span><br><span class="line">SqList L1,L2,L;</span><br><span class="line">initlist(L1);</span><br><span class="line">initlist(L2);</span><br><span class="line">initlist(L);</span><br><span class="line">cout&lt;&lt;&quot;请输入4个数字！&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">L1=createlist(4);</span><br><span class="line">cout&lt;&lt;&quot;请输入3个数字！&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">L2=createlist(3);</span><br><span class="line">merge(L1,L2,L);</span><br><span class="line">for(int j=0;j&lt;L.length;j++)</span><br><span class="line">&#123;</span><br><span class="line">cout&lt;&lt;L.elem[j];</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="有序表的合并（单链表）"><a href="#有序表的合并（单链表）" class="headerlink" title="有序表的合并（单链表）"></a>有序表的合并（单链表）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">#define ERROR 0</span><br><span class="line">#define MAXSIZE 100</span><br><span class="line">#define OK 1</span><br><span class="line">typedef int status;</span><br><span class="line">typedef int Elemtype;</span><br><span class="line"></span><br><span class="line">typedef struct LNode</span><br><span class="line">&#123;</span><br><span class="line">    Elemtype data;</span><br><span class="line">struct LNode *next;</span><br><span class="line">&#125;LNode,*Linklist;</span><br><span class="line"></span><br><span class="line">status init(Linklist &amp;L)    //链表初始化</span><br><span class="line">&#123; </span><br><span class="line">    L=new LNode;    //为链表开辟内存空间</span><br><span class="line">L-&gt;next=NULL;</span><br><span class="line">return OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void create_L(Linklist &amp;L,int n)     //后插法</span><br><span class="line">&#123;</span><br><span class="line">LNode *p,*r;</span><br><span class="line">L=new LNode;   //开辟内存空间</span><br><span class="line">L-&gt;next=NULL;  //创建一个链表</span><br><span class="line">r=L;</span><br><span class="line">for(int i=0;i&lt;n;i++)</span><br><span class="line">&#123;</span><br><span class="line">    p=new LNode;    //创建结点</span><br><span class="line">cin&gt;&gt;p-&gt;data;</span><br><span class="line">p-&gt;next=NULL;</span><br><span class="line">r-&gt;next=p;</span><br><span class="line">r=p;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void MergeList_L(Linklist La,Linklist Lb,Linklist &amp;Lc)&#123;     //合并有序链表</span><br><span class="line">   LNode *pa,*pb,*pc,*a;</span><br><span class="line">   init(Lc);    //******这是必须的！！！</span><br><span class="line">   pa=La-&gt;next;  pb=Lb-&gt;next; </span><br><span class="line">   pc=Lc=La;             //用La的头结点作为Lc的头结点 </span><br><span class="line">   while(pa &amp;&amp; pb)&#123;</span><br><span class="line">      if(pa-&gt;data&lt;=pb-&gt;data)&#123; pc-&gt;next=pa;pc=pa;pa=pa-&gt;next;&#125;</span><br><span class="line">      else&#123;pc-&gt;next=pb; pc=pb; pb=pb-&gt;next;&#125;</span><br><span class="line">   pc-&gt;next=pa?pa:pb;    //插入剩余段  </span><br><span class="line">   //delete a;             //释放Lb的头结点  </span><br><span class="line">   &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">LNode *p,*L1,*L2,*L,*p1,*p2;</span><br><span class="line">cout&lt;&lt;&quot;请输入3个数字&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">create_L(L1,3);</span><br><span class="line">cout&lt;&lt;&quot;创建成功！&quot;&lt;&lt;&quot;第一个序列是：&quot;;</span><br><span class="line">p1=L1-&gt;next;</span><br><span class="line">while(p1)</span><br><span class="line">&#123;</span><br><span class="line">cout&lt;&lt;p1-&gt;data;</span><br><span class="line">p1=p1-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">cout&lt;&lt;&quot;请输入4个数字&quot;&lt;&lt;&quot;\n&quot;;</span><br><span class="line">create_L(L2,4);</span><br><span class="line">cout&lt;&lt;&quot;创建成功！&quot;&lt;&lt;&quot;第二个序列是：&quot;;</span><br><span class="line">p2=L2-&gt;next;</span><br><span class="line">while(p2)</span><br><span class="line">&#123;</span><br><span class="line">cout&lt;&lt;p2-&gt;data;</span><br><span class="line">p2=p2-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">MergeList_L(L1,L2,L);</span><br><span class="line">p=L-&gt;next;</span><br><span class="line">cout&lt;&lt;&quot;输出为&quot;&lt;&lt;&quot;&quot;;</span><br><span class="line">while(p)</span><br><span class="line">&#123;</span><br><span class="line">cout&lt;&lt;p-&gt;data;</span><br><span class="line">p=p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构知识点（1）——绪论</title>
      <link href="/2018/09/07/2018-09-07-data-struct-summary-1/"/>
      <url>/2018/09/07/2018-09-07-data-struct-summary-1/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}</li></ul><h3 id="数据结构研究内容"><a href="#数据结构研究内容" class="headerlink" title="数据结构研究内容"></a>数据结构研究内容</h3><ul><li><strong>数值计算</strong><br>计算机主要用于数值计算，主要步骤包括：①从具体问题中抽象出数学模型；②设计解决此数学模型的算法；③编写程序，进行调试。<br>寻找数学模型的实质是分析问题，从中提取操作对象，并找出这些操作对象之间的关系，然后用数学语言加以描述，即建立相应的数学方程。    </li><li><strong>非数值计算</strong><br>非数值问题的数学模型不再是数学方程，而是诸如线性表、树和图的数据结构。<br><strong>数据结构是一门研究非数值（抽象数据类型）计算程序设计中的操作对象，以及这些对象之间的关系和操作的学科。</strong>       </li></ul><hr><h3 id="基本概念和术语"><a href="#基本概念和术语" class="headerlink" title="基本概念和术语"></a>基本概念和术语</h3><ul><li><strong>数据</strong><br>所有能输入到计算机中并被计算机程序处理的符号总称；（整数/实数/字符串/图形/声音/动画经特殊编码后的数据）    </li><li><strong>数据元素</strong><br>数据的基本单位，也称元素、记录。数据元素用于完整地描述一个操作对象，如花名单中一名学生记录、树中棋盘的一个状态、图中的一个顶点；    </li><li><strong>数据项</strong><br>组成数据元素的、有独立含义的、不可分割的最小单位。如学生基本信息表中的学号、姓名、性别都是数据项；    </li><li><strong>数据对象</strong><br>性质相同的数据元素的集合，是数据的一个子集。    </li></ul><hr><ul><li>数据结构的<strong>逻辑结构</strong><br>从逻辑上描述数据，与数据的存储无关，可以看作是从具体问题中抽象出来的数学模型。<br>逻辑结构的两个要素：一是数据元素；二是关系。<br>（1）_线性结构_：线性表、栈和队列、字符串、数组、广义表；<br>（2）_非线性结构_：树和二叉树、有向图和无向图。    </li><li>数据结构的<strong>存储结构</strong><br>数据对象在计算机中的存储表示称为数据的存储结构，也称物理结构。<br>将数据对象存储到计算机的时候通常要考虑存储数据元素的数据，又要存储数据元素之间的逻辑关系。<br>存储结构包括：<strong>顺序存储结构</strong>和<strong>链式存储结构</strong>。    </li></ul><hr><ul><li><strong>抽象数据类型</strong><br>抽象数据类型是指由用户定义的、表示应用问题的数学模型，以及定义在这个模型上的一组操作的总称。<br>具体包括三部分：数据对象、数据对象上关系的集合，以及对数据对象的基本操作的集合。<br>ADT 抽象数据类型名{<br>&nbsp;&nbsp; 数据对象：&lt;数据对象的定义&gt;<br>&nbsp;&nbsp; 数据关系：&lt;数据关系的定义&gt;<br>&nbsp;&nbsp; 基本操作：&lt;基本操作的定义&gt;<br>}ADT&nbsp; 抽象数据类型名<br>基本操作名（参数表）<br>&nbsp;&nbsp; 初始条件：&lt;初始条件描述&gt;<br>&nbsp;&nbsp; 操作结果：&lt;操作结果描述&gt;<br>基本操作有两种参数：<strong>赋值参数</strong>只为操作提供输入值；<strong>引用参数</strong>以”&amp;”打头，既可以提供输入值，还可返回操作结果。         </li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用caffe训练数据集</title>
      <link href="/2018/08/24/2018-08-24-caffe-train-data/"/>
      <url>/2018/08/24/2018-08-24-caffe-train-data/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}<h3 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h3>（1） 结合Caffe平台，进一步掌握Caffe的使用流程；<br>（2） 进一步理解Caffe卷积神经网络定义和优化思想；<br>（3） 学会使用prototxt定义卷积神经网络和优化方法；<br>（4） 能看懂卷积神经网络的关键代码；<br>（5） 能独立完成卷积神经网络和优化自定义；<br>（6） 运行自己的数据，解决自己在实践或科研过程中要解决的计算机视觉问题。</li></ul><h3 id="实验需求"><a href="#实验需求" class="headerlink" title="实验需求"></a>实验需求</h3><ul><li>硬件准备：GPU（若使用GPU模式），此选项可选择</li><li>软件准备：Caffe  </li><li>数据准备：自己要识别的数据集<h3 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h3>使用Caffe自定义网络结构和优化方案，识别分类自己的数据集。<h3 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h3><h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4>在网上找大巴车、恐龙、大象、鲜花和马五个图像数据集，编号分别以3,4,5,6,7开头，每个种类100张，其中80张作为训练集，20张作为测试集。因此最终训练图片400张，测试图片100张。<h4 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h4>训练集目录：/home/joczu/caffe-master/data/re/train<br>测试集目录：/home/joczu/caffe-master/data/re/val<br>sh文件目录：/home/joczu/caffe-master/examples/myfile<h4 id="预处理（生成标签）"><a href="#预处理（生成标签）" class="headerlink" title="预处理（生成标签）"></a>预处理（生成标签）</h4>编写create_filelist.sh文件，使用<br><pre><code>find $DATA/train -name $i*.jpg | cut -d '/' -f4-5 | sed "s/$/ $i/">>$MY/train.txt</code></pre><br>把每个图片的名称和上级目录名给截取出来，并分别以开头数字3,4,5,6,7作为一个种类的标签。<br><pre><code><h1 id="usr-bin-env-sh"><a href="#usr-bin-env-sh" class="headerlink" title="/usr/bin/env sh"></a>/usr/bin/env sh</h1>DATA1=”/home/joczu/caffe-master/data/re”<br>DATA2=”/home/joczu/caffe-master/data/re/train/cat”<br>DATA3=”/home/joczu/caffe-master/data/re/train/dog”<br>DATA4=”/home/joczu/caffe-master/data/re/val”</code></pre></li></ul><p>echo “Create train.txt…”</p><p>rm -rf $DATA1/train.txt<br>rm -rf $DATA1/val.txt</p><p>find $DATA2 -name Abyssinian<em>.jpg | cut -d ‘/‘ -f8-9 | sed “s/$/ 1/“&gt;&gt;$DATA1/train.txt<br>find $DATA3 -name american_bulldog</em>.jpg | cut -d ‘/‘ -f8-9 | sed “s/$/ 2/“&gt;&gt;$DATA1/tmp.txt<br>find $DATA4 -name Abyssinian<em>.jpg | cut -d ‘/‘ -f8-9 | sed “s/$/ 1/“&gt;&gt;$DATA1/val.txt<br>find $DATA4 -name american_bulldog</em>.jpg | cut -d ‘/‘ -f8-9 | sed “s/$/ 2/“&gt;&gt;$DATA1/tmp_val.txt</p><p>cat $DATA1/tmp.txt&gt;&gt;$DATA1/train.txt<br>cat $DATA1/tmp_val.txt&gt;&gt;$DATA1/val.txt<br>rm -rf $DATA1/tmp.txt<br>rm -rf $DATA1/tmp_val.txt</p><p>echo “Done..”<br>&lt;/code&gt;&lt;/pre&gt;</p><h4 id="转换lmdb数据格式"><a href="#转换lmdb数据格式" class="headerlink" title="转换lmdb数据格式"></a>转换lmdb数据格式</h4><p>编写creat_lmdb.sh文件，首先转换图片大小，像素均变化成256X256，再调用build/tools/convert_imageset转换图片的数据格式，生成img_test_lmdb和img_train_lmdb文件</p><p><pre><code></code></pre></p><h1 id="usr-bin-env-sh-1"><a href="#usr-bin-env-sh-1" class="headerlink" title="!/usr/bin/env sh"></a>!/usr/bin/env sh</h1><p>MY=examples/myfile</p><p>echo “Creating train lmdb…”<br>rm -rf $MY/img_train_lmdb<br>build/tools/convert_imageset \<br>—shuffle \<br>—resize_height=256 \<br>—resize_width=256 \</p><h1 id="data-re-train"><a href="#data-re-train" class="headerlink" title="/data/re/train \"></a>/data/re/train \</h1><p>$MY/train.txt \<br>$MY/img_train_lmdb<br>echo “Done.”</p><p>echo “Creating test lmdb..”<br>rm -rf $MY/img_test_lmdb<br>build/tools/convert_imageset \<br>—shuffle \<br>—resize_width=256 \<br>—resize_height=256 \</p><h1 id="data-re-val"><a href="#data-re-val" class="headerlink" title="/data/re/val \"></a>/data/re/val \</h1><p>$MY/val.txt \<br>$MY/img_test_lmdb<br>echo “All Done.”<br>&lt;/code&gt;&lt;/pre&gt;<br>到此数据的预处理完成。</p><h4 id="生成均值文件"><a href="#生成均值文件" class="headerlink" title="生成均值文件"></a>生成均值文件</h4><p>图片减去均值再训练，会提高训练速度和精度。因此，一般都会有这个操作。<br>caffe程序提供了一个计算均值的文件compute_image_mean.cpp，我们直接使用就可以了。<br>compute_image_mean带两个参数，第一个参数是lmdb训练数据位置，第二个参数设定均值文件的名字及保存路径。 运行成功后，会在 examples/myfile/ 下面生成一个mean.binaryproto的均值文件。</p><h4 id="创建训练模型"><a href="#创建训练模型" class="headerlink" title="创建训练模型"></a>创建训练模型</h4><p>模型就用程序自带的caffenet模型，位置在 models/bvlc_reference_caffenet/文件夹下,<br>将需要的两个配置文件，复制到myfile文件夹内，<br>修改其中的solver.prototxt</p><p><pre><code>net: "examples/myfile/train_val.prototxt"test_iter: 2test_interval: 50base_lr: 0.001lr_policy: "step"gamma: 0.1stepsize: 100display: 20max_iter: 200momentum: 0.9weight_decay: 0.005solver_mode: CPUsnapshot: 200snapshot_prefix: "examples/myfile/myfile"</code></pre><br>100个测试数据，batch_size为50，因此test_iter设置为2，就能全cover了。在训练过程中，调整学习率，逐步变小。<br>相关参数解释：<br>_net: “examples/myfile/train_val.prototxt” 网络模型的路径。注意的是：文件的路径要从caffe的根目录开始，其它的所有配置都是这样<br>test_iter: 2 这个要结合layer理解，表示两层；<br>test_interval: 50 测试间隔。也就是每训练50次，才进行一次测试<br>base_lr: 0.001 base_lr用于设置基础学习率，在迭代的过程中，可以对基础学习率进行调整。怎么样进行调整，就是调整的策略，由lr_policy来设置<br>lr_policy: “step” 如果设置为step,则还需要设置一个stepsize, 返回 base_lr * gamma ^ (floor(iter / stepsize)),其中iter表示当前的迭代次数<br>gamma: 0.1 上一次梯度更新的权重<br>stepsize: 100<br>display: 20 每训练２0次，在屏幕上显示一次。如果设置为0，则不显示<br>max_iter: 200 最大迭代次数。这个数设置太小，会导致没有收敛，精确度很低。设置太大，会导致震荡，浪费时间<br>momentum: 0.9 上一次梯度更新的权重<br>weight_decay: 0.005 权重衰减项，防止过拟合的一个参数<br>solver_mode: CPU 设置运行模式。默认为GPU,如果你没有GPU,则需要改成CPU，否则会出错<br>snapshot: 200<br>snapshot_prefix: “examples/myfile/myfile”_<br>修改train_val.protxt，只需要修改两个阶段的data层的文件目录</p><p><pre><code>name: "CaffeNet"layer {  name: "data"  type: "Data"  top: "data"  top: "label"  include {    phase: TRAIN  }  transform_param {    mirror: true    crop_size: 227    mean_file: "data/re/imagenet_mean.binaryproto"  }  data_param {    source: "examples/myfile/imagenet_train_leveldb"    batch_size: 256    backend: LMDB  }}layer {  name: "data"  type: "Data"  top: "data"  top: "label"  include {    phase: TEST  }  transform_param {    mirror: false    crop_size: 227    mean_file: "data/re/imagenet_mean.binaryproto"  }  data_param {    source: "examples/myfile/imagenet_val_leveldb"    batch_size: 20    backend: LMDB  }}</code></pre></p><h4 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h4><p>在caffe根目录下输入以下命令</p><p><pre><code>build/tools/caffe train -solver examples/myfile/solver.prototxt</code></pre><br>接下来就是等待训练完成，训练时间大约需要1.5小时<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/caffe%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C/caffe%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C.png" alt="caffe训练结果"><br>训练到此完成，从结果可以看出训练精度为92％<br><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/caffe%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C/caffe%E8%AE%AD%E7%BB%83%E7%94%9F%E6%88%90%E4%B8%AD%E9%97%B4%E6%96%87%E4%BB%B6.png" alt="caffe训练生成中间文件"><br>生成许多中间文件。</p><h3 id="实验问题及解决方法"><a href="#实验问题及解决方法" class="headerlink" title="实验问题及解决方法"></a>实验问题及解决方法</h3><p>（1） 本次实验很大的问题就是路径问题，有的地方在使用相对路径的时候需要在caffe-master目录下运行sh文件；<br>（2） 注意训练集、测试集、sh文件放置的相应位置，以免出现不可名状的错误；<br>（3） 注意设置solver.protptxt及train_val.prototxt文件的参数设置，需根据自己的训练集和测试集进行匹配。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> caffe 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分割——钢铁表面缺陷检测</title>
      <link href="/2018/08/24/2018-08-24-image-segmentation/"/>
      <url>/2018/08/24/2018-08-24-image-segmentation/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}</li></ul><h3 id="实验思路"><a href="#实验思路" class="headerlink" title="实验思路"></a>实验思路</h3><p>先对原图进行几何变化（旋转）变成长方形，再对图像进行分割</p><h3 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h3><p><pre><code>clearclcinit=imread('C:\Users\joczu\Desktop\作业3.bmp');%图像旋转G=rgb2gray(init);E=edge(G);theta=1:180;[R,xp]=radon(E,theta);[E,J]=find(R>=max(max(R)));Q=90-J;I=imrotate(G,Q,'bilinear','crop');%图像切割s=I(:,:,1);bw=im2bw(s,graythresh(s));  %graythresh自动找比较合适的阈值se=strel('disk',1);  %创建切割形状bw2=imclose(bw,se);figure(1);imshow(bw2);perim=bwperim(bw2,8); %表示从输入图像BW1中返回只包括对象边缘坐标r=I(:,:,1);%g=I(:,:,2);%b=I(:,:,3);r(perim)=250;%g(perim)=0;%b(perim)=0;I(:,:,1)=r;%I(:,:,2)=g;%I(:,:,3)=b;figure(2);imshow(I);</code></pre></p><h3 id="实验截图"><a href="#实验截图" class="headerlink" title="实验截图"></a>实验截图</h3><p><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/图像分割-钢铁表面检测/图像分割-钢铁表面检测.png" alt="钢铁表面缺陷分割"></p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 MATLAB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DICOM医学图像处理</title>
      <link href="/2018/08/21/2018-08-21-DICOM-process/"/>
      <url>/2018/08/21/2018-08-21-DICOM-process/</url>
      
        <content type="html"><![CDATA[<ul><li>content<br>{:toc}</li></ul><h3 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h3><p>最大灰度投影（MIP）是临床上最常见的一种血管成像方式，要求将三维数据沿z轴投影。</p><h3 id="实验提示"><a href="#实验提示" class="headerlink" title="实验提示"></a>实验提示</h3><p>将每层DICOM图像对应位置像素点依次比较取最大。</p><h3 id="实验平台"><a href="#实验平台" class="headerlink" title="实验平台"></a>实验平台</h3><p>MATLAB</p><h3 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h3><p><pre><code>clear allclcclose allfile_path =  'E:\data\'; % 图像文件夹路径  img_path_list = dir(strcat(file_path,'*.dcm'));%获取该文件夹中所有dcm格式的图像  img_num = length(img_path_list);%获取图像总数量  imagemax = img_path_list(1).name;% 图像名imagemax =dicomread(strcat(file_path,imagemax)); %%dcm变成灰度图for w=1:400    for u=1:400        tmp=double(imagemax(w,u));        imagemax(w,u)=uint8(255*(tmp-17)/2407);    endend%%比较        for j = 1:img_num %逐一读取图像              image_name = img_path_list(j).name;% 图像名            image =dicomread(strcat(file_path,image_name));            for c=1:400                for d=1:400                    tem=double(image(c,d));                    image(c,d)=uint8(255*(tem-17)/2407);                end            end            for m=1:400                for n=1:400                    imagemax(m,n)=max(image(m,n),imagemax(m,n));                end            end        end  imshow(imagemax,[]);</code></pre></p><h3 id="实验截图"><a href="#实验截图" class="headerlink" title="实验截图"></a>实验截图</h3><p><img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/DICOM%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/DICOM.png" alt="DICOM医学图像"></p>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图像处理 MATLAB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN 知识点</title>
      <link href="/2018/08/17/2018-08-17-CNN/"/>
      <url>/2018/08/17/2018-08-17-CNN/</url>
      
        <content type="html"><![CDATA[<h3 id="卷积神经网络-CNN"><a href="#卷积神经网络-CNN" class="headerlink" title="卷积神经网络(CNN)"></a>卷积神经网络(CNN)</h3><p>1、    深度学习中极具代表性的网络结构之一，常用于图像处理，避免对图像复杂的特征提取，可直接输入原始图像；<br><br>2、    传统的神经网络都是采用输入层到隐藏层全连接的方式，这样导致参数量巨大；而CNN通过局部连接、权值共享方式连接来降低权值参数；<br></p><p>3、    局部连接：</p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5.png" alt="全连接与局部连接"></p><p>4、    权值共享：</p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB.png" alt="权值共享"></p><p> 10*10个权值参数，也就是卷积核（也称滤波器）的大小。一个卷积核只能提取图像的一种特征，使用不同大小的卷积核可以得到图像的不同映射下的特征，称之为Feature Map。另外偏置参数也是共享的，同一种滤波器共享一个；<br><br>5、    卷积神经网络的核心思想是：局部感受野（local field），权值共享以及时间或者空间亚采样相结合，获取某种程度的位移、尺度、形变不变性；<br><br>6、    经典的CNN结构——LeNet-5网络</p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%E7%BD%91%E7%BB%9C.png" alt="LeNet-5网络"></p><p>CNN主要由两种类型的网络层，分别是卷积层和池化/采样层（pooling）。卷积层的作用是提取图像的各种特征；池化层是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。<br><br>卷积层：</p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/%E5%8D%B7%E7%A7%AF.png" alt="卷积"></p><p>池化/采样层：<br>通过不变性（平移、旋转、尺度）保留feature maps主要特征，同时减少特征。<br>通常有两种方式包括Max-Pooling（选择Pooling窗口中的最大值作为采样值）和Mean-Pooling（将Pooling窗口中的所有值相加取平均，以平均值作为采样值）</p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20C1%E5%8D%B7%E7%A7%AF%E5%B1%82.png" alt="C1"></p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20S2%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82.png" alt="S2"></p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20C3%E5%8D%B7%E7%A7%AF%E5%B1%82.png" alt="C3"></p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20S4%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82.png" alt="S4"></p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20C5%E5%8D%B7%E7%A7%AF%E5%B1%82.png" alt="C5"></p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20F6.png" alt="F6"></p><p> <img src="https://raw.githubusercontent.com/joczu/Picture-Set/master/CNN/LeNet-5%20%E8%BE%93%E5%87%BA%E5%B1%82.png" alt="输出层"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
